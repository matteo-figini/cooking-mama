{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11601525,"sourceType":"datasetVersion","datasetId":7276106}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Further implementation \n\nThis is the third part of the notebooks for the Natural Language Processing course, held by Prof. Carman, a.a. 2024/2025.\n\n**Authors:**\n\nMatteo Figini\nRiccardo Figini\nSamuele Forner\nCaterina Motti\nSimone Zacchetti\n\nIn this notebook we are going to implement the most advanded topic we have seen in the lesson and a bit more...","metadata":{}},{"cell_type":"markdown","source":"## Text-to-image\n\nWe would like to see how some of our riceipts can look like...","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade --quiet langchain langchain-core langchain-openai\n!pip install -q python-terrier==0.11.0\n!pip install --upgrade langgraph","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:53:06.660290Z","iopub.execute_input":"2025-05-21T19:53:06.660575Z","iopub.status.idle":"2025-05-21T19:53:17.328350Z","shell.execute_reply.started":"2025-05-21T19:53:06.660551Z","shell.execute_reply":"2025-05-21T19:53:17.327484Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.5)\nRequirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.60)\nRequirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.26)\nRequirement already satisfied: langgraph-prebuilt>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.8)\nRequirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.69)\nRequirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.4)\nRequirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\nRequirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.3.23)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.13.2)\nRequirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.26->langgraph) (1.9.1)\nRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\nRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.16)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (2.32.3)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (0.23.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (2.4.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport matplotlib.pyplot as plt\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nfrom diffusers import DiffusionPipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:53:17.330453Z","iopub.execute_input":"2025-05-21T19:53:17.330672Z","iopub.status.idle":"2025-05-21T19:53:26.533120Z","shell.execute_reply.started":"2025-05-21T19:53:17.330652Z","shell.execute_reply":"2025-05-21T19:53:26.532517Z"}},"outputs":[{"name":"stderr","text":"2025-05-21 19:53:22.695244: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747857202.721579     294 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747857202.729587     294 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnableSequence\nfrom langchain.output_parsers import ResponseSchema, StructuredOutputParser\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nimport pandas as pd\nimport pyterrier as pt\nimport json\nimport openai\nfrom langchain_core.messages import HumanMessage\nfrom typing import Any\nfrom typing import Annotated, Literal\nfrom typing_extensions import TypedDict\nfrom langchain.output_parsers import StructuredOutputParser, ResponseSchema\nfrom langchain_core.tools import tool\nfrom langgraph.prebuilt import ToolNode\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\nfrom langchain_core.messages import ToolMessage\nfrom langchain_core.runnables import RunnableLambda, RunnableWithFallbacks\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:53:26.533838Z","iopub.execute_input":"2025-05-21T19:53:26.534355Z","iopub.status.idle":"2025-05-21T19:53:28.320964Z","shell.execute_reply.started":"2025-05-21T19:53:26.534334Z","shell.execute_reply":"2025-05-21T19:53:28.319841Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\n\n# HuggingFace login token\nsecret_value_0 = user_secrets.get_secret(\"NLP project\")\n\n# OpenAI API key\nsecret_value_1 = user_secrets.get_secret(\"OpenAI_key\")\n\n# Log-in in Huggingface\nlogin(secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:53:28.322020Z","iopub.execute_input":"2025-05-21T19:53:28.322790Z","iopub.status.idle":"2025-05-21T19:53:28.520832Z","shell.execute_reply.started":"2025-05-21T19:53:28.322754Z","shell.execute_reply":"2025-05-21T19:53:28.519946Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# save OpenAI key\nopenai.api_key = secret_value_1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:53:28.522679Z","iopub.execute_input":"2025-05-21T19:53:28.523002Z","iopub.status.idle":"2025-05-21T19:53:28.526928Z","shell.execute_reply.started":"2025-05-21T19:53:28.522981Z","shell.execute_reply":"2025-05-21T19:53:28.526317Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/recipe-sampled-0-25/sampled_dataset.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:53:28.527643Z","iopub.execute_input":"2025-05-21T19:53:28.527896Z","iopub.status.idle":"2025-05-21T19:53:36.131555Z","shell.execute_reply.started":"2025-05-21T19:53:28.527878Z","shell.execute_reply":"2025-05-21T19:53:36.130701Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Extract 3 titles to turn into images\nsampled_titles = df['title'].sample(n=3, random_state=42).tolist()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\npipe.to(\"cuda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(15, 5))\nfor i, title in enumerate(sampled_titles):\n    image = pipe(prompt=title).images[0]\n    axes[i].imshow(image)\n    axes[i].set_title(title, fontsize=10)\n    axes[i].axis('off')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Multi agent system using Pretrained LLM","metadata":{}},{"cell_type":"markdown","source":"This code implements a multi-agent system for generating and refining cooking recipes using a pretrained LLM (GPT-4) and information retrieval techniques. It leverages PyTerrier for indexing and retrieving recipes based on ingredients and directions. The system allows dynamic interactions with the user, enabling recipe generation, modification, and regeneration based on feedback. Using LangChain and LangGraph, the system orchestrates a workflow of nodes for handling user input, generating recipes, and refining them based on real-time corrections. The approach integrates both tools and prompts to create a flexible, user-driven cooking assistant.","metadata":{}},{"cell_type":"code","source":"if not pt.started():\n    pt.init()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:54:16.811635Z","iopub.execute_input":"2025-05-21T19:54:16.812134Z","iopub.status.idle":"2025-05-21T19:54:17.369512Z","shell.execute_reply.started":"2025-05-21T19:54:16.812106Z","shell.execute_reply":"2025-05-21T19:54:17.368501Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_294/3057724015.py:1: DeprecationWarning: Call to deprecated function (or staticmethod) started. (use pt.java.started() instead) -- Deprecated since version 0.11.0.\n  if not pt.started():\nJava started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n/tmp/ipykernel_294/3057724015.py:2: DeprecationWarning: Call to deprecated method pt.init(). Deprecated since version 0.11.0.\njava is now started automatically with default settings. To force initialisation early, run:\npt.java.init() # optional, forces java initialisation\n  pt.init()\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Graph objects","metadata":{}},{"cell_type":"code","source":"\"\"\"\nI am using the ChatOpenAI model from LangChain, which is a wrapper around OpenAI's GPT-3.5 and GPT-4 models.\n\"\"\"\nllm = ChatOpenAI(model=\"gpt-4\", temperature=0.7, openai_api_key=secret_value_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:34.904180Z","iopub.execute_input":"2025-05-21T19:56:34.905058Z","iopub.status.idle":"2025-05-21T19:56:35.210495Z","shell.execute_reply.started":"2025-05-21T19:56:34.905016Z","shell.execute_reply":"2025-05-21T19:56:35.209819Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"\"\"\"\nState Graph, maintaining the state of the conversation.\n\"\"\"\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.130200Z","iopub.execute_input":"2025-05-21T19:56:40.130807Z","iopub.status.idle":"2025-05-21T19:56:40.134980Z","shell.execute_reply.started":"2025-05-21T19:56:40.130783Z","shell.execute_reply":"2025-05-21T19:56:40.134066Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### RAG","metadata":{}},{"cell_type":"code","source":"documents_fields = [\n    {\n        'docno': str(row['id']),  # usa l'id reale\n        'title': row['title'],\n        'ingredients': row['ingredients'],\n    }\n    for _, row in df.iterrows()\n]\n\n\nindexer_fields = pt.IterDictIndexer(index_path)\nindexref = indexer_fields.index(\n    documents_fields,\n    fields=[\"title\", \"ingredients\"],\n    meta={'docno': 20, 'title': 512, 'ingredients': 1024}\n)\n\n# Build Index object and retrieval engine for ingredients\nindex_fields = pt.IndexFactory.of(indexref)\nbm25_ingredients = pt.terrier.Retriever(\n    index_fields,\n    wmodel=\"BM25\",\n    controls={\"w\": \"1.0\"},\n    metadata=[\"docno\", \"ingredients\"],\n    field=\"ingredients\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T20:00:35.355719Z","iopub.execute_input":"2025-05-21T20:00:35.356640Z","iopub.status.idle":"2025-05-21T20:00:35.674583Z","shell.execute_reply.started":"2025-05-21T20:00:35.356611Z","shell.execute_reply":"2025-05-21T20:00:35.673361Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'id'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_294/98437220.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m documents_fields = [\n\u001b[0m\u001b[1;32m      2\u001b[0m     {\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m'docno'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# usa l'id reale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m'title'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'ingredients'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ingredients'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_294/98437220.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m documents_fields = [\n\u001b[1;32m      2\u001b[0m     {\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;34m'docno'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# usa l'id reale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;34m'title'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'ingredients'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ingredients'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'id'"],"ename":"KeyError","evalue":"'id'","output_type":"error"}],"execution_count":19},{"cell_type":"code","source":"documents_fields = [\n    {\n        'docno': str(row['id']),  # usa l'id reale\n        'title': row['title'],\n        'directions': row['directions'],\n    }\n    for _, row in df.iterrows()\n]\n\nos.makedirs(index_path_directions, exist_ok=True)\n\nindexer_fields = pt.IterDictIndexer(index_path_directions)\nindexref_2 = indexer_fields.index(\n    documents_fields,\n    fields=[\"title\", \"directions\"],\n    meta={'docno': 20, 'title': 512, 'directions': 4096}\n)\n\n# Build Index object and retrieval engine for directions\nindex_fields = pt.IndexFactory.of(indexref_2)\nbm25_directions = pt.terrier.Retriever(\n    index_fields,\n    wmodel=\"BM25\",\n    controls={\"w\": \"1.0\"},\n    metadata=[\"docno\", \"directions\"],\n    field=\"directions\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.160151Z","iopub.status.idle":"2025-05-21T19:56:40.160499Z","shell.execute_reply.started":"2025-05-21T19:56:40.160359Z","shell.execute_reply":"2025-05-21T19:56:40.160374Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Prompts\n\nHere, a series of prompts are described for querying the LLM to perform various tasks. The prompts range from recipe generation to recipe validation, and they all follow a predefined format for how the app should respond, allowing for the use of a parser. The first two prompts also provide the ability to input custom information.","metadata":{}},{"cell_type":"code","source":"prompt_system_ingrs = \"\"\"\nYou are a creative and helpful cooking assistant.\n\nThe user will provide a list of available ingredients.  \nYour task is to create a complete and realistic recipe using **only those ingredients** — do not invent or add anything not included in the list.\n\nThe recipe must include:\n- A clear and descriptive title\n- Step-by-step preparation instructions\n\nImportant rules:\n- Do NOT use any ingredient that is not listed.\n- If a necessary item (e.g., salt, oil, water) is missing, do NOT assume it's available — exclude it.\n- You can adjust the form or quantity of the ingredients (e.g., chop, grate, blend), but not add new ones.\n- If the ingredients are unusual together, invent a plausible or creative dish that still makes good use of them.\n\nOutput your response in the following JSON format:\n\n{{\n\t\"title\": string  // The title of the recipe\n\t\"list_of_steps\": string  // A list of steps to prepare the dish, only the list\n}}\n\nDO NOT return any other text or explanation, just the JSON.\n\nExample, take some ispiration from this:\n{Example}\n\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.161238Z","iopub.status.idle":"2025-05-21T19:56:40.161501Z","shell.execute_reply.started":"2025-05-21T19:56:40.161368Z","shell.execute_reply":"2025-05-21T19:56:40.161378Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"response_schemas_2 = [\n    ResponseSchema(\n        name='title',\n        description='The title of the recipe',\n    ),\n    ResponseSchema(\n        name='list_of_steps',\n        description='A list of steps to prepare the dish, only the list',\n    )\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.162340Z","iopub.status.idle":"2025-05-21T19:56:40.162628Z","shell.execute_reply.started":"2025-05-21T19:56:40.162506Z","shell.execute_reply":"2025-05-21T19:56:40.162519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_parser_2 = StructuredOutputParser.from_response_schemas(response_schemas_2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.164033Z","iopub.status.idle":"2025-05-21T19:56:40.164761Z","shell.execute_reply.started":"2025-05-21T19:56:40.164579Z","shell.execute_reply":"2025-05-21T19:56:40.164596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt_system_ingrs_ = ChatPromptTemplate.from_messages(\n    [('system', prompt_system_ingrs), ('user', '{messages}')]\n).partial(format_instructions=output_parser_2.get_format_instructions())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.165406Z","iopub.status.idle":"2025-05-21T19:56:40.165659Z","shell.execute_reply.started":"2025-05-21T19:56:40.165535Z","shell.execute_reply":"2025-05-21T19:56:40.165546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompts_rigeneration_ask = \"\"\"\nYou are a cooking expert, and your task is to improve the recipe. The recipe has already been generated and is visible in the message list. \nYour job is to determine whether additional information is needed from a tool to improve the recipe, or if you should proceed with a new generation using the user's corrections. \n\nYour task is to decide whether to use a tool or not. There are two possible tools available:\n- `retrieve_by_ingredients_tool`: a tool that retrieves recipes based on the ingredients provided by the user.\n- `retrieve_by_directions_tool`: a tool that retrieves recipes based on the directions provided for preparing the dish.\n\nMake a reasoning about the recipe and the information you have, and what is necessary to improve it.\nThan call always the tool, even if you don't need it, to increase the information in the recipe.\n\nThis is the list of changes that the user has made to the recipe:\n{corrections}\n\nThat are very important to take into account in the new generation.\n\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.167081Z","iopub.status.idle":"2025-05-21T19:56:40.167331Z","shell.execute_reply.started":"2025-05-21T19:56:40.167214Z","shell.execute_reply":"2025-05-21T19:56:40.167231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompts_rigeneration_ = ChatPromptTemplate.from_messages(\n    [('system', prompts_rigeneration_ask), ('user', '{messages}')]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.229594Z","iopub.execute_input":"2025-05-21T19:56:40.230250Z","iopub.status.idle":"2025-05-21T19:56:40.265306Z","shell.execute_reply.started":"2025-05-21T19:56:40.230231Z","shell.execute_reply":"2025-05-21T19:56:40.263339Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_294/2476744686.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m prompts_rigeneration_ = ChatPromptTemplate.from_messages(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'system'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompts_rigeneration_ask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{messages}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n","\u001b[0;31mNameError\u001b[0m: name 'prompts_rigeneration_ask' is not defined"],"ename":"NameError","evalue":"name 'prompts_rigeneration_ask' is not defined","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"prompt_regen = \"\"\"\nYou are a creative and helpful cooking assistant.\n\nThe user will provide a list of message.  Use the messages to retrieve all the information that is needed to regenerate the recipe, because this is a regeneration following new directions.\nYour task is to create a complete and realistic recipe using **only those ingredients** — do not invent or add anything not included in the list.\n\nThe recipe must include:\n- A clear and descriptive title\n- Step-by-step preparation instructions\n\nImportant rules:\n- Do NOT use any ingredient that is not listed.\n- If a necessary item (e.g., salt, oil, water) is missing, do NOT assume it's available — exclude it.\n- You can adjust the form or quantity of the ingredients (e.g., chop, grate, blend), but not add new ones.\n- If the ingredients are unusual together, invent a plausible or creative dish that still makes good use of them.\n\nOutput your response in the following JSON format:\n\n{{\n\t\"title\": string  // The title of the recipe\n\t\"list_of_steps\": string  // A list of steps to prepare the dish, only the list\n}}\n\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.265761Z","iopub.status.idle":"2025-05-21T19:56:40.265991Z","shell.execute_reply.started":"2025-05-21T19:56:40.265879Z","shell.execute_reply":"2025-05-21T19:56:40.265888Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt_regen_ = ChatPromptTemplate.from_messages(\n    [('system', prompt_regen), ('user', '{messages}')]\n).partial(format_instructions=output_parser_2.get_format_instructions())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.266710Z","iopub.status.idle":"2025-05-21T19:56:40.266948Z","shell.execute_reply.started":"2025-05-21T19:56:40.266839Z","shell.execute_reply":"2025-05-21T19:56:40.266849Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Tools\n\nThe tools are resources that agents can utilize to perform operations that generally do not involve LLMs but are local and independent of them. In this case, specifically, the tools are related to RAG (Retrieval-Augmented Generation), meaning they are used for retrieving existing recipes to gather insights or inspiration. These tools allow the system to pull relevant data without relying on the LLM, improving the recipe generation process by leveraging previously indexed information.","metadata":{}},{"cell_type":"code","source":"def create_tool_node_with_fallback(tools: list) -> RunnableWithFallbacks[Any, dict]:\n    \"\"\"\n    Create a ToolNode with a fallback to handle errors and surface them to the agent.\n    1. This creates a node in a LangGraph that can execute a list of tools (which are functions, APIs, or other callable objects).\n    2. With_fallbacksensuring: if an error occurs, the agent receives a structured error message instead of failing.This adds a fallback mechanism in case any tool in tools fails.\n    3. Wraps the handle_tool_error function inside a RunnableLambda, making it compatible with LangGraph's execution model.\n\n    Nodes using “external functions” are seen as one or more tools. These tools are called in succession then\n    \"\"\"\n    return ToolNode(tools).with_fallbacks(\n        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n    )\n\n\ndef handle_tool_error(state) -> dict:\n    error = state.get(\"error\")\n    tool_calls = state[\"messages\"][-1].tool_calls\n    return {\n        \"messages\": [\n            ToolMessage(\n                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n                tool_call_id=tc[\"id\"],\n            )\n            for tc in tool_calls\n        ]\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.267833Z","iopub.status.idle":"2025-05-21T19:56:40.268112Z","shell.execute_reply.started":"2025-05-21T19:56:40.267962Z","shell.execute_reply":"2025-05-21T19:56:40.267973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@tool\ndef retrive_by_ingredients(ingredients: str):\n    \"\"\"Retrieves a recipe based on the provided ingredients.\"\"\"\n    # Use the bm25_ingredients to search for recipes based on the ingredients\n    result = bm25_ingredients.search(ingredients)\n    if result.empty:\n        return \"No recipes found.\"\n    \n    id = result.iloc[0][\"docno\"]\n    id = int(id)  # converti in intero\n\n    return df[df[\"id\"] == id]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.269172Z","iopub.status.idle":"2025-05-21T19:56:40.269398Z","shell.execute_reply.started":"2025-05-21T19:56:40.269295Z","shell.execute_reply":"2025-05-21T19:56:40.269304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@tool\ndef retrieve_by_ingredients_tool(ingredients: str, num_recipes: int):\n    \"\"\"\n    Retrieves a specified number of recipes based on the provided ingredients.\n\n    Parameters:\n    - ingredients (str): A string representing the ingredients to search for in the recipes.\n      Ingredients should be separated by a comma and a space (e.g., \"chicken, garlic, pasta\").\n    - num_recipes (int): The number of recipes to be returned as search results.\n      This parameter defines how many recipes are returned. It can be any positive integer.\n\n    Returns:\n    - List[DataFrame]: A list of DataFrames, each representing a recipe. Each DataFrame contains\n      the details of a recipe that matches the provided ingredients.\n      If there are fewer recipes than requested, the function will return only those found.\n      If no recipes are found, a message saying \"No recipes found.\" will be returned.\n\n    \"\"\"\n\n    # Use the bm25_ingredients to search for recipes based on the ingredients\n    result = bm25_ingredients.search(ingredients)\n    if result.empty:\n        return \"No recipes found.\"\n\n    # Prepare a list of recipes\n    recipes = []\n    \n    for idx in result.index[:num_recipes]:  # Take only top N results\n        recipe_id = int(result.loc[idx, \"docno\"])\n        recipe = df[df[\"id\"] == recipe_id]\n        recipes.append(recipe)\n        \n    return recipes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.270765Z","iopub.status.idle":"2025-05-21T19:56:40.271127Z","shell.execute_reply.started":"2025-05-21T19:56:40.270943Z","shell.execute_reply":"2025-05-21T19:56:40.270961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@tool\ndef retrieve_by_directions_tool(directions: str, num_recipes: int):\n    \"\"\"\n    Retrieves a specified number of recipes based on the provided directions.\n\n    Parameters:\n    - directions (str): A string representing the directions to search for in the recipes.\n    - num_recipes (int): The number of recipes to be returned as search results.\n      This parameter defines how many recipes are returned. It can be any positive integer.\n\n    Returns:\n    - List[DataFrame]: A list of DataFrames, each representing a recipe. Each DataFrame contains\n      the details of a recipe that matches the provided ingredients.\n      If there are fewer recipes than requested, the function will return only those found.\n      If no recipes are found, a message saying \"No recipes found.\" will be returned.\n\n    \"\"\"\n\n    # Use the bm25_ingredients to search for recipes based on the ingredients\n    result = bm25_ingredients.search(directions)\n    \n    if result.empty:\n        return \"No recipes found.\"\n\n    recipes = []\n    \n    for idx in result.index[:num_recipes]:\n        recipe_id = int(result.loc[idx, \"docno\"])\n        recipe = df[df[\"id\"] == recipe_id]\n        recipes.append(recipe)\n\n    return recipes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.271937Z","iopub.status.idle":"2025-05-21T19:56:40.272186Z","shell.execute_reply.started":"2025-05-21T19:56:40.272072Z","shell.execute_reply":"2025-05-21T19:56:40.272083Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Chain\n\nThe chains are sequences of operations that need to be executed when interacting with the LLM. They typically involve preparing the prompt, setting up the LLM, and handling the response. In some cases, chains also include calling the tools.","metadata":{}},{"cell_type":"code","source":"recipe_chain_2 = prompt_system_ingrs_ | llm | output_parser_2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.272974Z","iopub.status.idle":"2025-05-21T19:56:40.273349Z","shell.execute_reply.started":"2025-05-21T19:56:40.273173Z","shell.execute_reply":"2025-05-21T19:56:40.273189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"regen_chain = prompts_rigeneration_ | llm.bind_tools(\n    [retrieve_by_ingredients_tool, retrieve_by_directions_tool],\n    tool_choice=\"required\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.274360Z","iopub.status.idle":"2025-05-21T19:56:40.274588Z","shell.execute_reply.started":"2025-05-21T19:56:40.274481Z","shell.execute_reply":"2025-05-21T19:56:40.274490Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"recipe_regen = prompt_regen_ | llm | output_parser_2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.275259Z","iopub.status.idle":"2025-05-21T19:56:40.275495Z","shell.execute_reply.started":"2025-05-21T19:56:40.275379Z","shell.execute_reply":"2025-05-21T19:56:40.275389Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Node","metadata":{}},{"cell_type":"code","source":"def starter(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    This node initializes the workflow by collecting a list of ingredients \n    from the user and creating a HumanMessage with the input.\n    \"\"\"\n    user_input = input(\"Enter a list of ingredients (comma-separated): \")\n    return {\"messages\": HumanMessage(content=user_input)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.276302Z","iopub.status.idle":"2025-05-21T19:56:40.276552Z","shell.execute_reply.started":"2025-05-21T19:56:40.276434Z","shell.execute_reply":"2025-05-21T19:56:40.276444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def first_generation(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    This function generates a recipe based on the ingredients provided by the user.\n    \n    Steps:\n    1. Extracts the list of ingredients from the last message in the state.\n    2. Uses the `retrive_by_ingredients` tool to retrieve a recipe matching the ingredients.\n    3. Passes the retrieved recipe and messages to the `recipe_chain_2` for further processing.\n    4. Prints the recipe title and preparation steps.\n    5. Returns the updated state with the generated recipe.\n\n    \"\"\"\n    ingredients = state[\"messages\"][-1].content\n\n    recipe = retrive_by_ingredients(ingredients)\n\n    response_2 = recipe_chain_2.invoke({\"messages\": state[\"messages\"], \"Example\": recipe})\n\n    print(\"\\n\\n\\n\\nTitle:\", response_2['title'])\n\n    print(\"\\nPreparation Steps:\")\n    for i, step in enumerate(response_2['list_of_steps'], 1):\n        print(f\"{i}. {step}\")\n\n    return {\"messages\": AIMessage(content=json.dumps(response_2, indent=2))}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.278173Z","iopub.status.idle":"2025-05-21T19:56:40.278412Z","shell.execute_reply.started":"2025-05-21T19:56:40.278302Z","shell.execute_reply":"2025-05-21T19:56:40.278312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def modify_generation(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    This function regenerates a recipe based on the user's input and the current state.\n    Use the lit of messages to retrieve all the information needed to regenerate the recipe.\n    It checks if the user wants to use a tool to improve the recipe or if it should proceed with a new generation.\n\n    Steps:\n    1. Invokes the `recipe_regen` chain using the messages from the current state.\n    2. Extracts the title and preparation steps from the response.\n    3. Prints the recipe title and step-by-step preparation instructions.\n    4. Returns the updated state with the newly generated recipe.\n\n    \"\"\"\n    response_2 = recipe_regen.invoke({\"messages\": state[\"messages\"]})\n\n    print(\"\\n\\n\\n\\nTitle:\", response_2['title'])\n\n    print(\"\\nPreparation Steps:\")\n    for i, step in enumerate(response_2['list_of_steps'], 1):\n        print(f\"{i}. {step}\")\n\n    return {\"messages\": AIMessage(content=json.dumps(response_2, indent=2))}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.279428Z","iopub.status.idle":"2025-05-21T19:56:40.279759Z","shell.execute_reply.started":"2025-05-21T19:56:40.279589Z","shell.execute_reply":"2025-05-21T19:56:40.279604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def ask_what_to_do(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    This node interacts the LLM that decides what to do whether to retrieve other recipes by ingredients or by instructions, \n    or simply go to regenerate with the new directions.\n    \"\"\"\n    user_input = input(\"What do you want to do?\")\n\n    response_2 = regen_chain.invoke({\"messages\": state[\"messages\"], \"corrections\": user_input})\n    print(response_2)\n    return {\"messages\": [response_2]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.281036Z","iopub.status.idle":"2025-05-21T19:56:40.281309Z","shell.execute_reply.started":"2025-05-21T19:56:40.281193Z","shell.execute_reply":"2025-05-21T19:56:40.281202Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def modify_recipe_condition(state: State) -> Literal[END, \"ask_what_to_do\"]:\n    \"\"\"\n    This function determines whether the user wants to modify the recipe or terminate the program.\n    It prompts the user for input and checks if they want to make changes or end the program.\n    \"\"\"\n    print(\"\\n\\nModifying recipe...Do you need to change something?\")\n    user_input = input(\"Enter NO or YES: \")\n    if user_input.lower() == \"no\":\n        return END\n    else:\n        return \"ask_what_to_do\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.282011Z","iopub.status.idle":"2025-05-21T19:56:40.282368Z","shell.execute_reply.started":"2025-05-21T19:56:40.282188Z","shell.execute_reply":"2025-05-21T19:56:40.282204Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def where_continue(state: State) -> Literal[\"modify_generation\", \"retrieve_by_ingredients_tool\", \"retrieve_by_directions_tool\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n\n    if last_message.tool_calls:\n        for tc in last_message.tool_calls:\n            if tc[\"name\"] == \"retrieve_by_ingredients_tool\":\n                return \"retrieve_by_ingredients_tool\"\n            elif tc[\"name\"] == \"retrieve_by_directions_tool\":\n                return \"retrieve_by_directions_tool\"\n    else:\n        return \"modify_generation\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.283308Z","iopub.status.idle":"2025-05-21T19:56:40.283565Z","shell.execute_reply.started":"2025-05-21T19:56:40.283441Z","shell.execute_reply":"2025-05-21T19:56:40.283452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"workflow = StateGraph(State)\n\nworkflow.add_node(\"starter\", starter)\n\nworkflow.add_node(\"first_generation\", first_generation)\n\nworkflow.add_node(\"ask_what_to_do\", ask_what_to_do)\n\nworkflow.add_node(\"modify_generation\", modify_generation)\n\nworkflow.add_node(\"retrieve_by_ingredients_tool\", create_tool_node_with_fallback([retrieve_by_ingredients_tool]))\n\nworkflow.add_node(\"retrieve_by_directions_tool\", create_tool_node_with_fallback([retrieve_by_directions_tool]))\n\n#_____________________________________________________________________________________________________________#\n\nworkflow.add_edge(START, \"starter\")\n\nworkflow.add_edge(\"starter\", \"first_generation\")\n\nworkflow.add_conditional_edges(\n    \"first_generation\",\n    modify_recipe_condition\n)\n\nworkflow.add_conditional_edges(\n    \"ask_what_to_do\",\n    where_continue\n)\n\nworkflow.add_edge(\"retrieve_by_ingredients_tool\", \"modify_generation\")\n\nworkflow.add_edge(\"retrieve_by_directions_tool\", \"modify_generation\")\n\nworkflow.add_conditional_edges(\n    \"modify_generation\",\n    modify_recipe_condition\n)\n\napp = workflow.compile()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.284566Z","iopub.status.idle":"2025-05-21T19:56:40.284792Z","shell.execute_reply.started":"2025-05-21T19:56:40.284690Z","shell.execute_reply":"2025-05-21T19:56:40.284699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.327847Z","iopub.execute_input":"2025-05-21T19:56:40.328292Z","iopub.status.idle":"2025-05-21T19:56:40.355425Z","shell.execute_reply.started":"2025-05-21T19:56:40.328260Z","shell.execute_reply":"2025-05-21T19:56:40.354079Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_294/11261742.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m display(\n\u001b[1;32m      4\u001b[0m     Image(\n\u001b[0;32m----> 5\u001b[0;31m         app.get_graph().draw_mermaid_png(\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mdraw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMermaidDrawMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         )\n","\u001b[0;31mNameError\u001b[0m: name 'app' is not defined"],"ename":"NameError","evalue":"name 'app' is not defined","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"initial_state = {\n                'messages': []\n}\n\napp.invoke(initial_state)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.356012Z","iopub.status.idle":"2025-05-21T19:56:40.356416Z","shell.execute_reply.started":"2025-05-21T19:56:40.356188Z","shell.execute_reply":"2025-05-21T19:56:40.356202Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Chatbot\n\nThe following is a simple UI implementation of a chatbot that allow the user to interact through voice or text and receive a response that can be listened as well!","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install gradio\n!pip install --upgrade transformers sentencepiece datasets[audio]\n!pip install transformers torchaudio\n!pip install -q kokoro>=0.9.2 soundfile\n!apt-get -qq -y install espeak-ng > /dev/null 2>&1\n!pip install TTS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.357629Z","iopub.status.idle":"2025-05-21T19:56:40.357900Z","shell.execute_reply.started":"2025-05-21T19:56:40.357762Z","shell.execute_reply":"2025-05-21T19:56:40.357774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torchaudio\nimport soundfile as sf\nimport gradio as gr\nfrom transformers import pipeline, AutoProcessor, WhisperForConditionalGeneration, AutoTokenizer, AutoModelForCausalLM\nfrom TTS.api import TTS\nfrom datasets import load_dataset\nfrom datasets import load_dataset\nfrom kokoro import KPipeline\nfrom IPython.display import Audio, display\nfrom langchain.agents import initialize_agent, AgentType\nfrom langchain.chat_models import ChatOpenAI","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.359547Z","iopub.status.idle":"2025-05-21T19:56:40.359888Z","shell.execute_reply.started":"2025-05-21T19:56:40.359721Z","shell.execute_reply":"2025-05-21T19:56:40.359738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load STT model (Whisper)\nwhisper_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\nwhisper_processor = AutoProcessor.from_pretrained(\"openai/whisper-small\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.361245Z","iopub.status.idle":"2025-05-21T19:56:40.361535Z","shell.execute_reply.started":"2025-05-21T19:56:40.361406Z","shell.execute_reply":"2025-05-21T19:56:40.361420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agent_kwargs = {\n    \"prefix\": \"\"\"\nYou are an expert chef assistant.\n\nWhen given a list of ingredients, your goal is to decide whether to:\n- DIRECTLY create a recipe yourself (if the ingredients are common or easy to work with), or\n- USE ONE OF THE AVAILABLE TOOLS if you need to search for existing recipes or need help with the preparation steps.\n\nYou have access to the following tools:\n1. retrieve_by_ingredients_tool: use this to find recipes based on a list of ingredients.\n2. retrieve_by_directions_tool: use this to find recipes based on the preparation steps or cooking directions.\n\nThink step by step. If you can confidently create the recipe yourself, do it. If not, choose the appropriate tool. Always return a complete, well-structured recipe as your final answer.\n\"\"\"\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.363187Z","iopub.status.idle":"2025-05-21T19:56:40.363560Z","shell.execute_reply.started":"2025-05-21T19:56:40.363373Z","shell.execute_reply":"2025-05-21T19:56:40.363390Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n\nagent = initialize_agent(\n    tools=[retrieve_by_directions_tool, retrieve_by_ingredients_tool],\n    llm=llm,\n    agent=AgentType.OPENAI_FUNCTIONS,\n    agent_kwargs=agent_kwargs,\n    verbose=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.364492Z","iopub.status.idle":"2025-05-21T19:56:40.364707Z","shell.execute_reply.started":"2025-05-21T19:56:40.364603Z","shell.execute_reply":"2025-05-21T19:56:40.364612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load TTS model (Kokoro)\npipeline = KPipeline(lang_code='a')\n\nembeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\nspeaker_embedding = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.365202Z","iopub.status.idle":"2025-05-21T19:56:40.365447Z","shell.execute_reply.started":"2025-05-21T19:56:40.365335Z","shell.execute_reply":"2025-05-21T19:56:40.365346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def from_text_to_speech_with_embedding(text, embedding):\n    \"\"\"Convert text into audio using Kokoro + speaker embedding.\"\"\"\n    audio_path = '/tmp/generated_audio.wav'\n\n    generator = pipeline(text, voice='af_heart')\n\n    for i, (generated_sentence, phonemes, audio) in enumerate(generator):\n        print(f\"[{i}] Generated: {generated_sentence}\")\n        sf.write(audio_path, audio, 24000)\n\n    return audio_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.366939Z","iopub.status.idle":"2025-05-21T19:56:40.367267Z","shell.execute_reply.started":"2025-05-21T19:56:40.367077Z","shell.execute_reply":"2025-05-21T19:56:40.367090Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def transcribe(audio):\n    speech, sr = torchaudio.load(audio)\n    if sr != 16000:\n        speech = torchaudio.functional.resample(speech, orig_freq=sr, new_freq=16000)\n    input_features = whisper_processor(speech.squeeze(0), sampling_rate=16000, return_tensors=\"pt\").input_features\n    predicted_ids = whisper_model.generate(input_features)\n    transcription = whisper_processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n    return transcription\n\ndef chat(prompt, model=\"gpt-4\"):\n    response = agent.run(prompt)\n    return response\n\n\ndef generate_response(text=None, audio=None):\n    if audio:\n        text = transcribe(audio)\n\n    print(f\"User: {text}\")\n    response = chat(text)\n\n    audio_path = from_text_to_speech_with_embedding(response, speaker_embedding)\n\n    return response, audio_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.368294Z","iopub.status.idle":"2025-05-21T19:56:40.368530Z","shell.execute_reply.started":"2025-05-21T19:56:40.368414Z","shell.execute_reply":"2025-05-21T19:56:40.368423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with gr.Blocks() as demo:\n    gr.Markdown(\"## 🎙️🧠 Speech+Text Chatbot with Open Source Models\")\n\n    with gr.Row():\n        text_input = gr.Textbox(label=\"Write a message\")\n        audio_input = gr.Audio(type=\"filepath\", label=\"...or talk\")\n\n    submit_btn = gr.Button(\"Send\")\n\n    with gr.Row():\n        text_output = gr.Textbox(label=\"Bot answer\")\n        audio_output = gr.Audio(label=\"Listen the answer\", type=\"filepath\")\n\n    submit_btn.click(\n        fn=generate_response,\n        inputs=[text_input, audio_input],\n        outputs=[text_output, audio_output]\n    )\n\n    # Input reset\n    submit_btn.click(\n        fn=lambda: (\"\", None),\n        inputs=None,\n        outputs=[text_input, audio_input],\n        queue=False\n    )\n\ndemo.launch()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T19:56:40.369621Z","iopub.status.idle":"2025-05-21T19:56:40.369837Z","shell.execute_reply.started":"2025-05-21T19:56:40.369734Z","shell.execute_reply":"2025-05-21T19:56:40.369742Z"}},"outputs":[],"execution_count":null}]}