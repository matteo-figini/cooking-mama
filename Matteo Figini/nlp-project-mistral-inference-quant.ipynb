{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Mistral Inference, Quantization & Fine-Tuning # \n\nIn this notebook, we use a large language model called \"Mistral-7B-Instruct-v0.3\" (https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3), to define a cooking chatbot and trying to fine-tuning it based on the RecipeNLG dataset.","metadata":{}},{"cell_type":"markdown","source":"## Install necessary libraries\n\nFirst, install the HuggingFace Transformers library and some related libraries, such as accelerate. Then, download a few libraries from HuggingFace Transformers.","metadata":{}},{"cell_type":"code","source":"!pip install -q -U transformers bitsandbytes accelerate #xformers\n\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:23:19.908328Z","iopub.execute_input":"2025-05-10T20:23:19.908565Z","iopub.status.idle":"2025-05-10T20:25:10.080621Z","shell.execute_reply.started":"2025-05-10T20:23:19.908546Z","shell.execute_reply":"2025-05-10T20:25:10.080013Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2025-05-10 20:24:57.827754: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746908698.064587      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746908698.130931      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"torch.random.manual_seed(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:25:10.081732Z","iopub.execute_input":"2025-05-10T20:25:10.082294Z","iopub.status.idle":"2025-05-10T20:25:10.092000Z","shell.execute_reply.started":"2025-05-10T20:25:10.082269Z","shell.execute_reply":"2025-05-10T20:25:10.091294Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7c463490c2f0>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"NLP project\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:25:10.092773Z","iopub.execute_input":"2025-05-10T20:25:10.093063Z","iopub.status.idle":"2025-05-10T20:25:10.258727Z","shell.execute_reply.started":"2025-05-10T20:25:10.093032Z","shell.execute_reply":"2025-05-10T20:25:10.258210Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Import model and tokenizer\n\nLet's import the model and the tokenizer, load the model into the GPU, and show a structure of both.","metadata":{}},{"cell_type":"code","source":"# Define the model name\nmodel_name = \"mistralai/Mistral-7B-Instruct-v0.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:25:10.260079Z","iopub.execute_input":"2025-05-10T20:25:10.260305Z","iopub.status.idle":"2025-05-10T20:25:10.263549Z","shell.execute_reply.started":"2025-05-10T20:25:10.260287Z","shell.execute_reply":"2025-05-10T20:25:10.262978Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained (\n    model_name,\n    device_map=\"cuda\",\n    torch_dtype=\"auto\",\n    trust_remote_code=True,\n    token=secret_value_0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:25:10.264331Z","iopub.execute_input":"2025-05-10T20:25:10.264915Z","iopub.status.idle":"2025-05-10T20:26:15.390420Z","shell.execute_reply.started":"2025-05-10T20:25:10.264898Z","shell.execute_reply":"2025-05-10T20:26:15.389891Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ad9f7a8770c406d8d23b1488214b227"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"611d7c0c95954353b29cfa7156533cc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3215d104e7034bb3b3930c3f4713b1fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0246a9e96b2240839b6951e742220fd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bee57afda4643ec885121318bc01aa4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2068d98784441a6b3e9a2d6ce453db0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db56d4acb60443f685a46afd300ae5ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27814e01145b401385828c2dabd39e62"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:26:15.391198Z","iopub.execute_input":"2025-05-10T20:26:15.391486Z","iopub.status.idle":"2025-05-10T20:26:15.397883Z","shell.execute_reply.started":"2025-05-10T20:26:15.391461Z","shell.execute_reply":"2025-05-10T20:26:15.397182Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"MistralForCausalLM(\n  (model): MistralModel(\n    (embed_tokens): Embedding(32768, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x MistralDecoderLayer(\n        (self_attn): MistralAttention(\n          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n        )\n        (mlp): MistralMLP(\n          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): MistralRMSNorm((4096,), eps=1e-05)\n    (rotary_emb): MistralRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, token=secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:26:15.398606Z","iopub.execute_input":"2025-05-10T20:26:15.398879Z","iopub.status.idle":"2025-05-10T20:26:21.636845Z","shell.execute_reply.started":"2025-05-10T20:26:15.398856Z","shell.execute_reply":"2025-05-10T20:26:21.636054Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d724b69ca871420d8e62117f09a98565"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"235270efcb5c48b18c0be740c811d3e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92773984700b4362ace64443252a69f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0206abffffdc447cb88bf38fb3d7e82a"}},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Use the model","metadata":{}},{"cell_type":"code","source":"# Define a pipeline to give the input to the model\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:26:21.637769Z","iopub.execute_input":"2025-05-10T20:26:21.638086Z","iopub.status.idle":"2025-05-10T20:26:21.643368Z","shell.execute_reply.started":"2025-05-10T20:26:21.638049Z","shell.execute_reply":"2025-05-10T20:26:21.642727Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Arguments used during the tokens generation.\ngeneration_args = {\n    \"max_new_tokens\": 800,\n    \"return_full_text\": False,\n    \"temperature\": 0.3,\n    \"do_sample\": True,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:26:21.644266Z","iopub.execute_input":"2025-05-10T20:26:21.644643Z","iopub.status.idle":"2025-05-10T20:26:21.655984Z","shell.execute_reply.started":"2025-05-10T20:26:21.644621Z","shell.execute_reply":"2025-05-10T20:26:21.655279Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Let's test our Mistral model by giving cooking advices. Start with a very common Italian dish, *Spaghetti alla Carbonara*, and let's see the results.","metadata":{}},{"cell_type":"code","source":"def chatbot(user_request, system_prompt = \"You give cooking advices.\"):\n#    print(system_prompt)\n    messages = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": user_request},\n    ]\n    output = pipe(messages, **generation_args)\n    return output[0]['generated_text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:26:21.658643Z","iopub.execute_input":"2025-05-10T20:26:21.658889Z","iopub.status.idle":"2025-05-10T20:26:21.669135Z","shell.execute_reply.started":"2025-05-10T20:26:21.658875Z","shell.execute_reply":"2025-05-10T20:26:21.668570Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"answer = chatbot(\"How to cook spaghetti alla carbonara?\")\nprint(answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:26:21.669907Z","iopub.execute_input":"2025-05-10T20:26:21.670168Z","iopub.status.idle":"2025-05-10T20:26:53.703954Z","shell.execute_reply.started":"2025-05-10T20:26:21.670147Z","shell.execute_reply":"2025-05-10T20:26:53.703281Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":" To cook Spaghetti alla Carbonara, you'll need the following ingredients:\n\n* 1 lb (450g) spaghetti\n* 4 large eggs\n* 1 cup (100g) grated Pecorino Romano cheese\n* 1/2 cup (100g) grated Parmesan cheese\n* 8 oz (225g) guanciale or pancetta, diced\n* Freshly ground black pepper\n* Salt\n\nHere's a step-by-step guide on how to prepare Spaghetti alla Carbonara:\n\n1. Cook the spaghetti in a large pot of salted boiling water until al dente. Reserve 1 cup of pasta water before draining the pasta.\n\n2. While the pasta is cooking, whisk the eggs, Pecorino Romano, Parmesan, and a generous amount of black pepper in a large bowl.\n\n3. In a large skillet, cook the guanciale or pancetta over medium heat until crispy. Remove the skillet from the heat.\n\n4. Drain the pasta, but do not rinse it. Immediately add the drained pasta to the skillet with the rendered fat from the guanciale or pancetta. Toss the pasta to coat it evenly.\n\n5. Remove the skillet from the heat again. Gradually add the reserved pasta water, 1/2 cup at a time, while continuously tossing the pasta, until the sauce thickens slightly.\n\n6. Slowly pour the egg mixture into the skillet, continuously tossing the pasta to cook the eggs without scrambling them. If the sauce becomes too thick, add more pasta water.\n\n7. Season the pasta with salt, if needed, and serve immediately, garnished with additional grated cheese and black pepper, if desired.\n\nEnjoy your homemade Spaghetti alla Carbonara!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"We can even change language (i.e. switching to Italian) to compare the answers.","metadata":{}},{"cell_type":"code","source":"answer = chatbot(\"Come cucinare gli spaghetti alla carbonara?\")\nprint(answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:26:53.704720Z","iopub.execute_input":"2025-05-10T20:26:53.704957Z","iopub.status.idle":"2025-05-10T20:27:31.170260Z","shell.execute_reply.started":"2025-05-10T20:26:53.704939Z","shell.execute_reply":"2025-05-10T20:27:31.169304Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":" Sì, qui di seguito trovi la ricetta per preparare gli spaghetti alla carbonara:\n\nIngredienti:\n- 400g di spaghetti\n- 100g di guanciale o pancetta tagliata a fettine\n- 4 uova\n- 100g di pecorino romano\n- 50g di parmigiano reggiano\n- Sale e pepe\n- Olio d'oliva\n\nIstruzioni:\n1. Fate bollire una grande casseruola di acqua salata. Aggiungete poi gli spaghetti e fate cuocere secondo le istruzioni sulle confezioni.\n2. Nel frattempo, tagliate il guanciale a fettine e calpestate il pecorino romano.\n3. Prendete una padella e calpestate l'olio d'oliva, il guanciale e il pecorino romano finché non diventano un po' croccanti.\n4. Sia la casseruola con gli spaghetti che la padella con il guanciale e il pecorino romano devono essere caldi.\n5. Prendete un cucchiaio di cottura e prelevate un po' dell'acqua calda in cui gli spaghetti sono bolliti. Aggiungete questa acqua calda alla padella con il guanciale e il pecorino romano.\n6. Spezzate le uova in una ciotola e aggiungete il parmigiano reggiano.\n7. Una volta che gli spaghetti sono al dente, toglieteli dalla casseruola e aggiungeteli alla padella con il guanciale e il pecorino romano.\n8. Mescolate bene gli spaghetti con il guanciale e il pecorino romano, aggiungendo un po' di sale e pepe.\n9. Aggiungete poi le uova e il parmigiano reggiano mescolando bene fino a creare una salsa cremosissima.\n10. Servite subito gli spaghetti alla carbonara caldi.\n\nBuon appetito!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"We can employ the model to better analyse some conditions of the recipe, e.g. if the recipe is vegan or not.","metadata":{}},{"cell_type":"code","source":"answer = chatbot(\"Are spaghetti alla carbonara good for vegans?\", \"You are a friendly but concise chatbot.\")\nprint(answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:27:31.171207Z","iopub.execute_input":"2025-05-10T20:27:31.171514Z","iopub.status.idle":"2025-05-10T20:27:36.838710Z","shell.execute_reply.started":"2025-05-10T20:27:31.171495Z","shell.execute_reply":"2025-05-10T20:27:36.838060Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":" No, traditional spaghetti alla carbonara is not suitable for vegans as it contains ingredients like guanciale (cured pork cheek), Pecorino Romano cheese, and sometimes eggs. A vegan version can be made by substituting the guanciale with smoked tofu or mushrooms, and using a vegan cheese or a plant-based cream.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"And we can see some more peculiar recipes, such as *pizzoccheri valtellinesi*.","metadata":{}},{"cell_type":"code","source":"answer = chatbot(\"Are you able to prepare pizzoccheri valtellinesi?\")\nprint(answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:27:36.839400Z","iopub.execute_input":"2025-05-10T20:27:36.839702Z","iopub.status.idle":"2025-05-10T20:28:08.863787Z","shell.execute_reply.started":"2025-05-10T20:27:36.839684Z","shell.execute_reply":"2025-05-10T20:28:08.863027Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":" While I can't physically prepare food, I can certainly guide you through the process of making Pizzoccheri Valtellinesi, a traditional Italian dish from the Valtellina region. Here's a simplified recipe:\n\nIngredients:\n1. 500g fresh buckwheat pasta (pizzoccheri)\n2. 200g Swiss chard, stems removed and leaves chopped\n3. 200g potatoes, peeled and cubed\n4. 100g cubed Swiss cheese (such as Valtellina Casera)\n5. 100g cubed Italian salami (such as Bergamasca or Cremasco)\n6. 2 tablespoons butter\n7. 2 tablespoons extra-virgin olive oil\n8. 1 onion, finely chopped\n9. Salt\n10. Freshly ground black pepper\n11. Grated Parmesan cheese, for serving\n\nInstructions:\n1. Cook the potatoes in salted boiling water until tender. Drain and set aside.\n2. Bring a large pot of salted water to a boil. Add the pizzoccheri and cook until al dente. Add the Swiss chard leaves to the pot during the last minute of cooking. Drain, reserving some of the pasta water.\n3. In a large skillet, heat the butter and olive oil over medium heat. Add the onion and cook until softened.\n4. Add the cooked potatoes, Swiss chard, and pizzoccheri to the skillet. Toss to combine.\n5. Gradually add some of the reserved pasta water, a little at a time, to help create a sauce.\n6. Add the salami and Swiss cheese, and season with salt and pepper. Cook until the cheese is melted and the sauce has thickened.\n7. Serve hot, topped with additional grated Parmesan cheese.\n\nEnjoy your homemade Pizzoccheri Valtellinesi!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Ok, maybe on not-so-known dishes, such as *pizzoccheri*, we still need to improve...\n\nWhat about giving as reference a webpage containing the description of the receipt?","metadata":{}},{"cell_type":"code","source":"import urllib.request\nimport bs4 as bs\nimport re\n\nhtml_doc = urllib.request.urlopen('https://it.wikipedia.org/wiki/Pizzoccheri_della_Valtellina').read()\nparsed_doc = bs.BeautifulSoup(html_doc,'lxml')\npage = '\\n'.join(p.text for p in parsed_doc.find_all('p'))\nprint(page)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:28:08.864579Z","iopub.execute_input":"2025-05-10T20:28:08.864825Z","iopub.status.idle":"2025-05-10T20:28:09.350014Z","shell.execute_reply.started":"2025-05-10T20:28:08.864800Z","shell.execute_reply":"2025-05-10T20:28:09.349252Z"}},"outputs":[{"name":"stdout","text":"I pizzòccheri della Valtellina (pizzocher in lombardo) sono una varietà di pasta alimentare preparata con farina di grano saraceno miscelata con altri sfarinati. Simili alle tagliatelle, ma di colore grigiastro, i pizzoccheri sono un piatto tradizionale della Valtellina, in particolare di Teglio, e si mangiano sia in Lombardia, in Italia, sia nel cantone svizzero dei Grigioni.\n\nNon devono essere confusi con i pizzoccheri di Chiavenna, che sono invece una particolare varietà di gnocchi, preparati con farina di frumento e pane secco ammollato nel latte. Nel 2016 il prodotto ha ottenuto dall'Unione europea il riconoscimento di indicazione geografica protetta (IGP).[1]\n\nLa prima testimonianza certa sulla coltivazione del grano saraceno (chiamato formentone) in Valtellina risale al 1616, quando il governatore della Valle dell'Adda (appartenente al cantone dei Grigioni in Svizzera) scrisse che «Il saraceno veniva coltivato soprattutto sul versante retico delle Alpi, in particolare nel comprensorio di Teglio, in quanto caratterizzato da un clima più mite grazie a una maggiore esposizione al sole».\n\nIl grano saraceno venne coltivato fino al XIX secolo, diffondendosi anche in aree disagiate e improduttive, poiché tale specie matura in breve tempo ed è molto adatta per i terreni alpini. In seguito, grazie ai maggiori scambi commerciali dovuti all'annessione della Valtellina al Regno Lombardo-Veneto, la produzione di farina di grano saraceno entrò in declino, a favore di altri sfarinati più richiesti dal mercato.\n\nNella provincia di Sondrio, tuttavia, la coltura del grano saraceno è continuata per il consumo famigliare o per la vendita diretta ai consumatori locali.\n\nL'usanza di preparare i pizzoccheri è certamente contemporanea all'introduzione del grano saraceno in Valtellina e in provincia di Sondrio. Le prime fonti indirette si trovano in alcuni antichi testamenti del XVIII secolo, in cui venivano lasciati agli eredi gli attrezzi da cucina, fra cui «una scarella per li Pizzoccheri e il rodelino per li ravioli» (1750) oppure «le resene per li Pizzoccheri» (1775).\n\nI documenti storici attestano che i pizzoccheri della Valtellina sono legati ad eventi, tradizioni ed enogastronomia del luogo d'origine, tanto che il loro condimento tradizionale è preparato con ingredienti locali e tipici (burro, formaggio, verdure quali verze e patate). Nel corso degli anni sono stati organizzati eventi e sagre popolari che celebrano il prodotto: quella più celebre è il \"Pizzocchero d'oro\" a Teglio.\n\nL'etimologia della parola è per il momento dubbia. Il nome \"pizzoccheri\" sembra derivare dalla radice \"pit\" o \"piz\" col significato di pezzetto o ancora dalla parola pinzare col significato di schiacciare, in riferimento alla forma schiacciata della pasta.[2] Altre ipotesi farebbero risalire il termine alla parola “pinzochera” usata già nel '300 da Dante Alighieri e Giovanni Boccaccio, per indicare la povertà e la semplicità, che sono le caratteristiche di questo tipico piatto valtellinese.[3]\n\nIl condimento tipico nella zona del riconoscimento è composto dai seguenti elementi:\n\nDopo aver soffritto l'aglio nel burro, il tutto viene steso a strati in una teglia, i pizzoccheri precedentemente scolati, il tutto deve avvenire a caldo.[4][5]\n\nInfine, in Valtellina, è usanza cospargere i pizzoccheri caldi e fumanti con un'abbondante dose di Pesteda.[6]\n\nLe più comuni varianti prevedono la sostituzione della verza con bietole (dette comunemente anche coste).\n\nAltri progetti\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"document = page[:2000]\nprint(document)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:28:09.350796Z","iopub.execute_input":"2025-05-10T20:28:09.351628Z","iopub.status.idle":"2025-05-10T20:28:09.355453Z","shell.execute_reply.started":"2025-05-10T20:28:09.351607Z","shell.execute_reply":"2025-05-10T20:28:09.354708Z"}},"outputs":[{"name":"stdout","text":"I pizzòccheri della Valtellina (pizzocher in lombardo) sono una varietà di pasta alimentare preparata con farina di grano saraceno miscelata con altri sfarinati. Simili alle tagliatelle, ma di colore grigiastro, i pizzoccheri sono un piatto tradizionale della Valtellina, in particolare di Teglio, e si mangiano sia in Lombardia, in Italia, sia nel cantone svizzero dei Grigioni.\n\nNon devono essere confusi con i pizzoccheri di Chiavenna, che sono invece una particolare varietà di gnocchi, preparati con farina di frumento e pane secco ammollato nel latte. Nel 2016 il prodotto ha ottenuto dall'Unione europea il riconoscimento di indicazione geografica protetta (IGP).[1]\n\nLa prima testimonianza certa sulla coltivazione del grano saraceno (chiamato formentone) in Valtellina risale al 1616, quando il governatore della Valle dell'Adda (appartenente al cantone dei Grigioni in Svizzera) scrisse che «Il saraceno veniva coltivato soprattutto sul versante retico delle Alpi, in particolare nel comprensorio di Teglio, in quanto caratterizzato da un clima più mite grazie a una maggiore esposizione al sole».\n\nIl grano saraceno venne coltivato fino al XIX secolo, diffondendosi anche in aree disagiate e improduttive, poiché tale specie matura in breve tempo ed è molto adatta per i terreni alpini. In seguito, grazie ai maggiori scambi commerciali dovuti all'annessione della Valtellina al Regno Lombardo-Veneto, la produzione di farina di grano saraceno entrò in declino, a favore di altri sfarinati più richiesti dal mercato.\n\nNella provincia di Sondrio, tuttavia, la coltura del grano saraceno è continuata per il consumo famigliare o per la vendita diretta ai consumatori locali.\n\nL'usanza di preparare i pizzoccheri è certamente contemporanea all'introduzione del grano saraceno in Valtellina e in provincia di Sondrio. Le prime fonti indirette si trovano in alcuni antichi testamenti del XVIII secolo, in cui venivano lasciati agli eredi gli attrezzi da cucina, fra cui «una scarella per li Piz\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"question = \"How to cook pizzoccheri della Valtellina?\"\n\nuser_request = \"Answer the user question: '\" + question + \"' \\n\\n based on the information in the document: \\n```\\n\" + document + \"\\n```\\n\\n\"\nanswer = chatbot(user_request)\nprint(answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:28:09.356278Z","iopub.execute_input":"2025-05-10T20:28:09.356491Z","iopub.status.idle":"2025-05-10T20:28:56.711413Z","shell.execute_reply.started":"2025-05-10T20:28:09.356475Z","shell.execute_reply":"2025-05-10T20:28:56.710591Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":" To cook Pizzoccheri della Valtellina, you'll need the specialty pasta made from Saraceno wheat flour, which is mixed with other types of flour. The pasta resembles tagliatelle but has a grayish color. Here's a traditional recipe:\n\nIngredients:\n- 500g of Pizzoccheri pasta\n- 200g of Swiss chard (or other leafy greens)\n- 200g of potatoes\n- 100g of cubed, smoked, Valtellina ham (Casera or Bitto)\n- 100g of cubed, smoked, Valtellina cheese (Casera or Bitto)\n- 4 tablespoons of butter\n- 2 tablespoons of extra virgin olive oil\n- Salt, to taste\n- Pepper, to taste\n- 2 cloves of garlic\n- 1 onion\n- 1 glass of white wine\n- 1 liter of broth (vegetable or meat)\n\nInstructions:\n1. Boil the potatoes in salted water until tender. Once cooked, peel them and cut into small cubes.\n2. Clean the Swiss chard, removing the stems and chopping the leaves.\n3. In a large pan, heat the butter and olive oil over medium heat. Add the garlic and onion, sauté until softened.\n4. Add the Swiss chard leaves to the pan, cook until wilted.\n5. Add the white wine to the pan and let it reduce for a few minutes.\n6. Add the broth to the pan and bring to a simmer.\n7. Cook the Pizzoccheri pasta in salted boiling water until al dente.\n8. Drain the pasta, reserving some of the cooking water.\n9. Add the cooked pasta, potatoes, ham, and cheese to the pan with the sauce. Toss everything together, adding some of the reserved pasta water if needed to achieve the desired consistency.\n10. Season with salt and pepper, to taste.\n11. Serve hot, garnished with grated cheese if desired.\n\nEnjoy your homemade Pizzoccheri della Valtellina!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"Ok, a bit better!","metadata":{}},{"cell_type":"code","source":"# Since the original model (and the tokenizer) is not needed anymore, we can delete it.\ndel model\ndel tokenizer\n\n# Clear GPU cache\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:28:56.712292Z","iopub.execute_input":"2025-05-10T20:28:56.712580Z","iopub.status.idle":"2025-05-10T20:28:56.734132Z","shell.execute_reply.started":"2025-05-10T20:28:56.712554Z","shell.execute_reply":"2025-05-10T20:28:56.733587Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Load a Quantized Model\nhttps://medium.com/@vishnuchirukandathramesh/how-to-run-mistral-7b-on-free-version-of-google-colab-e0effd9c6a12","metadata":{}},{"cell_type":"markdown","source":"First, let's install the necessary packages and import the following libraries.","metadata":{}},{"cell_type":"code","source":"!pip install -q -U langchain  # transformers bitsandbytes accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:28:56.734839Z","iopub.execute_input":"2025-05-10T20:28:56.735040Z","iopub.status.idle":"2025-05-10T20:29:03.951856Z","shell.execute_reply.started":"2025-05-10T20:28:56.735017Z","shell.execute_reply":"2025-05-10T20:29:03.950924Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.7/437.7 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"!pip install -q langchain-community langchain-core","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:29:03.952990Z","iopub.execute_input":"2025-05-10T20:29:03.953347Z","iopub.status.idle":"2025-05-10T20:29:09.551705Z","shell.execute_reply.started":"2025-05-10T20:29:03.953303Z","shell.execute_reply":"2025-05-10T20:29:09.550801Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import torch\nfrom transformers import BitsAndBytesConfig\nfrom langchain import HuggingFacePipeline, PromptTemplate, LLMChain\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:29:09.552873Z","iopub.execute_input":"2025-05-10T20:29:09.553330Z","iopub.status.idle":"2025-05-10T20:29:10.482912Z","shell.execute_reply.started":"2025-05-10T20:29:09.553296Z","shell.execute_reply":"2025-05-10T20:29:10.482388Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"The quantization configuration specifies settings for loading a model in 4-bit precision, utilizing torch.float16 for computation, with “nf4” quantization type and double quantization enabled, aiming to enhance efficiency and reduce memory footprint during model deployment.","metadata":{}},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:29:10.483598Z","iopub.execute_input":"2025-05-10T20:29:10.483811Z","iopub.status.idle":"2025-05-10T20:29:10.489190Z","shell.execute_reply.started":"2025-05-10T20:29:10.483793Z","shell.execute_reply":"2025-05-10T20:29:10.488313Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"Then, load the quantized model.","metadata":{}},{"cell_type":"code","source":"model_4bit = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\",quantization_config=quantization_config, )\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:29:10.490004Z","iopub.execute_input":"2025-05-10T20:29:10.490559Z","iopub.status.idle":"2025-05-10T20:29:40.445454Z","shell.execute_reply.started":"2025-05-10T20:29:10.490541Z","shell.execute_reply":"2025-05-10T20:29:40.444669Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f13cd2b0ad744d078c7bb1b7bd59f956"}},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"model_4bit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:29:40.446461Z","iopub.execute_input":"2025-05-10T20:29:40.447092Z","iopub.status.idle":"2025-05-10T20:29:40.453251Z","shell.execute_reply.started":"2025-05-10T20:29:40.447065Z","shell.execute_reply":"2025-05-10T20:29:40.452511Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"MistralForCausalLM(\n  (model): MistralModel(\n    (embed_tokens): Embedding(32768, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x MistralDecoderLayer(\n        (self_attn): MistralAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n        )\n        (mlp): MistralMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): MistralRMSNorm((4096,), eps=1e-05)\n    (rotary_emb): MistralRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n)"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"The code sets up a text generation pipeline using Mistral-7B-Instruct-v0.3 model loaded in 4-bit precision, along with its corresponding tokenizer, enabling caching and automatic device mapping. It configures the generation parameters such as maximum length, sampling, top-k sampling, and number of returned sequences. Additionally, it initializes a LangChain HuggingFacePipeline for streamlined text generation tasks.","metadata":{}},{"cell_type":"code","source":"pipeline_inst = pipeline(\n        \"text-generation\",\n        model=model_4bit,\n        tokenizer=tokenizer,\n        use_cache=True,\n        device_map=\"auto\",\n        max_length=2500,\n        truncation=True,\n        do_sample=True,\n        top_k=5,\n        num_return_sequences=1,\n        eos_token_id=tokenizer.eos_token_id,\n        pad_token_id=tokenizer.eos_token_id,\n)\n\nllm = HuggingFacePipeline(pipeline=pipeline_inst)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:29:40.453897Z","iopub.execute_input":"2025-05-10T20:29:40.454060Z","iopub.status.idle":"2025-05-10T20:29:40.470454Z","shell.execute_reply.started":"2025-05-10T20:29:40.454046Z","shell.execute_reply":"2025-05-10T20:29:40.469853Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n/tmp/ipykernel_31/2658258502.py:16: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n  llm = HuggingFacePipeline(pipeline=pipeline_inst)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"template = \"\"\"You are an respectful and helpful cooking assistant, respond always and be precise and polite.\nAnswer the question below: {question}\nAnswer:\n\"\"\"\n\ndef generate_response(question):\n    prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n    llm_chain = LLMChain(prompt=prompt, llm=llm)\n    response = llm_chain.run({\"question\": question})\n    return response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:31:31.727324Z","iopub.execute_input":"2025-05-10T20:31:31.727622Z","iopub.status.idle":"2025-05-10T20:31:31.732080Z","shell.execute_reply.started":"2025-05-10T20:31:31.727600Z","shell.execute_reply":"2025-05-10T20:31:31.731362Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"output = generate_response(\"How to prepare spaghetti alla carbonara for 2 people?\")\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:31:33.719251Z","iopub.execute_input":"2025-05-10T20:31:33.719962Z","iopub.status.idle":"2025-05-10T20:32:02.929039Z","shell.execute_reply.started":"2025-05-10T20:31:33.719936Z","shell.execute_reply":"2025-05-10T20:32:02.928163Z"}},"outputs":[{"name":"stdout","text":"You are an respectful and helpful cooking assistant, respond always and be precise and polite.\nAnswer the question below: How to prepare spaghetti alla carbonara for 2 people?\nAnswer:\nTo prepare Spaghetti alla Carbonara for 2 people, gather the following ingredients:\n- 200 grams of spaghetti\n- 2 large eggs\n- 100 grams of guanciale (Italian cured pork cheeks) or pancetta (Italian bacon), cut into small pieces\n- 80 grams of freshly grated Pecorino Romano cheese\n- 30 grams of freshly grated Parmesan cheese\n- Freshly ground black pepper to taste\n- Salt for the pasta water\n\nInstructions:\n1. Boil a large pot of salted water for the pasta. Cook the spaghetti according to the package instructions until al dente. Reserve 1 cup of pasta water and drain the pasta.\n\n2. While the pasta cooks, combine the eggs, Pecorino Romano cheese, and a generous amount of black pepper in a large bowl. Mix until well combined.\n\n3. In a large skillet, cook the guanciale or pancetta over medium heat until crispy, about 4-5 minutes. Remove the skillet from the heat.\n\n4. Carefully add the drained pasta to the skillet with the crispy guanciale. Toss the pasta to coat with the rendered fat.\n\n5. Off the heat, quickly add about 1/2 cup of the reserved pasta water to the skillet and immediately remove from heat. Stir the pasta to distribute the water.\n\n6. Transfer the pasta to the bowl with the egg-cheese mixture. Toss the pasta to coat evenly with the mixture. The warmth of the pasta will cook the eggs slightly.\n\n7. If the pasta looks too dry, add more reserved pasta water as needed. Serve the Spaghetti alla Carbonara immediately, garnished with additional grated cheese and freshly ground black pepper.\n\nEnjoy your meal! Buon appetito!\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Clear GPU cache\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:32:02.930386Z","iopub.execute_input":"2025-05-10T20:32:02.930619Z","iopub.status.idle":"2025-05-10T20:32:02.943745Z","shell.execute_reply.started":"2025-05-10T20:32:02.930601Z","shell.execute_reply":"2025-05-10T20:32:02.943084Z"}},"outputs":[],"execution_count":31}]}