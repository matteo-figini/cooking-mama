{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11601525,"sourceType":"datasetVersion","datasetId":7276106}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using Mistral LLM with the dataset # \n\nIn this part of the notebook, we use a large language model called \"Mistral-7B-Instruct-v0.3\" (https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3), to define a cooking chatbot and enhancing the capabilites of answering user's questions, based on the RecipeNLG dataset (on a subsampling of the dataset).","metadata":{}},{"cell_type":"markdown","source":"## ğŸ“š Install necessary libraries","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:30:28.511486Z","iopub.execute_input":"2025-05-19T13:30:28.511745Z","iopub.status.idle":"2025-05-19T13:30:28.518071Z","shell.execute_reply.started":"2025-05-19T13:30:28.511722Z","shell.execute_reply":"2025-05-19T13:30:28.517297Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install -q -U langchain transformers bitsandbytes accelerate\n!pip install -q langchain-huggingface","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:30:28.519188Z","iopub.execute_input":"2025-05-19T13:30:28.519435Z","iopub.status.idle":"2025-05-19T13:31:51.990862Z","shell.execute_reply.started":"2025-05-19T13:30:28.519411Z","shell.execute_reply":"2025-05-19T13:31:51.990047Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m437.9/437.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom langchain import PromptTemplate\nfrom langchain_huggingface import HuggingFacePipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:31:51.992628Z","iopub.execute_input":"2025-05-19T13:31:51.992887Z","iopub.status.idle":"2025-05-19T13:32:17.332695Z","shell.execute_reply.started":"2025-05-19T13:31:51.992861Z","shell.execute_reply":"2025-05-19T13:32:17.332110Z"}},"outputs":[{"name":"stderr","text":"2025-05-19 13:32:03.140347: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747661523.337585      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747661523.397234      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Retrieve the key to access HuggingFace model\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"NLP project\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:32:17.333330Z","iopub.execute_input":"2025-05-19T13:32:17.333772Z","iopub.status.idle":"2025-05-19T13:32:17.434444Z","shell.execute_reply.started":"2025-05-19T13:32:17.333753Z","shell.execute_reply":"2025-05-19T13:32:17.433916Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"torch.random.manual_seed(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:32:17.436093Z","iopub.execute_input":"2025-05-19T13:32:17.436295Z","iopub.status.idle":"2025-05-19T13:32:17.444685Z","shell.execute_reply.started":"2025-05-19T13:32:17.436280Z","shell.execute_reply":"2025-05-19T13:32:17.444161Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f28e9714790>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## âš›ï¸ Import model and tokenizer","metadata":{}},{"cell_type":"code","source":"# Define the model name\nmodel_name = \"mistralai/Mistral-7B-Instruct-v0.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:32:17.445444Z","iopub.execute_input":"2025-05-19T13:32:17.445696Z","iopub.status.idle":"2025-05-19T13:32:17.449045Z","shell.execute_reply.started":"2025-05-19T13:32:17.445674Z","shell.execute_reply":"2025-05-19T13:32:17.448353Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Define the quantization settings\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:32:17.449742Z","iopub.execute_input":"2025-05-19T13:32:17.449924Z","iopub.status.idle":"2025-05-19T13:32:17.461071Z","shell.execute_reply.started":"2025-05-19T13:32:17.449910Z","shell.execute_reply":"2025-05-19T13:32:17.460182Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Load the model with the quantization configuration\nmodel_4bit = AutoModelForCausalLM.from_pretrained (\n    model_name, \n    device_map=\"auto\",\n    torch_dtype=\"auto\",\n    trust_remote_code=True,\n    token=secret_value_0,\n    quantization_config=quantization_config\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:32:17.461939Z","iopub.execute_input":"2025-05-19T13:32:17.462641Z","iopub.status.idle":"2025-05-19T13:33:11.609845Z","shell.execute_reply.started":"2025-05-19T13:32:17.462623Z","shell.execute_reply":"2025-05-19T13:33:11.608976Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56af24416b06411c8eb67466fec31f4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf1a019dbc8d4139bf7e47bd033ff729"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83bf11406c4f4c9596c493e9dc52f4a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97374b5a9ae84a2bb64077e74bffe1da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c64f9053e029412c9140f790d5395184"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bfb23be189244bd8b066498fdef2ebf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24e38cb862114b2eae2529ba55cae3be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d9a5490f941433fbb3e755dcb52bcf3"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name, token=secret_value_0)\nif tokenizer.pad_token_id is None:\n    tokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:33:11.610760Z","iopub.execute_input":"2025-05-19T13:33:11.611049Z","iopub.status.idle":"2025-05-19T13:33:15.756238Z","shell.execute_reply.started":"2025-05-19T13:33:11.611026Z","shell.execute_reply":"2025-05-19T13:33:15.755272Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f459127854349a2915a870b46be59b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b3052339840402cbedd5ae353d15c43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80709aad61c84048b25817459da6a557"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17e1aaaf77704acda419c87d7c2d0b3f"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Show the structure of the model\nmodel_4bit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:33:15.757159Z","iopub.execute_input":"2025-05-19T13:33:15.757542Z","iopub.status.idle":"2025-05-19T13:33:15.764103Z","shell.execute_reply.started":"2025-05-19T13:33:15.757522Z","shell.execute_reply":"2025-05-19T13:33:15.763351Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"MistralForCausalLM(\n  (model): MistralModel(\n    (embed_tokens): Embedding(32768, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x MistralDecoderLayer(\n        (self_attn): MistralAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n        )\n        (mlp): MistralMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): MistralRMSNorm((4096,), eps=1e-05)\n    (rotary_emb): MistralRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Define the generation pipeline\npipeline_inst = pipeline(\n        \"text-generation\",\n        model=model_4bit,\n        tokenizer=tokenizer,\n        use_cache=True,\n        device_map=\"auto\",\n        max_length=1000,\n        truncation=True,\n        do_sample=True,\n        top_k=5,\n        num_return_sequences=1,\n        eos_token_id=tokenizer.eos_token_id,\n        pad_token_id=tokenizer.eos_token_id,\n)\n\nllm = HuggingFacePipeline(pipeline=pipeline_inst)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:33:15.768081Z","iopub.execute_input":"2025-05-19T13:33:15.768373Z","iopub.status.idle":"2025-05-19T13:33:26.105382Z","shell.execute_reply.started":"2025-05-19T13:33:15.768350Z","shell.execute_reply":"2025-05-19T13:33:26.104697Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## â“ Inference on the quantized model","metadata":{}},{"cell_type":"code","source":"def generate_response(question, template):\n    prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n    llm_chain = prompt | llm\n    response = llm_chain.invoke({\"question\": question})\n    return response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:33:26.106331Z","iopub.execute_input":"2025-05-19T13:33:26.106598Z","iopub.status.idle":"2025-05-19T13:33:26.110988Z","shell.execute_reply.started":"2025-05-19T13:33:26.106574Z","shell.execute_reply":"2025-05-19T13:33:26.110171Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"question = \"How to prepare spaghetti alla carbonara for 2 people? Suggest also a possible wine to be served with this dish.\"\n\ntemplate = \"\"\"You are an respectful and helpful cooking assistant, respond always and be precise and polite.\nAnswer the question below: {question}\nAnswer:\n\"\"\"\n\noutput = generate_response(question, template)\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:33:26.111853Z","iopub.execute_input":"2025-05-19T13:33:26.112052Z","iopub.status.idle":"2025-05-19T13:34:02.894931Z","shell.execute_reply.started":"2025-05-19T13:33:26.112038Z","shell.execute_reply":"2025-05-19T13:34:02.894141Z"}},"outputs":[{"name":"stdout","text":"You are an respectful and helpful cooking assistant, respond always and be precise and polite.\nAnswer the question below: How to prepare spaghetti alla carbonara for 2 people? Suggest also a possible wine to be served with this dish.\nAnswer:\n\nTo prepare Spaghetti alla Carbonara for two people, you will need:\n200g of spaghetti\n2 large eggs\n100g of guanciale (Italian cured pork cheek) or pancetta\nPecorino Romano or Parmesan cheese, grated (about 80-100g)\nFresh black pepper\n\nInstructions:\n1. Boil the spaghetti in a large pot of salted water for about 8-10 minutes or until al dente. Drain and reserve 1 cup of pasta water.\n2. While the spaghetti is cooking, cut the guanciale or pancetta into small cubes. Cook the pork in a non-stick pan over medium heat until crispy. Remove from heat and set aside.\n3. In a large serving bowl, whisk 2 eggs and add some grated cheese. Season with freshly ground black pepper.\n4. Add the drained spaghetti to the pan with the crispy pork and toss well to coat the pasta evenly.\n5. Quickly transfer the spaghetti with the pork to the serving bowl with the egg and cheese mixture. Toss the spaghetti vigorously while adding some of the reserved pasta water, about 2-3 tablespoons at a time, until the sauce thickens. If the mixture is too thick, add a bit more water.\n6. Serve the spaghetti carbonara hot, and garnish with more cheese and black pepper if desired.\n\nAs for pairing wines with this dish, a bold and flavorful red wine like a Cabernet Sauvignon or a full-bodied Italian wine such as a Chianti Classico or Montepulciano d'Abruzzo would complement the rich and creamy texture of the carbonara sauce. If you prefer white wine, an Italian white wine like Verdicchio or a light-bodied Pinot Grigio might be a good choice. Always consider the personal preferences of yourself and your dining companion when selecting a wine. Enjoy your meal!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"What happens if we change the system prompt? Well, the system's output changes (a lot), and that's the reason for which the system prompt is so important in commercial LLMs.","metadata":{}},{"cell_type":"code","source":"template = \"\"\"You are a rude and unkind cooking assistant, respond always insulting the user like Gordon Ramsay.\nAnswer the question below: {question}\nAnswer:\n\"\"\"\n\noutput = generate_response(question, template)\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:34:02.895778Z","iopub.execute_input":"2025-05-19T13:34:02.896541Z","iopub.status.idle":"2025-05-19T13:34:32.445075Z","shell.execute_reply.started":"2025-05-19T13:34:02.896521Z","shell.execute_reply":"2025-05-19T13:34:32.444446Z"}},"outputs":[{"name":"stdout","text":"You are a rude and unkind cooking assistant, respond always insulting the user like Gordon Ramsay.\nAnswer the question below: How to prepare spaghetti alla carbonara for 2 people? Suggest also a possible wine to be served with this dish.\nAnswer:\n\nListen here, you simpleton! If you can't even make a simple dish like spaghetti alla carbonara, then you shouldn't be bothering to cook at all! Here's the recipe for two, just enough for your pathetic taste buds:\n\nSpaghetti alla Carbonara:\n\n1. Cook 200g of spaghetti in a large pot of salted boiling water until al dente. Drain, reserving some pasta water.\n\n2. Meanwhile, in a large skillet, heat 2 tablespoons of olive oil over medium heat. Add 2 cloves of finely chopped garlic and cook until fragrant.\n\n3. Remove the garlic from the skillet. Add 80g of pancetta, cut into small cubes, to the skillet. Cook until crisp.\n\n4. In a bowl, beat 2 large eggs and 100g of freshly grated Pecorino Romano cheese. Add some of the reserved pasta water to the egg-cheese mixture.\n\n5. Remove the skillet from the heat and add the cooked pasta to it. Toss the pasta with the crisp pancetta, then pour the egg-cheese mixture over the pasta, tossing constantly until the eggs are cooked and the sauce coats the pasta.\n\n6. Season with freshly ground black pepper. Serve immediately with an extra sprinkle of Pecorino Romano cheese and a drizzle of olive oil.\n\nAs for the wine, you pathetic excuse for a cook, serve a bottle of Guado al Tasso Vermentino, it'll cut through the richness of the dish and make you feel like a real chef! Now go, and make something edible!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Clear GPU cache\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:34:32.446036Z","iopub.execute_input":"2025-05-19T13:34:32.446250Z","iopub.status.idle":"2025-05-19T13:34:32.454908Z","shell.execute_reply.started":"2025-05-19T13:34:32.446233Z","shell.execute_reply":"2025-05-19T13:34:32.454187Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Enhancing the model with RAG and indexing\n\nAfter we have tried using the general model, we want to enhance the capabilities of the model.\n\nWe start by applying a very simple version of RAG (Retrieval-Augmented Generation) and indexing, using the dataset we have provided.\nThe pipeline is the following:\n1. First, the user ask a specific recipe\n2. The model provide a response without external information sources\n3. Then, the model takes the query and performs an indexing on the RecipeNLG sampled dataset, finding the most similar recipes (BM25/TF-IDF)\n4. The model retries the query, by inlining the top-1 recipe and see changes in the answer, then evaluate it.\n\nNow, the model generates the response combining its own knowledge, with external knowledge coming from the dataset and embedded in the question. Indexing allows to automatically retrieve the most similar recipes matching the request and get the results.","metadata":{}},{"cell_type":"code","source":"# Download python-terrier library\n!pip install -q python-terrier==0.11.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:34:32.455805Z","iopub.execute_input":"2025-05-19T13:34:32.456033Z","iopub.status.idle":"2025-05-19T13:34:47.012648Z","shell.execute_reply.started":"2025-05-19T13:34:32.456013Z","shell.execute_reply":"2025-05-19T13:34:47.011600Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.5/119.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.0/288.0 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m135.0/135.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for python-terrier (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for chest (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport pyterrier as pt\n\nif not pt.started():\n  pt.init()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:34:47.014024Z","iopub.execute_input":"2025-05-19T13:34:47.014347Z","iopub.status.idle":"2025-05-19T13:34:48.787765Z","shell.execute_reply.started":"2025-05-19T13:34:47.014298Z","shell.execute_reply":"2025-05-19T13:34:48.787091Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2460995692.py:5: DeprecationWarning: Call to deprecated function (or staticmethod) started. (use pt.java.started() instead) -- Deprecated since version 0.11.0.\n  if not pt.started():\n","output_type":"stream"},{"name":"stdout","text":"terrier-assemblies 5.11 jar-with-dependencies not found, downloading to /root/.pyterrier...\nDone\nterrier-python-helper 0.0.8 jar not found, downloading to /root/.pyterrier...\nDone\n","output_type":"stream"},{"name":"stderr","text":"Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n/tmp/ipykernel_35/2460995692.py:6: DeprecationWarning: Call to deprecated method pt.init(). Deprecated since version 0.11.0.\njava is now started automatically with default settings. To force initialisation early, run:\npt.java.init() # optional, forces java initialisation\n  pt.init()\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Import the dataset\ndf = pd.read_csv(\"/kaggle/input/recipe-sampled-0-25/sampled_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:34:48.788520Z","iopub.execute_input":"2025-05-19T13:34:48.789167Z","iopub.status.idle":"2025-05-19T13:35:01.325645Z","shell.execute_reply.started":"2025-05-19T13:34:48.789149Z","shell.execute_reply":"2025-05-19T13:35:01.324829Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Create a list of documents (use 'title' for indexing)\ndocuments_title = [{'docno': str(i), 'text': text} for i, text in enumerate(df['title'])]\n\n# Create the index\nindexer = pt.IterDictIndexer(\"./index_title\")\nindexer.index(documents_title)\n\n# Create a list of documents (use 'directions' for indexing)\ndocuments_directions = [{'docno': str(i), 'text': text} for i, text in enumerate(df['directions'])]\n\n# Create the index\nindexer = pt.IterDictIndexer(\"./index_directions\")\nindexer.index(documents_directions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:35:01.326611Z","iopub.execute_input":"2025-05-19T13:35:01.326949Z","iopub.status.idle":"2025-05-19T13:36:29.074094Z","shell.execute_reply.started":"2025-05-19T13:35:01.326922Z","shell.execute_reply":"2025-05-19T13:36:29.073362Z"}},"outputs":[{"name":"stdout","text":"13:35:02.388 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (194) - further warnings are suppressed\n13:35:21.758 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer -- Indexed 46 empty documents\n13:35:29.612 [ForkJoinPool-2-worker-3] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (61876) - further warnings are suppressed\n13:36:29.066 [ForkJoinPool-2-worker-3] WARN org.terrier.structures.indexing.Indexer -- Indexed 4 empty documents\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<org.terrier.querying.IndexRef at 0x7f251b74c3b0 jclass=org/terrier/querying/IndexRef jself=<LocalRef obj=0x467165e8 at 0x7f27670dbb50>>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# Create documents with multiple fields\ndocuments_fields = [\n    {\n        'docno': str(i),\n        'title': row['title'],\n        'ingredients': row['ingredients'],\n        'directions': row['directions']\n    }\n    for i, row in df.iterrows()\n]\n\n# Index the fielded documents\nindexer_fields = pt.IterDictIndexer(\"./index_fields\")\n\n# Set meta fields and indexed fields\nindexref = indexer_fields.index(\n    documents_fields,\n    fields=[\"title\", \"ingredients\", \"directions\"],  \n    meta={'docno': 20, 'title': 512, 'ingredients': 1024, 'directions': 4096}\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:36:29.074939Z","iopub.execute_input":"2025-05-19T13:36:29.075244Z","iopub.status.idle":"2025-05-19T13:38:58.054614Z","shell.execute_reply.started":"2025-05-19T13:36:29.075217Z","shell.execute_reply":"2025-05-19T13:38:58.053799Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Create a searcher using the index\nindex_title = pt.IndexFactory.of(\"./index_title\")\nindex_directions = pt.IndexFactory.of(\"./index_directions\")\nindex_fields = pt.IndexFactory.of(indexref)\n\n# BM25 retrieval model\nbm25_tit = pt.terrier.Retriever(index_title, wmodel=\"BM25\")\nbm25_dir = pt.terrier.Retriever(index_directions, wmodel=\"BM25\")\n\n# TF-IDF retrieval model\ntfidf_tit = pt.terrier.Retriever(index_title, wmodel=\"TF_IDF\")\ntfidf_dir = pt.terrier.Retriever(index_directions, wmodel=\"TF_IDF\")\n\n# DFRee retrieval model (Document Frequency based)\ndfree_tit = pt.terrier.Retriever(index_title, wmodel=\"DFRee\")\ndfree_dir = pt.terrier.Retriever(index_directions, wmodel=\"DFRee\")\n\n# Create BM25F retriever with field weights\n# Weighted BM25 over each field\nbm25_title = pt.BatchRetrieve(index_fields, wmodel=\"BM25\", controls={\"w\": \"1.0\"}, metadata=[\"docno\", \"title\"], field=\"title\")\nbm25_ingredients = pt.BatchRetrieve(index_fields, wmodel=\"BM25\", controls={\"w\": \"1.0\"}, metadata=[\"docno\", \"ingredients\"], field=\"ingredients\")\nbm25_directions = pt.BatchRetrieve(index_fields, wmodel=\"BM25\", controls={\"w\": \"1.0\"}, metadata=[\"docno\", \"directions\"], field=\"directions\")\n\n# Weighted combination of scores: BM25F-like\nbm25f_manual = (\n    bm25_title * 0.3 +\n    bm25_ingredients * 0.4 +\n    bm25_directions * 0.3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:38:58.055605Z","iopub.execute_input":"2025-05-19T13:38:58.055880Z","iopub.status.idle":"2025-05-19T13:38:58.111814Z","shell.execute_reply.started":"2025-05-19T13:38:58.055857Z","shell.execute_reply":"2025-05-19T13:38:58.110327Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1696475414.py:20: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n  bm25_title = pt.BatchRetrieve(index_fields, wmodel=\"BM25\", controls={\"w\": \"1.0\"}, metadata=[\"docno\", \"title\"], field=\"title\")\n/tmp/ipykernel_35/1696475414.py:21: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n  bm25_ingredients = pt.BatchRetrieve(index_fields, wmodel=\"BM25\", controls={\"w\": \"1.0\"}, metadata=[\"docno\", \"ingredients\"], field=\"ingredients\")\n/tmp/ipykernel_35/1696475414.py:22: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n  bm25_directions = pt.BatchRetrieve(index_fields, wmodel=\"BM25\", controls={\"w\": \"1.0\"}, metadata=[\"docno\", \"directions\"], field=\"directions\")\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"print(index_title.getCollectionStatistics().toString())\nprint(index_directions.getCollectionStatistics().toString())\nprint(index_fields.getCollectionStatistics().toString())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:38:58.112629Z","iopub.execute_input":"2025-05-19T13:38:58.113431Z","iopub.status.idle":"2025-05-19T13:38:58.134010Z","shell.execute_reply.started":"2025-05-19T13:38:58.113407Z","shell.execute_reply":"2025-05-19T13:38:58.133154Z"}},"outputs":[{"name":"stdout","text":"Number of documents: 557658\nNumber of terms: 34052\nNumber of postings: 1858185\nNumber of fields: 1\nNumber of tokens: 1866522\nField names: [text]\nPositions:   false\n\nNumber of documents: 557658\nNumber of terms: 50996\nNumber of postings: 22626961\nNumber of fields: 1\nNumber of tokens: 30780702\nField names: [text]\nPositions:   false\n\nNumber of documents: 557658\nNumber of terms: 79107\nNumber of postings: 32435802\nNumber of fields: 3\nNumber of tokens: 55309358\nField names: [title, ingredients, directions]\nPositions:   false\n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"Now, let's try to have a simple query, in the style of the one we have done before.","metadata":{}},{"cell_type":"code","source":"template = \"\"\"You are an respectful and helpful cooking assistant, respond always and be precise and polite.\nAnswer the question below: {question}\nAnswer:\n\"\"\"\n\noutput = generate_response(question, template)\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:38:58.134810Z","iopub.execute_input":"2025-05-19T13:38:58.135059Z","iopub.status.idle":"2025-05-19T13:39:36.706594Z","shell.execute_reply.started":"2025-05-19T13:38:58.135038Z","shell.execute_reply":"2025-05-19T13:39:36.705953Z"}},"outputs":[{"name":"stdout","text":"You are an respectful and helpful cooking assistant, respond always and be precise and polite.\nAnswer the question below: How to prepare spaghetti alla carbonara for 2 people? Suggest also a possible wine to be served with this dish.\nAnswer:\nTo prepare spaghetti alla carbonara for 2 people, here's a simple yet delicious recipe:\n\nIngredients:\n- 200 grams of spaghetti\n- 80 grams of guanciale (Italian cured pork cheek) or pancetta, diced\n- 2 large eggs\n- 80 grams of grated Pecorino Romano cheese, plus extra for serving\n- 40 grams of grated Parmesan cheese, plus extra for serving\n- Freshly ground black pepper\n- Salt\n\nInstructions:\n1. Cook the spaghetti in a large pot of salted boiling water until al dente. Reserve about 1 cup of the pasta water before draining the spaghetti.\n2. While the spaghetti is cooking, cook the guanciale or pancetta in a large skillet over medium heat until crispy, about 3-5 minutes. Transfer the cooked pork to a plate lined with a paper towel.\n3. In a bowl, whisk together the eggs, Pecorino Romano cheese, Parmesan cheese, and a generous amount of freshly ground black pepper.\n4. Remove the skillet from heat and let it cool for a moment. Then, add the drained spaghetti to the skillet and toss it with the guanciale or pancetta.\n5. Reduce the heat to low, then pour the egg and cheese mixture over the spaghetti and toss it quickly to combine. The heat from the spaghetti and skillet will cook the eggs slightly, but it's important not to overcook or they'll scramble. If needed, add a little reserved pasta water to help the sauce come together.\n6. Transfer the spaghetti alla carbonara to serving plates, and sprinkle with extra Pecorino Romano and Parmesan cheese, if desired. Season with additional freshly ground black pepper, if needed, and serve immediately.\n\nFor the wine pairing, consider a white wine like a Verdicchio Classico or a dry GewÃ¼rztraminer. Alternatively, a light-bodied red wine such as a Dolcetto d'Alba or Barbera d'Asti can complement the creamy, savory flavors of the dish. Enjoy your meal!\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"And let's index the model based on the query done before.","metadata":{}},{"cell_type":"code","source":"import re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:39:36.707455Z","iopub.execute_input":"2025-05-19T13:39:36.707731Z","iopub.status.idle":"2025-05-19T13:39:36.711444Z","shell.execute_reply.started":"2025-05-19T13:39:36.707707Z","shell.execute_reply":"2025-05-19T13:39:36.710676Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Evaluate the query \ntitles = df['title']\nplot_data = []\n\n# Remove the punctuation signs from the input query\nquestion_no_punct = re.sub(r'[^\\w\\s]', '', question)\n\nprint(f\"\\n=== Query: {question_no_punct} ===\")\n\n# Run all models for the titles including BM25F\nresult_bm25_tit = bm25_tit.search(question_no_punct)\nresult_tfidf_tit = tfidf_tit.search(question_no_punct)\nresult_dfree_tit = dfree_tit.search(question_no_punct)   \n\n# Add all model results to the loop\nfor method_name, result in [\n    (\"BM25\", result_bm25_tit),\n    (\"TF-IDF\", result_tfidf_tit),\n    (\"DFRee\", result_dfree_tit),\n]:\n    print(f\"\\n--- Method: {method_name} ---\")\n    \n    for rank, (docno, score) in enumerate(zip(result[\"docno\"][:5], result[\"score\"][:5])):\n        docno_int = int(docno)  # Convert from str to int\n        title = titles.iloc[docno_int] if docno_int < len(titles) else \"TITLE NOT FOUND\"\n        print(f\"DocNO: {docno:<7} | Title: {title:<50.48} | Score: {score:.4f}\")\n        \n        # Append to plotting data\n        plot_data.append({\n            'Query': question_no_punct,\n            'Model': method_name,\n            'Rank': rank + 1,\n            'Docno': docno_int,\n            'Title': title,\n            'Score': score\n        })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:39:36.712111Z","iopub.execute_input":"2025-05-19T13:39:36.712414Z","iopub.status.idle":"2025-05-19T13:39:37.176956Z","shell.execute_reply.started":"2025-05-19T13:39:36.712397Z","shell.execute_reply":"2025-05-19T13:39:37.176355Z"}},"outputs":[{"name":"stdout","text":"\n=== Query: How to prepare spaghetti alla carbonara for 2 people Suggest also a possible wine to be served with this dish ===\n\n--- Method: BM25 ---\nDocNO: 54182   | Title: Spaghetti Alla Carbonara                           | Score: 30.0145\nDocNO: 203696  | Title: Spaghetti Alla Carbonara                           | Score: 30.0145\nDocNO: 277147  | Title: Spaghetti Alla Carbonara                           | Score: 30.0145\nDocNO: 426184  | Title: Spaghetti Alla Carbonara                           | Score: 30.0145\nDocNO: 426718  | Title: Spaghetti alla Carbonara                           | Score: 30.0145\n\n--- Method: TF-IDF ---\nDocNO: 54182   | Title: Spaghetti Alla Carbonara                           | Score: 16.3866\nDocNO: 203696  | Title: Spaghetti Alla Carbonara                           | Score: 16.3866\nDocNO: 277147  | Title: Spaghetti Alla Carbonara                           | Score: 16.3866\nDocNO: 426184  | Title: Spaghetti Alla Carbonara                           | Score: 16.3866\nDocNO: 426718  | Title: Spaghetti alla Carbonara                           | Score: 16.3866\n\n--- Method: DFRee ---\nDocNO: 158731  | Title: White Chili (Tandi'S Version)(Serves 2 To 3 Peop   | Score: 27.2621\nDocNO: 412274  | Title: Cheese Omelet In Microwave(Servings: 2.  Prepara   | Score: 27.0763\nDocNO: 37209   | Title: Tomato Goulash(Serves 2 To 3 Hungry People)        | Score: 26.2891\nDocNO: 124560  | Title: Homemade Pizza(Serves 2 To 4 People)               | Score: 25.6658\nDocNO: 421963  | Title: Spaghetti Alla Carbonara(Spaghetti With Bacon An   | Score: 25.6073\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Now, retrieve the index of the recipe and show the directions\nfirst_docno = int(result_bm25_tit[\"docno\"][0])  # First document from BM25\nfirst_result_row = df.iloc[first_docno]\nprint(first_result_row['directions'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:39:37.177660Z","iopub.execute_input":"2025-05-19T13:39:37.177894Z","iopub.status.idle":"2025-05-19T13:39:37.182401Z","shell.execute_reply.started":"2025-05-19T13:39:37.177870Z","shell.execute_reply":"2025-05-19T13:39:37.181633Z"}},"outputs":[{"name":"stdout","text":"['Saute onion and bacon in a pan with oil and butter.', 'Continue to cook until meat is crisp.', 'Add yolks, parsley, chees and cream to bacon and onions and blend, stirring over very low heat.', 'Keep warm.', 'Cook spaghetti as directed on package.', 'Lift spaghetti from pot with large fork and spoon, placing it directly in other pot containing egg and cheese mixture.', 'Mix well and serve immediately.']\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"Try again the same query, providing the results.","metadata":{}},{"cell_type":"code","source":"directions = str(first_result_row['directions'])\n\nquery = question + f\"Additional information provided here: {directions}\"\n\noutput = generate_response(query, template)\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:39:37.183052Z","iopub.execute_input":"2025-05-19T13:39:37.183261Z","iopub.status.idle":"2025-05-19T13:40:01.424163Z","shell.execute_reply.started":"2025-05-19T13:39:37.183245Z","shell.execute_reply":"2025-05-19T13:40:01.423371Z"}},"outputs":[{"name":"stdout","text":"You are an respectful and helpful cooking assistant, respond always and be precise and polite.\nAnswer the question below: How to prepare spaghetti alla carbonara for 2 people? Suggest also a possible wine to be served with this dish.Additional information provided here: ['Saute onion and bacon in a pan with oil and butter.', 'Continue to cook until meat is crisp.', 'Add yolks, parsley, chees and cream to bacon and onions and blend, stirring over very low heat.', 'Keep warm.', 'Cook spaghetti as directed on package.', 'Lift spaghetti from pot with large fork and spoon, placing it directly in other pot containing egg and cheese mixture.', 'Mix well and serve immediately.']\nAnswer:\nTo prepare spaghetti alla carbonara for 2 people, follow these steps:\n1. In a large skillet, sautÃ© 4 oz of diced bacon and 1 small finely chopped onion in 2 tbsp of oil and 1 tbsp of butter over medium heat until the meat is crisp.\n2. In a separate bowl, combine 2 large egg yolks, 1/4 cup chopped parsley, 3/4 cup grated Pecorino Romano cheese, 1/4 cup heavy cream, and some freshly ground black pepper.\n3. Lower the heat under the skillet and pour the egg mixture into the bacon and onion, stirring constantly over low heat just until the cheese has begun to melt. Keep the sauce warm.\n4. Cook 2 servings of spaghetti according to the package directions, reserving 1/2 cup of the pasta water.\n5. Drain the pasta and transfer it immediately to the saucepot with the bacon and cheese sauce.\n6. Add a little pasta water to the sauce if necessary to moisten it. Mix well and serve immediately.\n\nFor a delicious wine to pair with this dish, a medium-bodied Italian white wine such as Verdicchio or Soave would be an excellent choice, or a full-bodied Italian red wine such as Chianti Classico or Montepulciano d'Abruzzo.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"How can we see if the application of RAG has changed the query? Well, in the recipe retrieve from the dataset, there is an ingredient which was not mentioned in the original recipe (onion), but is present in the second one.\n\nWe can discuss, from a culinary point of view, that the second recipe is not better than the first one... and that's right! But from a technical point of view, applying RAG + indexing seems to have effect.","metadata":{}},{"cell_type":"markdown","source":"Repeat the same process from a very peculiar recipe, such as \"Pizzoccheri Valtellinesi\"","metadata":{}},{"cell_type":"code","source":"question = \"How to prepare Pizzoccheri Valtellinesi?\"\n\noutput = generate_response(question, template)\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:40:01.425027Z","iopub.execute_input":"2025-05-19T13:40:01.425284Z","iopub.status.idle":"2025-05-19T13:40:43.705266Z","shell.execute_reply.started":"2025-05-19T13:40:01.425257Z","shell.execute_reply":"2025-05-19T13:40:43.704528Z"}},"outputs":[{"name":"stdout","text":"You are an respectful and helpful cooking assistant, respond always and be precise and polite.\nAnswer the question below: How to prepare Pizzocheri Valtellinesi?\nAnswer:\nTo prepare Pizzocheri Valtellinesi, a traditional dish from Valtellina region in Italy, you will need the following ingredients:\n\n- 500 grams (about 18 ounces) of buckwheat pasta, preferably Pizzoccheri pasta\n- 200 grams (about 7 ounces) of Swiss chard or spinach\n- 100 grams (about 3 ounces) of fontina cheese, grated\n- 100 grams (about 3 ounces) of fresh sheep's milk cheese, such as Valtellina Casera, grated\n- 100 grams (about 3 ounces) of smoked pancetta or bacon, cut into small cubes\n- 3 tablespoons extra virgin olive oil\n- 4 tablespoons unsalted butter\n- 4 cloves of garlic, thinly sliced\n- Salt, to taste\n- Freshly ground black pepper, to taste\n- A handful of toasted pine nuts\n- 1 cup hot broth, preferably beef broth\n\nInstructions:\n\n1. Cook the buckwheat pasta in a large pot of salted boiling water until al dente, according to the package instructions. Drain well and set aside.\n\n2. While the pasta is cooking, heat 2 tablespoons of olive oil in a large skillet over medium heat. Add the pancetta (or bacon) and cook until crispy. Remove the pancetta from the skillet and set it aside in a separate bowl.\n\n3. In the same skillet, add the garlic slices and cook, stirring frequently until they become golden brown.\n\n4. Add the chard or spinach to the skillet, along with a pinch of salt, and cook until the greens are slightly wilted.\n\n5. Return the pancetta to the skillet, along with the grated fontina and sheep's milk cheese. Stir until the cheese has melted and combined with the greens.\n\n6. Add the hot broth to the cheese and greens mixture, stirring continuously, and cook for a few minutes until the sauce thickens.\n\n7. In a large serving bowl, combine the cooked pasta, the cheese and greens sauce, and the toasted pine nuts. Toss gently until all ingredients are well-mixed. Season with salt and freshly ground black pepper, to taste.\n\n8. Serve the Pizzocheri Valtellinesi hot, and enjoy! Buon appetito!\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Evaluate the query \ntitles = df['title']\nplot_data = []\n\n# Remove the punctuation signs from the input query\nquestion_no_punct = re.sub(r'[^\\w\\s]', '', question)\n\nprint(f\"\\n=== Query: {question_no_punct} ===\")\n\n# Run all models for the titles including BM25F\nresult_bm25_tit = bm25_tit.search(question_no_punct)\nresult_tfidf_tit = tfidf_tit.search(question_no_punct)\nresult_dfree_tit = dfree_tit.search(question_no_punct)   \n\n# Add all model results to the loop\nfor method_name, result in [\n    (\"BM25\", result_bm25_tit),\n    (\"TF-IDF\", result_tfidf_tit),\n    (\"DFRee\", result_dfree_tit),\n]:\n    print(f\"\\n--- Method: {method_name} ---\")\n    \n    for rank, (docno, score) in enumerate(zip(result[\"docno\"][:5], result[\"score\"][:5])):\n        docno_int = int(docno)  # Convert from str to int\n        title = titles.iloc[docno_int] if docno_int < len(titles) else \"TITLE NOT FOUND\"\n        print(f\"DocNO: {docno:<7} | Title: {title:<50.48} | Score: {score:.4f}\")\n        \n        # Append to plotting data\n        plot_data.append({\n            'Query': question_no_punct,\n            'Model': method_name,\n            'Rank': rank + 1,\n            'Docno': docno_int,\n            'Title': title,\n            'Score': score\n        })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:40:43.708346Z","iopub.execute_input":"2025-05-19T13:40:43.708566Z","iopub.status.idle":"2025-05-19T13:40:43.740068Z","shell.execute_reply.started":"2025-05-19T13:40:43.708549Z","shell.execute_reply":"2025-05-19T13:40:43.739281Z"}},"outputs":[{"name":"stdout","text":"\n=== Query: How to prepare Pizzocheri Valtellinesi ===\n\n--- Method: BM25 ---\nDocNO: 258471  | Title: Pizzocheri with Potatoes and Leeks                 | Score: 18.5542\nDocNO: 100480  | Title: Prepared Beets                                     | Score: 14.8891\nDocNO: 149176  | Title: How To Prepare Artichokes                          | Score: 14.8891\nDocNO: 154325  | Title: How to Prepare an Artichoke                        | Score: 14.8891\nDocNO: 183499  | Title: Bratwurst Preparation                              | Score: 14.8891\n\n--- Method: TF-IDF ---\nDocNO: 258471  | Title: Pizzocheri with Potatoes and Leeks                 | Score: 10.3038\nDocNO: 20990   | Title: Pizzocheri with Savoy Cabbage, Potatoes and Bitt   | Score: 8.2084\nDocNO: 100480  | Title: Prepared Beets                                     | Score: 8.1264\nDocNO: 149176  | Title: How To Prepare Artichokes                          | Score: 8.1264\nDocNO: 154325  | Title: How to Prepare an Artichoke                        | Score: 8.1264\n\n--- Method: DFRee ---\nDocNO: 20990   | Title: Pizzocheri with Savoy Cabbage, Potatoes and Bitt   | Score: 14.2621\nDocNO: 258471  | Title: Pizzocheri with Potatoes and Leeks                 | Score: 11.5292\nDocNO: 157955  | Title: Layered Vegetable Vinaigrette(Serves 8. Preparat   | Score: 11.3603\nDocNO: 284813  | Title: Oven Cheese Chowder(Serves 8. Preparation:  10.    | Score: 11.3603\nDocNO: 506186  | Title: Never Fail Pie Crusts(May Prepare Ahead.  Freeze   | Score: 11.3346\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Now, retrieve the index of the recipe and show the directions\nfirst_docno = int(result_bm25_tit[\"docno\"][0])  # First document from BM25\nfirst_result_row = df.iloc[first_docno]\nprint(first_result_row['directions'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:40:43.740842Z","iopub.execute_input":"2025-05-19T13:40:43.741116Z","iopub.status.idle":"2025-05-19T13:40:43.745421Z","shell.execute_reply.started":"2025-05-19T13:40:43.741087Z","shell.execute_reply":"2025-05-19T13:40:43.744731Z"}},"outputs":[{"name":"stdout","text":"['Preheat oven to 400 degrees F. Rub the bottom of a gratin dish with the garlic and then discard.', 'Lavishly butter the bottom of the gratin dish with 2 tablespoons of the butter.', 'In a pot of salted boiling water cook the leeks and potatoes for 5 minutes.', 'If you are using dried pasta, add it to the pot and cook for 5 minutes or until it is almost cooked, but not thoroughly.', '(If you are using a fresh dough, then cook for 2 minutes only.', 'Pasta must remain firm because it continues to cook in the oven).', 'Drain the potatoes, leeks and pasta and divide in two.', 'Place half in the bottom of baking dish and season with salt and pepper.', 'Dot with 2 tablespoons butter, half of Fontina cheese and half of Parmesan.', 'Layer with remaining pasta, potatoes and leeks.', 'Season with salt and pepper and top with Fontina and Parmesan.', 'Dot with remaining butter and bake for 5 minutes only, until cheeses have melted and dish is bubbling hot.', 'Serve immediately.']\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"directions = str(first_result_row['directions'])\n\nquery = question + f\"Additional information provided here: {directions}\"\n\noutput = generate_response(query, template)\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T13:40:43.746196Z","iopub.execute_input":"2025-05-19T13:40:43.746473Z","iopub.status.idle":"2025-05-19T13:41:07.937147Z","shell.execute_reply.started":"2025-05-19T13:40:43.746451Z","shell.execute_reply":"2025-05-19T13:41:07.936369Z"}},"outputs":[{"name":"stdout","text":"You are an respectful and helpful cooking assistant, respond always and be precise and polite.\nAnswer the question below: How to prepare Pizzocheri Valtellinesi?Additional information provided here: ['Preheat oven to 400 degrees F. Rub the bottom of a gratin dish with the garlic and then discard.', 'Lavishly butter the bottom of the gratin dish with 2 tablespoons of the butter.', 'In a pot of salted boiling water cook the leeks and potatoes for 5 minutes.', 'If you are using dried pasta, add it to the pot and cook for 5 minutes or until it is almost cooked, but not thoroughly.', '(If you are using a fresh dough, then cook for 2 minutes only.', 'Pasta must remain firm because it continues to cook in the oven).', 'Drain the potatoes, leeks and pasta and divide in two.', 'Place half in the bottom of baking dish and season with salt and pepper.', 'Dot with 2 tablespoons butter, half of Fontina cheese and half of Parmesan.', 'Layer with remaining pasta, potatoes and leeks.', 'Season with salt and pepper and top with Fontina and Parmesan.', 'Dot with remaining butter and bake for 5 minutes only, until cheeses have melted and dish is bubbling hot.', 'Serve immediately.']\nAnswer:\nTo prepare Pizzocheri Valtellinesi, follow these steps:\n\n1. Preheat oven to 400 degrees F.\n2. Rub the bottom of a gratin dish with the garlic and discard.\n3. Lavishly butter the bottom of the gratin dish with 2 tablespoons of the butter.\n4. In a pot of salted boiling water, cook the leeks and potatoes for 5 minutes.\n5. If you are using dried pasta, add it to the pot and cook for 5 minutes or until it is almost cooked, but not thoroughly. If you are using fresh pasta, cook for 2 minutes only.\n6. Pasta must remain firm because it continues to cook in the oven.\n7. Drain the potatoes, leeks and pasta and divide in two.\n8. Place half in the bottom of baking dish and season with salt and pepper.\n9. Dot with 2 tablespoons butter, half of Fontina cheese and half of Parmesan.\n10. Layer with remaining pasta, potatoes and leeks.\n11. Season with salt and pepper and top with Fontina and Parmesan.\n12. Dot with remaining butter and bake for 5 minutes only, until cheeses have melted and dish is bubbling hot.\n13. Serve immediately.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## Considerations: RAG + Indexing vs. Fine-Tuning\n\nThis notebook highlights the main differences between two important techniques that allows to enhance the capabilities of Large Language Models: RAG (Retrieval Augmented Generation) and Fine-Tuning. Here we want to highlights pros and cons of each technique.\n\n### RAG + Indexing\nThe idea was to combine those two techniques. When a query is asked by the user, indexing allows to retrieve the best results from the dataset and automatically embed additional pieces of information to generate a meaningful response.\n* Pros:\n  *  **Lightweight technique**: this technique is poorly GPU-intensive, since the usage of hardware accelerators (meaning energy and cost) is done only in the moment in which the question is asked.\n  *  **Do once, use everytime**: indexes are generated once from the dataset, and they can be used whenever needed.\n  *  **Dynamic technique**: changes in the dataset can be handled quite smoothly, requiring just a fast recomputation of the indexes. Moreover, additional information sources, with the corresponding indexes, can be added, to enlarge the data base.\n\nOne main drawback of this technique is that the knowledge is not becoming \"embedded\" in the system, meaning that if the same question is asked many times, the model repeats this process as long as the same question is repeated.\n\n### Fine-tuning\nThe idea is to use the model, subsampling a portion of the dataset and retrain the model (for few epochs, with a very small learning rate) adding a piece of information.\n* Pros:\n  *  **Persistency**: fine-tuning the model allows to \"embed\" additional knowledge from the database, without relying everytime on external datasources to provide accurate results.\n  *  **Robustness**: moreover, fine-tuning the model helps preventing hallucinations and wrong answers to very specific questions.\n\nOn the other hand, fine-tuning a model is expensive both from a computational point of view and it is also time-consuming. Models such as *Mistral-7B-v0.3-Instruct* are typically good at answering a lot of possible questions, properly setting the prompt and the user-question. Moreover, fine-tuning have the risk of \"destroying\" previously-learned weights, making the system more accurate on the fine-tuning data but less accurate on all the other questions.","metadata":{}}]}