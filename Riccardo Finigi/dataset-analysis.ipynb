{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11546547,"sourceType":"datasetVersion","datasetId":7240981}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Not used\nfrom datasets import load_dataset\n\n#Imported directly from kaggle\nimport pandas as pd\n\ndf = pd.read_csv(\"/kaggle/input/recipes/dataset/full_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T14:30:37.585054Z","iopub.execute_input":"2025-04-26T14:30:37.585465Z","iopub.status.idle":"2025-04-26T14:31:11.558845Z","shell.execute_reply.started":"2025-04-26T14:30:37.585435Z","shell.execute_reply":"2025-04-26T14:31:11.557886Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dim_dataset = len(df)\n\nprint(f\"In the dataset there are {dim_dataset} recipe. \\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analysis first column: Unnamed: 0**","metadata":{}},{"cell_type":"code","source":"fields = list(df.columns)\n    \nfirst_cols = list(df.columns[:1])  \nduplicates = df[df.duplicated(subset=first_cols)]\n  \nprint(f\"Duplicates index: {duplicates}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"“Unnamed: 0” corresponds to the ‘id’ field, which uniquely identifies a prescription in the database","metadata":{}},{"cell_type":"code","source":"import ast \n\n\nfor field in fields:\n    sample_value = df[field].dropna().iloc[0]  \n    \n    if isinstance(sample_value, str):\n        try:\n            evaluated = ast.literal_eval(sample_value)\n            sample_value = evaluated\n        except (ValueError, SyntaxError):\n            pass \n\n    print(f\"\\nField: {field}\")\n    print(f\"Type: {type(sample_value).__name__}\")\n    \n    # If it's a list or dict, show inner types\n    if isinstance(sample_value, list):\n        inner_types = set(type(x).__name__ for x in sample_value)\n        print(f\"Inner types in list: {inner_types}\")\n    elif isinstance(sample_value, dict):\n        key_types = set(type(k).__name__ for k in sample_value.keys())\n        value_types = set(type(v).__name__ for v in sample_value.values())\n        print(f\"Inner types in dict - keys: {key_types}, values: {value_types}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analysis second column: title**","metadata":{}},{"cell_type":"code","source":"from collections import defaultdict\n\nsecond_col = df.columns[1]  \nupper_title = df[second_col].str.upper()\n\ntitle_indices = defaultdict(list)\n\nfor i, title in enumerate(upper_title):\n    title_indices[title].append(i)\n\nduplicates_dict = {title: idxs for title, idxs in title_indices.items() if len(idxs) > 1}\n\nl = []\nfor i, (title, idxs) in enumerate(duplicates_dict.items()):\n    l.append(title)\n    if i >= 4:  # Stop after 5 examples\n        break\n\nprint(f\"Example of duplicates: {l} \\n\")\n\nsingle_recipe = {title: idxs for title, idxs in title_indices.items() if len(idxs) == 1}\n\ncount = 0\nmaxR = 1\nmaxItem = \"\"\nfor item in duplicates_dict:\n    #print(f\"Item: {item}, recipes: {len(duplicates_dict[item])}\")\n    count += len(duplicates_dict[item])\n    if len(duplicates_dict[item]) > maxR:\n        maxR = len(duplicates_dict[item])\n        maxItem = item\n\nprint(f\"Number of title: {len(title_indices)}. \\n\")\n\nprint(f\"Number of title with one recipe: {len(single_recipe)}, with more than one: {len(title_indices) - len(single_recipe)}. \\n\")\n\nprint(f\"MAX number for recipe: {maxR}, {maxItem}. \\n\")\n\nprint(f\"AVG recipe for title: {count/len(duplicates_dict)} (counting only duplicates). \\n\")\n\nprint(f\"AVG recipe for title: {count/len(title_indices)} . \\n\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now let's take some time to understand how recipes with the same name differ, focusing only on the ingredients ","metadata":{}},{"cell_type":"code","source":"\ningredients = df.columns[6]\n\n#Insert a duplicates recipe from the dataset\nrecipe = \"CHICKEN CASSEROLE\"\n\nsetIngr = set()\nindexRecipe = duplicates_dict[recipe]\n\nprint(f\"Example of index: {indexRecipe[:10]} \\n\")\nprint(f\"Recipe ing: {df.iloc[63][ingredients]} \\n\")\n\ningredientsCounter = defaultdict(int) \n\n#Some statistics \ncounter = 0\nfor idx in indexRecipe:\n    counter += 1\n    ingredientList_str = df.iloc[idx][ingredients].upper()\n    ingredientList = ast.literal_eval(ingredientList_str)\n    for ingredient in ingredientList:\n        if ingredient in ingredientsCounter:\n            ingredientsCounter[ingredient] += 1\n        else:\n            ingredientsCounter[ingredient] = 1\n\nnPrint = 10\nnumRecipe = len(indexRecipe)\nprint(f\"Percentage of ingredients in {recipe}: \\n\")\nfor ingr, count in ingredientsCounter.items():\n    print(f\"{ingr}:  {count/numRecipe:.2%}\")\n    nPrint -= 1\n    if nPrint == 0:\n        break\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sort ingredientsCounter by count in descending order\nsorted_ingredients = sorted(ingredientsCounter.items(), key=lambda x: x[1], reverse=True)\n\nnPrint = 10\nnumRecipe = len(indexRecipe)\nprint(f\"Percentage of ingredients in {recipe}: \\n\")\nfor ingr, count in sorted_ingredients:\n    print(f\"{ingr}: {count/numRecipe:.2%}\")  \n    nPrint -= 1\n    if nPrint == 0:\n        break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The recipe duplicated several times has only 60% more ingredient present. The main problem is also in the names, maybe the same ingredient with different names","metadata":{}},{"cell_type":"code","source":"del sorted_ingredients, ingredientsCounter, duplicates_dict, upper_title, first_cols","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analysis second column: Directions**","metadata":{}},{"cell_type":"code","source":"directions_col = df['directions'].dropna().apply(ast.literal_eval)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"step_counts = directions_col.apply(lambda x: len(x) if isinstance(x, list) else 0)\n\nprint(\"Analysis of 'directions' field:\\n\")\nprint(f\"Total recipes with directions: {len(step_counts)}\")\nprint(f\"Minimum steps in a recipe: {step_counts.min()}\")\nprint(f\"Maximum steps in a recipe: {step_counts.max()}\")\nprint(f\"Average number of steps: {step_counts.mean():.2f}\")\nprint(f\"Median number of steps: {step_counts.median()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nall_instructions = [instruction for instructions in directions_col for instruction in instructions]\n\ninstruction_lengths = [len(instr) for instr in all_instructions]\n\nprint(\"\\nAnalysis of single instructions:\\n\")\nprint(f\"Total instructions: {len(instruction_lengths)}\")\nprint(f\"Shortest instruction length: {np.min(instruction_lengths)} characters\")\nprint(f\"Longest instruction length: {np.max(instruction_lengths)} characters\")\nprint(f\"Average instruction length: {np.mean(instruction_lengths):.2f} characters\")\nprint(f\"Median instruction length: {np.median(instruction_lengths):.2f} characters\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del directions_col, all_instructions, instruction_lengths","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analysis second column: Link & source**","metadata":{}},{"cell_type":"markdown","source":"I leave out the recipes that come from the old dataset and dwell on those with a link","metadata":{}},{"cell_type":"code","source":"# Select columns\ncol4 = df.iloc[:, 4]  \ncol5 = df.iloc[:, 5]  \n\nmask = col5 != \"Gathered\"\nfiltered_col5 = col5[mask]\nprint(filtered_col5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mask = ~col5.str.contains(\"Recipes1M\", na=False)  # \"~\" means NOT, na=False to avoid NaN problems\nfiltered_col4 = col4[mask]\nfiltered_col4_inv = col4[~mask]\n\nprint(f\"Total entries in filtered column link: {len(filtered_col4)}\\n\")\n\ndef extract_base_link(link):\n    if pd.isna(link):\n        return None\n    return link.split('/')[0]\n\nbase_links = filtered_col4.apply(extract_base_link)\n\nbase_link_counts = base_links.value_counts()\n\nprint(\"Top base links:\\n\")\nprint(base_link_counts.head(10))\n\nprint(f\"\\n\\n Old dataset: {len(filtered_col4_inv)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analysis second column: NER**","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n\ningredienti_unici = set()\ningredient_counter = Counter()\n\nfor ingr_str in df['NER']:\n    try:\n        lista_ingredienti = ast.literal_eval(ingr_str)\n        for ingrediente in lista_ingredienti:\n            ingrediente_pulito = ingrediente.lower().strip()\n            ingredienti_unici.add(ingrediente_pulito)\n            ingredient_counter[ingrediente_pulito] += 1\n    except:\n        continue\n\nprint(f\"Total number of unique ingredients: {len(ingredienti_unici)}\\n\")\n\nprint(\"Top 10 ingredients by frequency:\")\nfor ingrediente, count in ingredient_counter.most_common(10):\n    print(f\"{ingrediente}: {count} times\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**vocabulary analysis**","metadata":{}},{"cell_type":"markdown","source":"How big is the vocabulary of the collection? How big is the vocabulary of a document on average? \n\nWhile the analysis on ingredients has already been done, the vocabulary for recipe instructions has not. Let us therefore try to extract some useful information.","metadata":{}},{"cell_type":"code","source":"import nltk\nimport pandas as pd\nimport ast\n\nnltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T14:31:31.814893Z","iopub.execute_input":"2025-04-26T14:31:31.815207Z","iopub.status.idle":"2025-04-26T14:31:33.416534Z","shell.execute_reply.started":"2025-04-26T14:31:31.815187Z","shell.execute_reply":"2025-04-26T14:31:33.415460Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from nltk.corpus import stopwords\nprint('English stopwords:')\nprint(stopwords.words('english'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T14:31:33.418692Z","iopub.execute_input":"2025-04-26T14:31:33.419281Z","iopub.status.idle":"2025-04-26T14:31:33.427895Z","shell.execute_reply.started":"2025-04-26T14:31:33.419254Z","shell.execute_reply":"2025-04-26T14:31:33.426989Z"}},"outputs":[{"name":"stdout","text":"English stopwords:\n['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#Flatten the list of instraction\ndirections_col = df['directions'].dropna().apply(ast.literal_eval)\nall_instructions_list = [instruction for instructions in directions_col for instruction in instructions]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T14:31:33.428842Z","iopub.execute_input":"2025-04-26T14:31:33.429113Z","iopub.status.idle":"2025-04-26T14:32:30.513370Z","shell.execute_reply.started":"2025-04-26T14:31:33.429093Z","shell.execute_reply":"2025-04-26T14:32:30.512605Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"From here on I work on a subset because the full dataset is too heavy, subset extracted completely randomly","metadata":{}},{"cell_type":"code","source":"import re\nimport random\nfrom nltk.corpus import stopwords\nfrom nltk.probability import FreqDist\n\ndivision = 1000\n\nsubset_size = len(all_instructions_list) // division  \nsubset_instructions = random.sample(all_instructions_list, subset_size)\n\nfull_text = ' '.join(subset_instructions)\n\nfull_text = full_text.lower()\nfull_text = re.sub(r'[^a-zA-Z0-9\\s]', '', full_text)  # keep only letters, numbers, spaces\n\nwords = full_text.split()\n\nwords_nostopwords = [w for w in words if w not in stopwords.words('english')]\n\nfdist = FreqDist(words_nostopwords)\n\nprint(\"Top 10 most common words:\")\nfor word, freq in fdist.most_common(10):\n    print(f\"{word}: {freq}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T14:38:24.961279Z","iopub.execute_input":"2025-04-26T14:38:24.961581Z","iopub.status.idle":"2025-04-26T14:38:41.801541Z","shell.execute_reply.started":"2025-04-26T14:38:24.961559Z","shell.execute_reply":"2025-04-26T14:38:41.800623Z"}},"outputs":[{"name":"stdout","text":"Top 10 most common words:\nadd: 2796\nminutes: 2316\nheat: 1597\nmix: 1220\ncook: 1164\nmixture: 1114\nstir: 1111\nbowl: 1107\npan: 1072\nsalt: 1059\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#Find emoticons, if any\n\nemoticon_regex = '(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)'\nemoticons_in_pos = re.findall(emoticon_regex,full_text)\ncounts = nltk.FreqDist(emoticons_in_pos)\nprint(f\"Number of emoticons: {counts}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T14:39:27.651756Z","iopub.execute_input":"2025-04-26T14:39:27.652128Z","iopub.status.idle":"2025-04-26T14:39:27.689889Z","shell.execute_reply.started":"2025-04-26T14:39:27.652104Z","shell.execute_reply":"2025-04-26T14:39:27.688726Z"}},"outputs":[{"name":"stdout","text":"Number of emoticons: <FreqDist with 0 samples and 0 outcomes>\n","output_type":"stream"}],"execution_count":9}]}