{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11601525,"sourceType":"datasetVersion","datasetId":7276106}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:37:54.544494Z","iopub.execute_input":"2025-05-15T08:37:54.544817Z","iopub.status.idle":"2025-05-15T08:37:57.866383Z","shell.execute_reply.started":"2025-05-15T08:37:54.544794Z","shell.execute_reply":"2025-05-15T08:37:57.865640Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:37:57.868221Z","iopub.execute_input":"2025-05-15T08:37:57.869071Z","iopub.status.idle":"2025-05-15T08:37:57.872580Z","shell.execute_reply.started":"2025-05-15T08:37:57.869047Z","shell.execute_reply":"2025-05-15T08:37:57.871987Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom datasets import Dataset\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nimport re\nimport nltk\nfrom nltk.tokenize import word_tokenize\n\nnltk.download('punkt')  \n\n\ndf = pd.read_csv(\"/kaggle/input/recipe-sampled-0-25/sampled_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:37:57.873274Z","iopub.execute_input":"2025-05-15T08:37:57.873486Z","iopub.status.idle":"2025-05-15T08:38:05.379661Z","shell.execute_reply.started":"2025-05-15T08:37:57.873461Z","shell.execute_reply":"2025-05-15T08:38:05.378855Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"#### Preparazione del dataset","metadata":{}},{"cell_type":"code","source":"df_sample = df[[\"directions\", \"ingredients\"]].sample(n=10000, random_state=42).reset_index(drop=True)\ndf_sample.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:05.395128Z","iopub.execute_input":"2025-05-15T08:38:05.395395Z","iopub.status.idle":"2025-05-15T08:38:05.517440Z","shell.execute_reply.started":"2025-05-15T08:38:05.395360Z","shell.execute_reply":"2025-05-15T08:38:05.516667Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                                          directions  \\\n0  ['Mix together the cheese, olives, onion, drie...   \n1  ['Brown meat; drain and set aside.', 'Blend ma...   \n2  ['Dissolve jello in boiling water.', 'Let cool...   \n\n                                         ingredients  \n0  [\"1 cup shredded cheddar cheese\", \"1 cup chopp...  \n1  [\"1 pie crust\", \"1/2 lb. ground beef (you can ...  \n2  [\"2 small orange jello\", \"2 c. boiling water\",...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>directions</th>\n      <th>ingredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['Mix together the cheese, olives, onion, drie...</td>\n      <td>[\"1 cup shredded cheddar cheese\", \"1 cup chopp...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['Brown meat; drain and set aside.', 'Blend ma...</td>\n      <td>[\"1 pie crust\", \"1/2 lb. ground beef (you can ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['Dissolve jello in boiling water.', 'Let cool...</td>\n      <td>[\"2 small orange jello\", \"2 c. boiling water\",...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"import ast\n\ndf_sample[\"ingredients\"] = df_sample[\"ingredients\"].apply(ast.literal_eval)\ndf_sample[\"directions\"] = df_sample[\"directions\"].apply(ast.literal_eval)\n\nprint(type(df_sample.loc[0, \"ingredients\"]))  # deve essere <class 'list'>\nprint(df_sample.loc[0, \"ingredients\"])        # stampa la lista vera\n\nprint(type(df_sample.loc[0, \"directions\"]))  # deve essere <class 'list'>\nprint(df_sample.loc[0, \"directions\"])        # stampa la lista vera","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:05.518573Z","iopub.execute_input":"2025-05-15T08:38:05.518931Z","iopub.status.idle":"2025-05-15T08:38:05.915800Z","shell.execute_reply.started":"2025-05-15T08:38:05.518912Z","shell.execute_reply":"2025-05-15T08:38:05.915070Z"}},"outputs":[{"name":"stdout","text":"<class 'list'>\n['1 cup shredded cheddar cheese', '1 cup chopped pimento stuffed olive', '1 tablespoon minced onion', '1 cup dried beef, chopped', '3/4 - 1 cup mayonnaise', '1 loaf sliced rye cocktail bread']\n<class 'list'>\n['Mix together the cheese, olives, onion, dried beef and mayo.', 'Spread on slices of rye cocktail bread. place the slices on a cookie sheet and broil until bubbly.']\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"df_sample[\"text\"] = df_sample[\"directions\"].apply(lambda steps: \" \".join(steps))\nprint(df_sample.loc[0, \"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:05.916469Z","iopub.execute_input":"2025-05-15T08:38:05.916691Z","iopub.status.idle":"2025-05-15T08:38:05.929678Z","shell.execute_reply.started":"2025-05-15T08:38:05.916674Z","shell.execute_reply":"2025-05-15T08:38:05.928800Z"}},"outputs":[{"name":"stdout","text":"Mix together the cheese, olives, onion, dried beef and mayo. Spread on slices of rye cocktail bread. place the slices on a cookie sheet and broil until bubbly.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"Queste regole regex non sono complete, non coprono tutti i casi. Bisognerebbe aggiunge man mano, ma è una operazione complicata","metadata":{}},{"cell_type":"code","source":"import re\n\ndef clean_ingredient(ingredient):\n    # Remove fractions and numbers (e.g., \"1\", \"1/2\", \"2.5\")\n    ingredient = re.sub(r'\\b\\d+([\\/\\.]\\d+)?\\b', '', ingredient)\n\n    # Common measurement units to remove\n    units = [\n        \"teaspoons?\", \"tsp\", \"tablespoons?\", \"tbsp\", \"cups?\", \"ounces?\", \"oz\",\n        \"pounds?\", \"lb\", \"grams?\", \"g\", \"kilograms?\", \"kg\", \"milliliters?\", \"ml\",\n        \"liters?\", \"l\", \"pinch\", \"clove\", \"cloves\", \"slices?\", \"dash\", \"cans?\", \n        \"packages?\", \"bunch\", \"stalks?\", \"heads?\", \"pieces?\", \"sticks?\", \"inches?\"\n    ]\n    units_pattern = r'\\b(?:' + '|'.join(units) + r')\\b'\n    ingredient = re.sub(units_pattern, '', ingredient, flags=re.IGNORECASE)\n\n    ingredient = re.sub(r'\\b(c\\.|c)\\b\\.?', '', ingredient, flags=re.IGNORECASE)\n\n    ingredient = re.sub(r'\\(\\s*\\.\\s*\\)', '', ingredient)\n    ingredient = re.sub(r'\\([^)]*\\)', '', ingredient)\n\n    ingredient = re.sub(r'\\bof\\b', '', ingredient, flags=re.IGNORECASE)\n    ingredient = re.sub(r'^\\s*\\.\\s*', '', ingredient)       # punto iniziale con spazio\n    ingredient = re.sub(r'\\.\\s*', ' ', ingredient)          # ogni \". \" ovunque\n    ingredient = re.sub(r',.*', '', ingredient)             # rimuove note dopo virgola\n\n    ingredient = re.sub(r'\\b(to |pt |pkg |qt )\\.?\\b', '', ingredient, flags=re.IGNORECASE)\n    ingredient = re.sub(r'^to\\s+', '', ingredient, flags=re.IGNORECASE)\n\n    # Remove extra spaces\n    ingredient = re.sub(r'\\s+', ' ', ingredient).strip()\n\n    return ingredient\n\n\n# Applica a tutta la colonna ingredients\ndf_sample[\"clean_ingredients\"] = df_sample[\"ingredients\"].apply(lambda lst: [clean_ingredient(i) for i in lst])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:05.930469Z","iopub.execute_input":"2025-05-15T08:38:05.930681Z","iopub.status.idle":"2025-05-15T08:38:07.255248Z","shell.execute_reply.started":"2025-05-15T08:38:05.930637Z","shell.execute_reply":"2025-05-15T08:38:07.254693Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"print(df_sample.loc[:10, \"clean_ingredients\"]) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:07.255955Z","iopub.execute_input":"2025-05-15T08:38:07.256162Z","iopub.status.idle":"2025-05-15T08:38:07.262274Z","shell.execute_reply.started":"2025-05-15T08:38:07.256146Z","shell.execute_reply":"2025-05-15T08:38:07.261367Z"}},"outputs":[{"name":"stdout","text":"0     [shredded cheddar cheese, chopped pimento stuf...\n1     [pie crust, ground beef, mayonnaise, milk, egg...\n2     [small orange jello, boiling water, small crus...\n3     [square graham crackers, reduced calorie marga...\n4     [cream cheese, sm jar Old English cheese, Lipt...\n5     [MIRACLE WHIP Dressing, BREAKSTONE'S or KNUDSE...\n6     [FOR THE FILLING:, Fresh Strawberries, - Fresh...\n7     [doz mangos, cabbage, celery, brown sugar, sal...\n8     [chopped green peppers, chopped red peppers, c...\n9     [fryer, uncooked rice, cream chicken soup, dry...\n10    [yeast, bread flour, salt, sugar, olive oil, w...\nName: clean_ingredients, dtype: object\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"Assegno le label \"0\" \"I-food\" \"B-food\"","metadata":{}},{"cell_type":"code","source":"\ndef check(labels):\n      # 🔍 Verifica coerenza: nessun I-FOOD senza un B-FOOD prima\n    for i, label in enumerate(labels):\n        if label == 'I-FOOD':\n            if i == 0 or labels[i - 1] not in ['B-FOOD', 'I-FOOD']:\n                raise ValueError(f\"Incoerenza IOB: I-FOOD alla posizione {i} senza B-FOOD precedente.\")\n\n\n\ndef iob_tag_tokens(text, ingredient_list):\n    tokens = word_tokenize(text)\n    labels = ['O'] * len(tokens)\n    \n    for ingredient in ingredient_list:\n        ingredient_tokens = word_tokenize(ingredient)\n        ingredient_len = len(ingredient_tokens)\n\n        if ingredient_len == 0:\n            continue  # ignora ingredienti vuoti\n\n        for i in range(len(tokens) - ingredient_len + 1):\n            window = tokens[i:i + ingredient_len]\n            if [t.lower() for t in window] == [t.lower() for t in ingredient_tokens]:\n                labels[i] = 'B-FOOD'\n                for j in range(1, ingredient_len):\n                    if i + j < len(labels):\n                        labels[i + j] = 'I-FOOD'\n                break  # evita doppi match dello stesso ingrediente\n\n\n    check(labels)\n    \n    return tokens, labels\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:07.263168Z","iopub.execute_input":"2025-05-15T08:38:07.264036Z","iopub.status.idle":"2025-05-15T08:38:07.278833Z","shell.execute_reply.started":"2025-05-15T08:38:07.264011Z","shell.execute_reply":"2025-05-15T08:38:07.278272Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"df_sample[\"ner_tokens_labels\"] = df_sample.apply(\n    lambda row: iob_tag_tokens(row[\"text\"], row[\"clean_ingredients\"]), axis=1\n)\n\"\"\"\nESEMPIO UTILIZZO:\ntext = \"Aggiungi una cipolla tritata e soffriggi in olio.\"\nclean_ingredients = [\"cipolla\", \"olio\"]\n\ntokens = [\"Aggiungi\", \"una\", \"cipolla\", \"tritata\", \"e\", \"soffriggi\", \"in\", \"olio\", \".\"]\nlabels = [\"O\",        \"O\",   \"B-FOOD\", \"I-FOOD\",  \"O\", \"O\",         \"O\", \"B-FOOD\", \"O\"]\n\nRISULTATO FINALE:\n(\"Aggiungi\", ..., \"olio\", \".\"), [\"O\", ..., \"B-FOOD\", \"O\"]\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:07.281236Z","iopub.execute_input":"2025-05-15T08:38:07.281427Z","iopub.status.idle":"2025-05-15T08:38:23.737893Z","shell.execute_reply.started":"2025-05-15T08:38:07.281413Z","shell.execute_reply":"2025-05-15T08:38:23.737311Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'\\nESEMPIO UTILIZZO:\\ntext = \"Aggiungi una cipolla tritata e soffriggi in olio.\"\\nclean_ingredients = [\"cipolla\", \"olio\"]\\n\\ntokens = [\"Aggiungi\", \"una\", \"cipolla\", \"tritata\", \"e\", \"soffriggi\", \"in\", \"olio\", \".\"]\\nlabels = [\"O\",        \"O\",   \"B-FOOD\", \"I-FOOD\",  \"O\", \"O\",         \"O\", \"B-FOOD\", \"O\"]\\n\\nRISULTATO FINALE:\\n(\"Aggiungi\", ..., \"olio\", \".\"), [\"O\", ..., \"B-FOOD\", \"O\"]\\n'"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"tokens, labels = df_sample.loc[0, \"ner_tokens_labels\"]\nfor t, l in zip(tokens, labels):\n    print(f\"{t:15} → {l}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:23.738589Z","iopub.execute_input":"2025-05-15T08:38:23.738908Z","iopub.status.idle":"2025-05-15T08:38:23.743918Z","shell.execute_reply.started":"2025-05-15T08:38:23.738889Z","shell.execute_reply":"2025-05-15T08:38:23.743051Z"}},"outputs":[{"name":"stdout","text":"Mix             → O\ntogether        → O\nthe             → O\ncheese          → O\n,               → O\nolives          → O\n,               → O\nonion           → O\n,               → O\ndried           → B-FOOD\nbeef            → I-FOOD\nand             → O\nmayo            → O\n.               → O\nSpread          → O\non              → O\nslices          → O\nof              → O\nrye             → O\ncocktail        → O\nbread           → O\n.               → O\nplace           → O\nthe             → O\nslices          → O\non              → O\na               → O\ncookie          → O\nsheet           → O\nand             → O\nbroil           → O\nuntil           → O\nbubbly          → O\n.               → O\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"#### Preparazione dell'addestramento","metadata":{}},{"cell_type":"code","source":"!pip install seqeval\n\nfrom datasets import Dataset, ClassLabel\nfrom transformers import AutoTokenizer\nfrom seqeval.metrics import precision_score, recall_score, f1_score\nfrom transformers import DataCollatorForTokenClassification\nfrom transformers import EarlyStoppingCallback\nfrom transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\nfrom seqeval.metrics import precision_score, recall_score, f1_score\nfrom torch.nn import CrossEntropyLoss\nfrom collections import Counter\nimport torch.nn as nn\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:23.744567Z","iopub.execute_input":"2025-05-15T08:38:23.744814Z","iopub.status.idle":"2025-05-15T08:38:26.851306Z","shell.execute_reply.started":"2025-05-15T08:38:23.744791Z","shell.execute_reply":"2025-05-15T08:38:26.850531Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: seqeval in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->seqeval) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->seqeval) (2024.2.0)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"\"\"\"\n([\"Aggiungi\", \"una\", \"cipolla\", \"tritata\", \"finemente\", ...],\n [\"O\",       \"O\",   \"B-FOOD\", \"I-FOOD\", \"O\", ...])\nDIVENTA:\n{\n    \"tokens\": [\"Aggiungi\", \"una\", \"cipolla\", \"tritata\", \"finemente\", ...],\n    \"ner_tags\": [\"O\", \"O\", \"B-FOOD\", \"I-FOOD\", \"O\", ...]\n}\n\"\"\"\n\nhf_data = [\n    {\n        \"tokens\": tokens,\n        \"ner_tags\": labels\n    }\n    for tokens, labels in df_sample[\"ner_tokens_labels\"]\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:26.852379Z","iopub.execute_input":"2025-05-15T08:38:26.852679Z","iopub.status.idle":"2025-05-15T08:38:26.948060Z","shell.execute_reply.started":"2025-05-15T08:38:26.852626Z","shell.execute_reply":"2025-05-15T08:38:26.947231Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"unique_tags = set(tag for row in hf_data for tag in row[\"ner_tags\"])\nunique_tags = sorted(unique_tags)\n\ntag2id = {tag: i for i, tag in enumerate(unique_tags)}\nid2tag = {i: tag for tag, i in tag2id.items()}\n\"\"\"\ntag2id = {\"B-FOOD\": 0, \"I-FOOD\": 1, \"O\": 2}\nid2tag = {0: \"B-FOOD\", 1: \"I-FOOD\", 2: \"O\"}\n\"\"\"\n\n#Sostituisce \"ner_tags\" con una nuova chiave \"labels\" contenente gli ID\nfor row in hf_data:\n    row[\"labels\"] = [tag2id[tag] for tag in row[\"ner_tags\"]]\n    del row[\"ner_tags\"]  \n\n#Conversione in un effetivo dataset\ndataset = Dataset.from_list(hf_data)\ndataset = dataset.train_test_split(test_size=0.1, seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:26.950048Z","iopub.execute_input":"2025-05-15T08:38:26.950280Z","iopub.status.idle":"2025-05-15T08:38:27.420167Z","shell.execute_reply.started":"2025-05-15T08:38:26.950264Z","shell.execute_reply":"2025-05-15T08:38:27.419690Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n\n\"\"\"\nIn teoria, questo metodo permette di andare a tokenizzare e spezzare le parole per inserirle\nall'interno di BERT, o comunque per convertirle prima in uno e-branding e inserirle all'interno\ndi BERT, mantenendo però le etichette corrette. Quindi se spezzo una parola lunga, che era un \nBFOOD, ci saranno alla fine due BFOOD, in teoria.\n\"\"\"\ndef tokenize_and_align_labels(example):\n    tokenized = tokenizer(example[\"tokens\"], is_split_into_words=True, truncation=True)\n    \n    word_ids = tokenized.word_ids()\n    labels = []\n    previous_word_idx = None\n    for word_idx in word_ids:\n        if word_idx is None:\n            labels.append(-100)\n        elif word_idx != previous_word_idx:\n            labels.append(example[\"labels\"][word_idx])\n        else:\n            # Se un word viene splittato in più subtoken, replichiamo la label (o metti -100 se vuoi ignorare)\n            labels.append(example[\"labels\"][word_idx])\n        previous_word_idx = word_idx\n    tokenized[\"labels\"] = labels\n    return tokenized\n\ntokenized_dataset = dataset.map(tokenize_and_align_labels, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:27.421048Z","iopub.execute_input":"2025-05-15T08:38:27.421701Z","iopub.status.idle":"2025-05-15T08:38:37.668836Z","shell.execute_reply.started":"2025-05-15T08:38:27.421674Z","shell.execute_reply":"2025-05-15T08:38:37.668069Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7d60fd419d47eaaa0c69c2a183e50f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44a7560fb5ee4a83a96884ccf0a026c1"}},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"\ndef compute_metrics(pred):\n    predictions, labels = pred\n    predictions = predictions.argmax(axis=2)\n\n    true_labels = []\n    true_preds = []\n\n    for pred_seq, label_seq in zip(predictions, labels):\n        curr_preds = []\n        curr_labels = []\n        for p, l in zip(pred_seq, label_seq):\n            if l != -100:\n                curr_preds.append(id2tag[p])\n                curr_labels.append(id2tag[l])\n        true_preds.append(curr_preds)\n        true_labels.append(curr_labels)\n\n    return {\n        \"precision\": precision_score(true_labels, true_preds),\n        \"recall\": recall_score(true_labels, true_preds),\n        \"f1\": f1_score(true_labels, true_preds)\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:37.669843Z","iopub.execute_input":"2025-05-15T08:38:37.670177Z","iopub.status.idle":"2025-05-15T08:38:37.675423Z","shell.execute_reply.started":"2025-05-15T08:38:37.670153Z","shell.execute_reply":"2025-05-15T08:38:37.674882Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Estrai tutte le etichette\nall_labels = []\nfor example in tokenized_dataset[\"train\"]:\n    all_labels += example[\"labels\"]\n\n# Conta le etichette escludendo i -100 (token ignorati)\nlabel_counts = Counter([label for label in all_labels if label != -100])\ntotal = sum(label_counts.values())\n\n# Calcola peso inverso della frequenza (più rara = peso più alto)\nweights = [0.0] * len(tag2id)\nfor label_id, count in label_counts.items():\n    weights[label_id] = total / (len(label_counts) * count)\n\nweights = torch.tensor(weights).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:38:37.676182Z","iopub.execute_input":"2025-05-15T08:38:37.676475Z","iopub.status.idle":"2025-05-15T08:38:40.744318Z","shell.execute_reply.started":"2025-05-15T08:38:37.676451Z","shell.execute_reply":"2025-05-15T08:38:40.743767Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"from transformers.modeling_outputs import TokenClassifierOutput\n\nclass WeightedTokenClassifier(nn.Module):\n    def __init__(self, base_model, weights):\n        super().__init__()\n        self.base_model = base_model\n        self.loss_fct = CrossEntropyLoss(weight=weights, ignore_index=-100)\n\n    def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n        # Rimuove 'num_items_in_batch' se presente\n        kwargs.pop(\"num_items_in_batch\", None)\n\n        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n        logits = outputs.logits\n\n        loss = None\n        if labels is not None:\n            loss = self.loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n\n        return TokenClassifierOutput(\n            loss=loss,\n            logits=logits,\n            hidden_states=outputs.hidden_states if hasattr(outputs, \"hidden_states\") else None,\n            attentions=outputs.attentions if hasattr(outputs, \"attentions\") else None,\n        )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:41:23.299738Z","iopub.execute_input":"2025-05-15T08:41:23.300356Z","iopub.status.idle":"2025-05-15T08:41:23.306866Z","shell.execute_reply.started":"2025-05-15T08:41:23.300334Z","shell.execute_reply":"2025-05-15T08:41:23.306061Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"base_model = AutoModelForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(tag2id))\nmodel = WeightedTokenClassifier(base_model, weights)\nmodel.to(device)\n\n\nargs = TrainingArguments(\n    output_dir=\"/kaggle/working/\",\n    run_name=\"bert-ner-food-v1\",  # nome run esplicito\n    do_train=True,\n    do_eval=True,\n    logging_steps=100,\n    save_steps=500,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=8,\n    num_train_epochs=6,\n    weight_decay=0.01,\n    report_to=\"none\",  # Disabilita logging verso wandb\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    data_collator=data_collator,\n)\n\n\"\"\"\nNel fine-tuning, serve a:uniformare la lunghezza delle sequenze (padding), \ngestire correttamente i batch, \nallineare i token con le label (soprattutto importante nel NER).\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:41:23.307970Z","iopub.execute_input":"2025-05-15T08:41:23.308191Z","iopub.status.idle":"2025-05-15T08:41:23.706226Z","shell.execute_reply.started":"2025-05-15T08:41:23.308168Z","shell.execute_reply":"2025-05-15T08:41:23.705335Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_31/102190035.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"'\\nNel fine-tuning, serve a:uniformare la lunghezza delle sequenze (padding), \\ngestire correttamente i batch, \\nallineare i token con le label (soprattutto importante nel NER).\\n'"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T08:41:23.707848Z","iopub.execute_input":"2025-05-15T08:41:23.708070Z","iopub.status.idle":"2025-05-15T09:20:08.392833Z","shell.execute_reply.started":"2025-05-15T08:41:23.708054Z","shell.execute_reply":"2025-05-15T09:20:08.392216Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3378' max='3378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3378/3378 38:42, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.391400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.238100</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.239500</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.232300</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.229600</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.204800</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.193600</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.176400</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.183500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.187700</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.176000</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.148300</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.150100</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.147200</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.144200</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.154700</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.136900</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.119500</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.118400</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.118400</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.118000</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.122000</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.107500</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.097200</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.097100</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.094700</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.098500</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.102600</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.085000</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.091100</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.083300</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.085800</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.086100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3378, training_loss=0.14862379722866242, metrics={'train_runtime': 2324.156, 'train_samples_per_second': 23.234, 'train_steps_per_second': 1.453, 'total_flos': 0.0, 'train_loss': 0.14862379722866242, 'epoch': 6.0})"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T09:20:08.393546Z","iopub.execute_input":"2025-05-15T09:20:08.393784Z","iopub.status.idle":"2025-05-15T09:20:18.739404Z","shell.execute_reply.started":"2025-05-15T09:20:08.393767Z","shell.execute_reply":"2025-05-15T09:20:18.738711Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:09]\n    </div>\n    "},"metadata":{}},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.4377688467502594,\n 'eval_precision': 0.3938333697791384,\n 'eval_recall': 0.8878481636677348,\n 'eval_f1': 0.5456335681284556,\n 'eval_runtime': 10.3365,\n 'eval_samples_per_second': 96.744,\n 'eval_steps_per_second': 12.093,\n 'epoch': 6.0}"},"metadata":{}}],"execution_count":49}]}