{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-16T08:48:36.539821Z",
     "iopub.status.busy": "2025-05-16T08:48:36.539571Z",
     "iopub.status.idle": "2025-05-16T08:49:58.216200Z",
     "shell.execute_reply": "2025-05-16T08:49:58.215527Z",
     "shell.execute_reply.started": "2025-05-16T08:48:36.539798Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:49:58.217392Z",
     "iopub.status.busy": "2025-05-16T08:49:58.217129Z",
     "iopub.status.idle": "2025-05-16T08:49:58.221680Z",
     "shell.execute_reply": "2025-05-16T08:49:58.220989Z",
     "shell.execute_reply.started": "2025-05-16T08:49:58.217370Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:49:58.223854Z",
     "iopub.status.busy": "2025-05-16T08:49:58.223539Z",
     "iopub.status.idle": "2025-05-16T08:50:20.450277Z",
     "shell.execute_reply": "2025-05-16T08:50:20.449513Z",
     "shell.execute_reply.started": "2025-05-16T08:49:58.223837Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from datasets import Dataset\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')  \n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/recipe-sampled-0-25/sampled_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:50:20.451402Z",
     "iopub.status.busy": "2025-05-16T08:50:20.451120Z",
     "iopub.status.idle": "2025-05-16T08:50:20.560836Z",
     "shell.execute_reply": "2025-05-16T08:50:20.560194Z",
     "shell.execute_reply.started": "2025-05-16T08:50:20.451378Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directions</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Mix together the cheese, olives, onion, drie...</td>\n",
       "      <td>[\"1 cup shredded cheddar cheese\", \"1 cup chopp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Brown meat; drain and set aside.', 'Blend ma...</td>\n",
       "      <td>[\"1 pie crust\", \"1/2 lb. ground beef (you can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Dissolve jello in boiling water.', 'Let cool...</td>\n",
       "      <td>[\"2 small orange jello\", \"2 c. boiling water\",...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          directions  \\\n",
       "0  ['Mix together the cheese, olives, onion, drie...   \n",
       "1  ['Brown meat; drain and set aside.', 'Blend ma...   \n",
       "2  ['Dissolve jello in boiling water.', 'Let cool...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  [\"1 cup shredded cheddar cheese\", \"1 cup chopp...  \n",
       "1  [\"1 pie crust\", \"1/2 lb. ground beef (you can ...  \n",
       "2  [\"2 small orange jello\", \"2 c. boiling water\",...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df[[\"directions\", \"ingredients\"]].sample(n=80000, random_state=42).reset_index(drop=True)\n",
    "df_sample.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:50:20.561847Z",
     "iopub.status.busy": "2025-05-16T08:50:20.561603Z",
     "iopub.status.idle": "2025-05-16T08:50:24.099428Z",
     "shell.execute_reply": "2025-05-16T08:50:24.098755Z",
     "shell.execute_reply.started": "2025-05-16T08:50:20.561829Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['1 cup shredded cheddar cheese', '1 cup chopped pimento stuffed olive', '1 tablespoon minced onion', '1 cup dried beef, chopped', '3/4 - 1 cup mayonnaise', '1 loaf sliced rye cocktail bread']\n",
      "<class 'list'>\n",
      "['Mix together the cheese, olives, onion, dried beef and mayo.', 'Spread on slices of rye cocktail bread. place the slices on a cookie sheet and broil until bubbly.']\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "df_sample[\"ingredients\"] = df_sample[\"ingredients\"].apply(ast.literal_eval)\n",
    "df_sample[\"directions\"] = df_sample[\"directions\"].apply(ast.literal_eval)\n",
    "\n",
    "print(type(df_sample.loc[0, \"ingredients\"]))  \n",
    "print(df_sample.loc[0, \"ingredients\"])        \n",
    "\n",
    "print(type(df_sample.loc[0, \"directions\"]))  \n",
    "print(df_sample.loc[0, \"directions\"])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:50:24.100297Z",
     "iopub.status.busy": "2025-05-16T08:50:24.100079Z",
     "iopub.status.idle": "2025-05-16T08:50:24.158617Z",
     "shell.execute_reply": "2025-05-16T08:50:24.157933Z",
     "shell.execute_reply.started": "2025-05-16T08:50:24.100280Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mix together the cheese, olives, onion, dried beef and mayo. Spread on slices of rye cocktail bread. place the slices on a cookie sheet and broil until bubbly.\n"
     ]
    }
   ],
   "source": [
    "df_sample[\"text\"] = df_sample[\"directions\"].apply(lambda steps: \" \".join(steps))\n",
    "print(df_sample.loc[0, \"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I try to clean up the ingredients, trying to remove quantities and other unnecessary information; which may not appear in the directions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:50:24.159591Z",
     "iopub.status.busy": "2025-05-16T08:50:24.159318Z",
     "iopub.status.idle": "2025-05-16T08:50:34.590898Z",
     "shell.execute_reply": "2025-05-16T08:50:34.589931Z",
     "shell.execute_reply.started": "2025-05-16T08:50:24.159572Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_ingredient(ingredient):\n",
    "    # Remove fractions and numbers (e.g., \"1\", \"1/2\", \"2.5\")\n",
    "    ingredient = re.sub(r'\\b\\d+([\\/\\.]\\d+)?\\b', '', ingredient)\n",
    "\n",
    "    # Common measurement units to remove\n",
    "    units = [\n",
    "        \"teaspoons?\", \"tsp\", \"tablespoons?\", \"tbsp\", \"cups?\", \"ounces?\", \"oz\",\n",
    "        \"pounds?\", \"lb\", \"grams?\", \"g\", \"kilograms?\", \"kg\", \"milliliters?\", \"ml\",\n",
    "        \"liters?\", \"l\", \"pinch\", \"clove\", \"cloves\", \"slices?\", \"dash\", \"cans?\", \n",
    "        \"packages?\", \"bunch\", \"stalks?\", \"heads?\", \"pieces?\", \"sticks?\", \"inches?\"\n",
    "    ]\n",
    "    units_pattern = r'\\b(?:' + '|'.join(units) + r')\\b'\n",
    "    ingredient = re.sub(units_pattern, '', ingredient, flags=re.IGNORECASE)\n",
    "\n",
    "    ingredient = re.sub(r'\\b(c\\.|c)\\b\\.?', '', ingredient, flags=re.IGNORECASE)\n",
    "\n",
    "    ingredient = re.sub(r'\\(\\s*\\.\\s*\\)', '', ingredient)\n",
    "    ingredient = re.sub(r'\\([^)]*\\)', '', ingredient)\n",
    "\n",
    "    ingredient = re.sub(r'\\bof\\b', '', ingredient, flags=re.IGNORECASE)\n",
    "    ingredient = re.sub(r'^\\s*\\.\\s*', '', ingredient)       # punto iniziale con spazio\n",
    "    ingredient = re.sub(r'\\.\\s*', ' ', ingredient)          # ogni \". \" ovunque\n",
    "    ingredient = re.sub(r',.*', '', ingredient)             # rimuove note dopo virgola\n",
    "\n",
    "    ingredient = re.sub(r'\\b(to |pt |pkg |qt )\\.?\\b', '', ingredient, flags=re.IGNORECASE)\n",
    "    ingredient = re.sub(r'^to\\s+', '', ingredient, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    ingredient = re.sub(r'\\s+', ' ', ingredient).strip()\n",
    "\n",
    "    return ingredient\n",
    "\n",
    "\n",
    "# Applica a tutta la colonna ingredients\n",
    "df_sample[\"clean_ingredients\"] = df_sample[\"ingredients\"].apply(lambda lst: [clean_ingredient(i) for i in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:50:34.591978Z",
     "iopub.status.busy": "2025-05-16T08:50:34.591747Z",
     "iopub.status.idle": "2025-05-16T08:50:34.599045Z",
     "shell.execute_reply": "2025-05-16T08:50:34.598197Z",
     "shell.execute_reply.started": "2025-05-16T08:50:34.591955Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [shredded cheddar cheese, chopped pimento stuf...\n",
      "1     [pie crust, ground beef, mayonnaise, milk, egg...\n",
      "2     [small orange jello, boiling water, small crus...\n",
      "3     [square graham crackers, reduced calorie marga...\n",
      "4     [cream cheese, sm jar Old English cheese, Lipt...\n",
      "5     [MIRACLE WHIP Dressing, BREAKSTONE'S or KNUDSE...\n",
      "6     [FOR THE FILLING:, Fresh Strawberries, - Fresh...\n",
      "7     [doz mangos, cabbage, celery, brown sugar, sal...\n",
      "8     [chopped green peppers, chopped red peppers, c...\n",
      "9     [fryer, uncooked rice, cream chicken soup, dry...\n",
      "10    [yeast, bread flour, salt, sugar, olive oil, w...\n",
      "Name: clean_ingredients, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_sample.loc[:10, \"clean_ingredients\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignlabels: \"0\" \"I-food\" \"B-food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:50:34.601994Z",
     "iopub.status.busy": "2025-05-16T08:50:34.601781Z",
     "iopub.status.idle": "2025-05-16T08:50:34.865060Z",
     "shell.execute_reply": "2025-05-16T08:50:34.864237Z",
     "shell.execute_reply.started": "2025-05-16T08:50:34.601977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def check(labels):\n",
    "    for i, label in enumerate(labels):\n",
    "        if label == 'I-FOOD':\n",
    "            if i == 0 or labels[i - 1] not in ['B-FOOD', 'I-FOOD']:\n",
    "                raise ValueError(f\"Incoerenza IOB: I-FOOD alla posizione {i} senza B-FOOD precedente.\")\n",
    "\n",
    "\n",
    "\n",
    "def iob_tag_tokens(text, ingredient_list):\n",
    "    tokens = word_tokenize(text)\n",
    "    labels = ['O'] * len(tokens)\n",
    "    \n",
    "    for ingredient in ingredient_list:\n",
    "        ingredient_tokens = word_tokenize(ingredient)\n",
    "        ingredient_len = len(ingredient_tokens)\n",
    "\n",
    "        if ingredient_len == 0:\n",
    "            continue  # ignora ingredienti vuoti\n",
    "\n",
    "        for i in range(len(tokens) - ingredient_len + 1):\n",
    "            window = tokens[i:i + ingredient_len]\n",
    "            if [t.lower() for t in window] == [t.lower() for t in ingredient_tokens]:\n",
    "                labels[i] = 'B-FOOD'\n",
    "                for j in range(1, ingredient_len):\n",
    "                    if i + j < len(labels):\n",
    "                        labels[i + j] = 'I-FOOD'\n",
    "                break  # evita doppi match dello stesso ingrediente\n",
    "\n",
    "\n",
    "    check(labels)\n",
    "    \n",
    "    return tokens, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:50:34.866565Z",
     "iopub.status.busy": "2025-05-16T08:50:34.866243Z",
     "iopub.status.idle": "2025-05-16T08:52:42.439298Z",
     "shell.execute_reply": "2025-05-16T08:52:42.438439Z",
     "shell.execute_reply.started": "2025-05-16T08:50:34.866539Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_sample[\"ner_tokens_labels\"] = df_sample.apply(\n",
    "    lambda row: iob_tag_tokens(row[\"text\"], row[\"clean_ingredients\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESEMPIO UTILIZZO:\n",
    "text = \"Aggiungi una cipolla tritata e soffriggi in olio.\"\n",
    "clean_ingredients = [\"cipolla\", \"olio\"]\n",
    "\n",
    "tokens = [\"Aggiungi\", \"una\", \"cipolla\", \"tritata\", \"e\", \"soffriggi\", \"in\", \"olio\", \".\"]\n",
    "labels = [\"O\",        \"O\",   \"B-FOOD\", \"I-FOOD\",  \"O\", \"O\",         \"O\", \"B-FOOD\", \"O\"]\n",
    "\n",
    "RISULTATO FINALE:\n",
    "(\"Aggiungi\", ..., \"olio\", \".\"), [\"O\", ..., \"B-FOOD\", \"O\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:52:42.441087Z",
     "iopub.status.busy": "2025-05-16T08:52:42.440164Z",
     "iopub.status.idle": "2025-05-16T08:52:42.446275Z",
     "shell.execute_reply": "2025-05-16T08:52:42.445499Z",
     "shell.execute_reply.started": "2025-05-16T08:52:42.441062Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mix             → O\n",
      "together        → O\n",
      "the             → O\n",
      "cheese          → O\n",
      ",               → O\n",
      "olives          → O\n",
      ",               → O\n",
      "onion           → O\n",
      ",               → O\n",
      "dried           → B-FOOD\n",
      "beef            → I-FOOD\n",
      "and             → O\n",
      "mayo            → O\n",
      ".               → O\n",
      "Spread          → O\n",
      "on              → O\n",
      "slices          → O\n",
      "of              → O\n",
      "rye             → O\n",
      "cocktail        → O\n",
      "bread           → O\n",
      ".               → O\n",
      "place           → O\n",
      "the             → O\n",
      "slices          → O\n",
      "on              → O\n",
      "a               → O\n",
      "cookie          → O\n",
      "sheet           → O\n",
      "and             → O\n",
      "broil           → O\n",
      "until           → O\n",
      "bubbly          → O\n",
      ".               → O\n"
     ]
    }
   ],
   "source": [
    "tokens, labels = df_sample.loc[0, \"ner_tokens_labels\"]\n",
    "for t, l in zip(tokens, labels):\n",
    "    print(f\"{t:15} → {l}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:52:42.447297Z",
     "iopub.status.busy": "2025-05-16T08:52:42.447047Z",
     "iopub.status.idle": "2025-05-16T08:53:08.064390Z",
     "shell.execute_reply": "2025-05-16T08:53:08.063756Z",
     "shell.execute_reply.started": "2025-05-16T08:52:42.447274Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2.4.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->seqeval) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->seqeval) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->seqeval) (2024.2.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=e0cb99ffa0fc705f41d18cc96a2fcf0f09cdf0d1831ff2da4d8130eb49362f6f\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 08:52:49.672048: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747385569.898491      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747385569.963818      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval\n",
    "\n",
    "from datasets import Dataset, ClassLabel\n",
    "from transformers import AutoTokenizer\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:53:08.065805Z",
     "iopub.status.busy": "2025-05-16T08:53:08.065155Z",
     "iopub.status.idle": "2025-05-16T08:53:08.133062Z",
     "shell.execute_reply": "2025-05-16T08:53:08.132507Z",
     "shell.execute_reply.started": "2025-05-16T08:53:08.065773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hf_data = [\n",
    "    {\n",
    "        \"tokens\": tokens,\n",
    "        \"ner_tags\": labels\n",
    "    }\n",
    "    for tokens, labels in df_sample[\"ner_tokens_labels\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This:\n",
    "(\n",
    "    [\"Aggiungi\", \"una\", \"cipolla\", \"tritata\", \"finemente\", ...],\n",
    "    [\"O\",       \"O\",   \"B-FOOD\", \"I-FOOD\", \"O\", ...]\n",
    ")\n",
    "into :\n",
    "{\n",
    "    \"tokens\": [\"Aggiungi\", \"una\", \"cipolla\", \"tritata\", \"finemente\", ...],\n",
    "    \"ner_tags\": [\"O\", \"O\", \"B-FOOD\", \"I-FOOD\", \"O\", ...]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:53:08.133902Z",
     "iopub.status.busy": "2025-05-16T08:53:08.133708Z",
     "iopub.status.idle": "2025-05-16T08:53:11.855049Z",
     "shell.execute_reply": "2025-05-16T08:53:11.854500Z",
     "shell.execute_reply.started": "2025-05-16T08:53:08.133886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Extract unique NER tags from the dataset and sort them\n",
    "unique_tags = set(tag for row in hf_data for tag in row[\"ner_tags\"])\n",
    "unique_tags = sorted(unique_tags)\n",
    "\n",
    "# Create mappings from tag to id and id to tag for label encoding/decoding\n",
    "tag2id = {tag: i for i, tag in enumerate(unique_tags)}\n",
    "id2tag = {i: tag for tag, i in tag2id.items()}\n",
    "\n",
    "# Convert string NER tags to integer labels for each example\n",
    "for row in hf_data:\n",
    "    row[\"labels\"] = [tag2id[tag] for tag in row[\"ner_tags\"]]\n",
    "    del row[\"ner_tags\"]  # Remove the original string tags\n",
    "\n",
    "# Create a HuggingFace Dataset and split into train and test sets\n",
    "dataset = Dataset.from_list(hf_data)\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:53:11.855969Z",
     "iopub.status.busy": "2025-05-16T08:53:11.855760Z",
     "iopub.status.idle": "2025-05-16T08:54:28.116714Z",
     "shell.execute_reply": "2025-05-16T08:54:28.115808Z",
     "shell.execute_reply.started": "2025-05-16T08:53:11.855952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer and prepare the data collator for token classification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "def tokenize_and_align_labels(example):\n",
    "    \"\"\"\n",
    "    Tokenizes input tokens and aligns the NER labels with the resulting wordpieces.\n",
    "    For each token, the corresponding label is assigned to all subword tokens.\n",
    "    Non-aligned tokens (special tokens) are assigned a label of -100 to be ignored in loss computation.\n",
    "    \"\"\"\n",
    "    tokenized = tokenizer(example[\"tokens\"], is_split_into_words=True, truncation=True)\n",
    "    \n",
    "    word_ids = tokenized.word_ids()\n",
    "    labels = []\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            labels.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            labels.append(example[\"labels\"][word_idx])\n",
    "        else:\n",
    "            labels.append(example[\"labels\"][word_idx])\n",
    "        previous_word_idx = word_idx\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized\n",
    "\n",
    "# Apply the tokenization and label alignment to the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of “custom” metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:54:28.117754Z",
     "iopub.status.busy": "2025-05-16T08:54:28.117447Z",
     "iopub.status.idle": "2025-05-16T08:54:28.123096Z",
     "shell.execute_reply": "2025-05-16T08:54:28.122337Z",
     "shell.execute_reply.started": "2025-05-16T08:54:28.117735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Computes precision, recall, and F1 score for token classification tasks.\n",
    "    Args:\n",
    "        pred: A tuple (predictions, labels) as returned by the Trainer.\n",
    "            - predictions: numpy array of shape (batch_size, seq_len, num_labels)\n",
    "            - labels: numpy array of shape (batch_size, seq_len)\n",
    "    Returns:\n",
    "        A dictionary with precision, recall, and f1 score.\n",
    "    \"\"\"\n",
    "    predictions, labels = pred\n",
    "    predictions = predictions.argmax(axis=2)\n",
    "\n",
    "    true_labels = []\n",
    "    true_preds = []\n",
    "\n",
    "    for pred_seq, label_seq in zip(predictions, labels):\n",
    "        curr_preds = []\n",
    "        curr_labels = []\n",
    "        for p, l in zip(pred_seq, label_seq):\n",
    "            if l != -100:  # Ignore special tokens\n",
    "                curr_preds.append(id2tag[p])\n",
    "                curr_labels.append(id2tag[l])\n",
    "        true_preds.append(curr_preds)\n",
    "        true_labels.append(curr_labels)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, true_preds),\n",
    "        \"recall\": recall_score(true_labels, true_preds),\n",
    "        \"f1\": f1_score(true_labels, true_preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the weighted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:54:28.124167Z",
     "iopub.status.busy": "2025-05-16T08:54:28.123920Z",
     "iopub.status.idle": "2025-05-16T08:54:49.915166Z",
     "shell.execute_reply": "2025-05-16T08:54:49.914598Z",
     "shell.execute_reply.started": "2025-05-16T08:54:28.124146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Select device: use GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Gather all label ids from the training set (excluding special tokens with label -100)\n",
    "all_labels = []\n",
    "for example in tokenized_dataset[\"train\"]:\n",
    "    all_labels += example[\"labels\"]\n",
    "\n",
    "# Count occurrences of each label (excluding -100)\n",
    "label_counts = Counter([label for label in all_labels if label != -100])\n",
    "total = sum(label_counts.values())\n",
    "\n",
    "# Compute class weights inversely proportional to class frequency\n",
    "# This helps to handle class imbalance during training\n",
    "weights = [0.0] * len(tag2id)\n",
    "for label_id, count in label_counts.items():\n",
    "    weights[label_id] = total / (len(label_counts) * count)\n",
    "\n",
    "# Convert weights to a tensor and move to the selected device\n",
    "weights = torch.tensor(weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:54:49.916205Z",
     "iopub.status.busy": "2025-05-16T08:54:49.915945Z",
     "iopub.status.idle": "2025-05-16T08:54:49.922104Z",
     "shell.execute_reply": "2025-05-16T08:54:49.921517Z",
     "shell.execute_reply.started": "2025-05-16T08:54:49.916182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "\n",
    "class WeightedTokenClassifier(nn.Module):\n",
    "    def __init__(self, base_model, weights):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.loss_fct = CrossEntropyLoss(weight=weights, ignore_index=-100)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n",
    "        # Rimuove 'num_items_in_batch' se presente\n",
    "        kwargs.pop(\"num_items_in_batch\", None)\n",
    "\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states if hasattr(outputs, \"hidden_states\") else None,\n",
    "            attentions=outputs.attentions if hasattr(outputs, \"attentions\") else None,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:54:49.923120Z",
     "iopub.status.busy": "2025-05-16T08:54:49.922893Z",
     "iopub.status.idle": "2025-05-16T08:54:52.068088Z",
     "shell.execute_reply": "2025-05-16T08:54:52.067221Z",
     "shell.execute_reply.started": "2025-05-16T08:54:49.923093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_model = AutoModelForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(tag2id))\n",
    "model = WeightedTokenClassifier(base_model, weights)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/\",\n",
    "    run_name=\"bert-ner-food-v1\",  # nome run esplicito\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=100,\n",
    "    save_steps=5000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",  # Disabilita logging verso wandb\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:54:52.069638Z",
     "iopub.status.busy": "2025-05-16T08:54:52.068954Z",
     "iopub.status.idle": "2025-05-16T15:06:50.627410Z",
     "shell.execute_reply": "2025-05-16T15:06:50.626455Z",
     "shell.execute_reply.started": "2025-05-16T08:54:52.069619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T15:06:50.628770Z",
     "iopub.status.busy": "2025-05-16T15:06:50.628328Z",
     "iopub.status.idle": "2025-05-16T15:09:31.447529Z",
     "shell.execute_reply": "2025-05-16T15:09:31.446847Z",
     "shell.execute_reply.started": "2025-05-16T15:06:50.628752Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7276106,
     "sourceId": 11601525,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
