{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11601525,"sourceType":"datasetVersion","datasetId":7276106}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:56:40.037242Z","iopub.execute_input":"2025-05-17T10:56:40.037506Z","iopub.status.idle":"2025-05-17T10:57:54.540384Z","shell.execute_reply.started":"2025-05-17T10:56:40.037483Z","shell.execute_reply":"2025-05-17T10:57:54.539433Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:57:54.541742Z","iopub.execute_input":"2025-05-17T10:57:54.541989Z","iopub.status.idle":"2025-05-17T10:57:54.546102Z","shell.execute_reply.started":"2025-05-17T10:57:54.541967Z","shell.execute_reply":"2025-05-17T10:57:54.545574Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom datasets import Dataset\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nimport re\nimport nltk\nfrom nltk.tokenize import word_tokenize\n\nnltk.download('punkt')  \n\n\ndf = pd.read_csv(\"/kaggle/input/recipe-sampled-0-25/sampled_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:57:54.546832Z","iopub.execute_input":"2025-05-17T10:57:54.547072Z","iopub.status.idle":"2025-05-17T10:58:16.562628Z","shell.execute_reply.started":"2025-05-17T10:57:54.547050Z","shell.execute_reply":"2025-05-17T10:58:16.561990Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"#### Preparazione del dataset","metadata":{}},{"cell_type":"code","source":"df_sample = df[[\"directions\", \"ingredients\"]].sample(n=100000, random_state=42).reset_index(drop=True)\ndf_sample.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:58:16.564676Z","iopub.execute_input":"2025-05-17T10:58:16.564924Z","iopub.status.idle":"2025-05-17T10:58:16.675017Z","shell.execute_reply.started":"2025-05-17T10:58:16.564905Z","shell.execute_reply":"2025-05-17T10:58:16.674439Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                          directions  \\\n0  ['Mix together the cheese, olives, onion, drie...   \n1  ['Brown meat; drain and set aside.', 'Blend ma...   \n2  ['Dissolve jello in boiling water.', 'Let cool...   \n\n                                         ingredients  \n0  [\"1 cup shredded cheddar cheese\", \"1 cup chopp...  \n1  [\"1 pie crust\", \"1/2 lb. ground beef (you can ...  \n2  [\"2 small orange jello\", \"2 c. boiling water\",...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>directions</th>\n      <th>ingredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['Mix together the cheese, olives, onion, drie...</td>\n      <td>[\"1 cup shredded cheddar cheese\", \"1 cup chopp...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['Brown meat; drain and set aside.', 'Blend ma...</td>\n      <td>[\"1 pie crust\", \"1/2 lb. ground beef (you can ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['Dissolve jello in boiling water.', 'Let cool...</td>\n      <td>[\"2 small orange jello\", \"2 c. boiling water\",...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import ast\n\ndf_sample[\"ingredients\"] = df_sample[\"ingredients\"].apply(ast.literal_eval)\ndf_sample[\"directions\"] = df_sample[\"directions\"].apply(ast.literal_eval)\n\nprint(type(df_sample.loc[0, \"ingredients\"]))  # deve essere <class 'list'>\nprint(df_sample.loc[0, \"ingredients\"])        # stampa la lista vera\n\nprint(type(df_sample.loc[0, \"directions\"]))  # deve essere <class 'list'>\nprint(df_sample.loc[0, \"directions\"])        # stampa la lista vera","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:58:16.675738Z","iopub.execute_input":"2025-05-17T10:58:16.676014Z","iopub.status.idle":"2025-05-17T10:58:20.957836Z","shell.execute_reply.started":"2025-05-17T10:58:16.675990Z","shell.execute_reply":"2025-05-17T10:58:20.957073Z"}},"outputs":[{"name":"stdout","text":"<class 'list'>\n['1 cup shredded cheddar cheese', '1 cup chopped pimento stuffed olive', '1 tablespoon minced onion', '1 cup dried beef, chopped', '3/4 - 1 cup mayonnaise', '1 loaf sliced rye cocktail bread']\n<class 'list'>\n['Mix together the cheese, olives, onion, dried beef and mayo.', 'Spread on slices of rye cocktail bread. place the slices on a cookie sheet and broil until bubbly.']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df_sample[\"text\"] = df_sample[\"directions\"].apply(lambda steps: \" \".join(steps))\nprint(df_sample.loc[0, \"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:58:20.958671Z","iopub.execute_input":"2025-05-17T10:58:20.958930Z","iopub.status.idle":"2025-05-17T10:58:21.032283Z","shell.execute_reply.started":"2025-05-17T10:58:20.958905Z","shell.execute_reply":"2025-05-17T10:58:21.031451Z"}},"outputs":[{"name":"stdout","text":"Mix together the cheese, olives, onion, dried beef and mayo. Spread on slices of rye cocktail bread. place the slices on a cookie sheet and broil until bubbly.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Queste regole regex non sono complete, non coprono tutti i casi. Bisognerebbe aggiunge man mano, ma è una operazione complicata","metadata":{}},{"cell_type":"code","source":"import re\n\ndef clean_ingredient(ingredient):\n    # Remove fractions and numbers (e.g., \"1\", \"1/2\", \"2.5\")\n    ingredient = re.sub(r'\\b\\d+([\\/\\.]\\d+)?\\b', '', ingredient)\n\n    # Common measurement units to remove\n    units = [\n        \"teaspoons?\", \"tsp\", \"tablespoons?\", \"tbsp\", \"cups?\", \"ounces?\", \"oz\",\n        \"pounds?\", \"lb\", \"grams?\", \"g\", \"kilograms?\", \"kg\", \"milliliters?\", \"ml\",\n        \"liters?\", \"l\", \"pinch\", \"clove\", \"cloves\", \"slices?\", \"dash\", \"cans?\", \n        \"packages?\", \"bunch\", \"stalks?\", \"heads?\", \"pieces?\", \"sticks?\", \"inches?\"\n    ]\n    units_pattern = r'\\b(?:' + '|'.join(units) + r')\\b'\n    ingredient = re.sub(units_pattern, '', ingredient, flags=re.IGNORECASE)\n\n    ingredient = re.sub(r'\\b(c\\.|c)\\b\\.?', '', ingredient, flags=re.IGNORECASE)\n\n    ingredient = re.sub(r'\\(\\s*\\.\\s*\\)', '', ingredient)\n    ingredient = re.sub(r'\\([^)]*\\)', '', ingredient)\n\n    ingredient = re.sub(r'\\bof\\b', '', ingredient, flags=re.IGNORECASE)\n    ingredient = re.sub(r'^\\s*\\.\\s*', '', ingredient)       # punto iniziale con spazio\n    ingredient = re.sub(r'\\.\\s*', ' ', ingredient)          # ogni \". \" ovunque\n    ingredient = re.sub(r',.*', '', ingredient)             # rimuove note dopo virgola\n\n    ingredient = re.sub(r'\\b(to |pt |pkg |qt )\\.?\\b', '', ingredient, flags=re.IGNORECASE)\n    ingredient = re.sub(r'^to\\s+', '', ingredient, flags=re.IGNORECASE)\n\n    # Remove extra spaces\n    ingredient = re.sub(r'\\s+', ' ', ingredient).strip()\n\n    return ingredient\n\n\n# Applica a tutta la colonna ingredients\ndf_sample[\"clean_ingredients\"] = df_sample[\"ingredients\"].apply(lambda lst: [clean_ingredient(i) for i in lst])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:58:21.033290Z","iopub.execute_input":"2025-05-17T10:58:21.033592Z","iopub.status.idle":"2025-05-17T10:58:35.113013Z","shell.execute_reply.started":"2025-05-17T10:58:21.033567Z","shell.execute_reply":"2025-05-17T10:58:35.112452Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(df_sample.loc[:10, \"clean_ingredients\"]) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:58:35.113704Z","iopub.execute_input":"2025-05-17T10:58:35.113929Z","iopub.status.idle":"2025-05-17T10:58:35.119808Z","shell.execute_reply.started":"2025-05-17T10:58:35.113904Z","shell.execute_reply":"2025-05-17T10:58:35.118946Z"}},"outputs":[{"name":"stdout","text":"0     [shredded cheddar cheese, chopped pimento stuf...\n1     [pie crust, ground beef, mayonnaise, milk, egg...\n2     [small orange jello, boiling water, small crus...\n3     [square graham crackers, reduced calorie marga...\n4     [cream cheese, sm jar Old English cheese, Lipt...\n5     [MIRACLE WHIP Dressing, BREAKSTONE'S or KNUDSE...\n6     [FOR THE FILLING:, Fresh Strawberries, - Fresh...\n7     [doz mangos, cabbage, celery, brown sugar, sal...\n8     [chopped green peppers, chopped red peppers, c...\n9     [fryer, uncooked rice, cream chicken soup, dry...\n10    [yeast, bread flour, salt, sugar, olive oil, w...\nName: clean_ingredients, dtype: object\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"Assegno le label \"0\" \"I-food\" \"B-food\"","metadata":{}},{"cell_type":"code","source":"\ndef check(labels):\n      # 🔍 Verifica coerenza: nessun I-FOOD senza un B-FOOD prima\n    for i, label in enumerate(labels):\n        if label == 'I-FOOD':\n            if i == 0 or labels[i - 1] not in ['B-FOOD', 'I-FOOD']:\n                raise ValueError(f\"Incoerenza IOB: I-FOOD alla posizione {i} senza B-FOOD precedente.\")\n\n\n\ndef iob_tag_tokens(text, ingredient_list):\n    tokens = word_tokenize(text)\n    labels = ['O'] * len(tokens)\n    \n    for ingredient in ingredient_list:\n        ingredient_tokens = word_tokenize(ingredient)\n        ingredient_len = len(ingredient_tokens)\n\n        if ingredient_len == 0:\n            continue  # ignora ingredienti vuoti\n\n        for i in range(len(tokens) - ingredient_len + 1):\n            window = tokens[i:i + ingredient_len]\n            if [t.lower() for t in window] == [t.lower() for t in ingredient_tokens]:\n                labels[i] = 'B-FOOD'\n                for j in range(1, ingredient_len):\n                    if i + j < len(labels):\n                        labels[i + j] = 'I-FOOD'\n                break  # evita doppi match dello stesso ingrediente\n\n\n    check(labels)\n    \n    return tokens, labels\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:58:35.120680Z","iopub.execute_input":"2025-05-17T10:58:35.120889Z","iopub.status.idle":"2025-05-17T10:58:35.161527Z","shell.execute_reply.started":"2025-05-17T10:58:35.120874Z","shell.execute_reply":"2025-05-17T10:58:35.160812Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df_sample[\"ner_tokens_labels\"] = df_sample.apply(\n    lambda row: iob_tag_tokens(row[\"text\"], row[\"clean_ingredients\"]), axis=1\n)\n\"\"\"\nESEMPIO UTILIZZO:\ntext = \"Aggiungi una cipolla tritata e soffriggi in olio.\"\nclean_ingredients = [\"cipolla\", \"olio\"]\n\ntokens = [\"Aggiungi\", \"una\", \"cipolla\", \"tritata\", \"e\", \"soffriggi\", \"in\", \"olio\", \".\"]\nlabels = [\"O\",        \"O\",   \"B-FOOD\", \"I-FOOD\",  \"O\", \"O\",         \"O\", \"B-FOOD\", \"O\"]\n\nRISULTATO FINALE:\n(\"Aggiungi\", ..., \"olio\", \".\"), [\"O\", ..., \"B-FOOD\", \"O\"]\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:58:35.164250Z","iopub.execute_input":"2025-05-17T10:58:35.164692Z","iopub.status.idle":"2025-05-17T11:01:13.155919Z","shell.execute_reply.started":"2025-05-17T10:58:35.164675Z","shell.execute_reply":"2025-05-17T11:01:13.155277Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'\\nESEMPIO UTILIZZO:\\ntext = \"Aggiungi una cipolla tritata e soffriggi in olio.\"\\nclean_ingredients = [\"cipolla\", \"olio\"]\\n\\ntokens = [\"Aggiungi\", \"una\", \"cipolla\", \"tritata\", \"e\", \"soffriggi\", \"in\", \"olio\", \".\"]\\nlabels = [\"O\",        \"O\",   \"B-FOOD\", \"I-FOOD\",  \"O\", \"O\",         \"O\", \"B-FOOD\", \"O\"]\\n\\nRISULTATO FINALE:\\n(\"Aggiungi\", ..., \"olio\", \".\"), [\"O\", ..., \"B-FOOD\", \"O\"]\\n'"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"tokens, labels = df_sample.loc[0, \"ner_tokens_labels\"]\nfor t, l in zip(tokens, labels):\n    print(f\"{t:15} → {l}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T11:01:13.156619Z","iopub.execute_input":"2025-05-17T11:01:13.156877Z","iopub.status.idle":"2025-05-17T11:01:13.161822Z","shell.execute_reply.started":"2025-05-17T11:01:13.156852Z","shell.execute_reply":"2025-05-17T11:01:13.161290Z"}},"outputs":[{"name":"stdout","text":"Mix             → O\ntogether        → O\nthe             → O\ncheese          → O\n,               → O\nolives          → O\n,               → O\nonion           → O\n,               → O\ndried           → B-FOOD\nbeef            → I-FOOD\nand             → O\nmayo            → O\n.               → O\nSpread          → O\non              → O\nslices          → O\nof              → O\nrye             → O\ncocktail        → O\nbread           → O\n.               → O\nplace           → O\nthe             → O\nslices          → O\non              → O\na               → O\ncookie          → O\nsheet           → O\nand             → O\nbroil           → O\nuntil           → O\nbubbly          → O\n.               → O\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"#### Preparazione dell'addestramento","metadata":{}},{"cell_type":"code","source":"!pip install seqeval\n\nfrom datasets import Dataset, ClassLabel\nfrom transformers import AutoTokenizer\nfrom seqeval.metrics import precision_score, recall_score, f1_score\nfrom transformers import DataCollatorForTokenClassification\nfrom transformers import EarlyStoppingCallback\nfrom transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\nfrom seqeval.metrics import precision_score, recall_score, f1_score\nfrom torch.nn import CrossEntropyLoss\nfrom collections import Counter\nimport torch.nn as nn\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T11:01:13.162583Z","iopub.execute_input":"2025-05-17T11:01:13.162747Z","iopub.status.idle":"2025-05-17T11:01:39.357722Z","shell.execute_reply.started":"2025-05-17T11:01:13.162734Z","shell.execute_reply":"2025-05-17T11:01:39.356926Z"}},"outputs":[{"name":"stdout","text":"Collecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->seqeval) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=c5fe456d3a01b10be7547e6557e641e2a21fe64cdca447048fd7a79d29591b88\n  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n","output_type":"stream"},{"name":"stderr","text":"2025-05-17 11:01:20.187610: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747479680.386737      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747479680.443769      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"\"\"\"\n([\"Aggiungi\", \"una\", \"cipolla\", \"tritata\", \"finemente\", ...],\n [\"O\",       \"O\",   \"B-FOOD\", \"I-FOOD\", \"O\", ...])\nDIVENTA:\n{\n    \"tokens\": [\"Aggiungi\", \"una\", \"cipolla\", \"tritata\", \"finemente\", ...],\n    \"ner_tags\": [\"O\", \"O\", \"B-FOOD\", \"I-FOOD\", \"O\", ...]\n}\n\"\"\"\n\nhf_data = [\n    {\n        \"tokens\": tokens,\n        \"ner_tags\": labels\n    }\n    for tokens, labels in df_sample[\"ner_tokens_labels\"]\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T11:01:39.358656Z","iopub.execute_input":"2025-05-17T11:01:39.359275Z","iopub.status.idle":"2025-05-17T11:01:40.314783Z","shell.execute_reply.started":"2025-05-17T11:01:39.359248Z","shell.execute_reply":"2025-05-17T11:01:40.314215Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"unique_tags = set(tag for row in hf_data for tag in row[\"ner_tags\"])\nunique_tags = sorted(unique_tags)\n\ntag2id = {tag: i for i, tag in enumerate(unique_tags)}\nid2tag = {i: tag for tag, i in tag2id.items()}\n\"\"\"\ntag2id = {\"B-FOOD\": 0, \"I-FOOD\": 1, \"O\": 2}\nid2tag = {0: \"B-FOOD\", 1: \"I-FOOD\", 2: \"O\"}\n\"\"\"\n\n#Sostituisce \"ner_tags\" con una nuova chiave \"labels\" contenente gli ID\nfor row in hf_data:\n    row[\"labels\"] = [tag2id[tag] for tag in row[\"ner_tags\"]]\n    del row[\"ner_tags\"]  \n\n#Conversione in un effetivo dataset\ndataset = Dataset.from_list(hf_data)\ndataset = dataset.train_test_split(test_size=0.2, seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T11:01:40.315529Z","iopub.execute_input":"2025-05-17T11:01:40.315753Z","iopub.status.idle":"2025-05-17T11:01:44.947800Z","shell.execute_reply.started":"2025-05-17T11:01:40.315737Z","shell.execute_reply":"2025-05-17T11:01:44.947218Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n\n\"\"\"\nIn teoria, questo metodo permette di andare a tokenizzare e spezzare le parole per inserirle\nall'interno di BERT, o comunque per convertirle prima in uno e-branding e inserirle all'interno\ndi BERT, mantenendo però le etichette corrette. Quindi se spezzo una parola lunga, che era un \nBFOOD, ci saranno alla fine due BFOOD, in teoria.\n\"\"\"\ndef tokenize_and_align_labels(example):\n    tokenized = tokenizer(example[\"tokens\"], is_split_into_words=True, truncation=True)\n    \n    word_ids = tokenized.word_ids()\n    labels = []\n    previous_word_idx = None\n    for word_idx in word_ids:\n        if word_idx is None:\n            labels.append(-100)\n        elif word_idx != previous_word_idx:\n            labels.append(example[\"labels\"][word_idx])\n        else:\n            # Se un word viene splittato in più subtoken, replichiamo la label (o metti -100 se vuoi ignorare)\n            labels.append(example[\"labels\"][word_idx])\n        previous_word_idx = word_idx\n    tokenized[\"labels\"] = labels\n    return tokenized\n\ntokenized_dataset = dataset.map(tokenize_and_align_labels, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T11:01:44.948612Z","iopub.execute_input":"2025-05-17T11:01:44.948834Z","iopub.status.idle":"2025-05-17T11:03:19.608005Z","shell.execute_reply.started":"2025-05-17T11:01:44.948815Z","shell.execute_reply":"2025-05-17T11:03:19.607353Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f05cf7203c242dca2e1a0a054c9b30c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"643bfc92720c4519b8af191d935dd14c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca835a1dbde3475cb1baacb2b11dda76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22e775c00f8444b1a752462691d7ff8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/80000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3633a4e7eac7454793f0e19fe578ff3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c8da68b25de48849d82bf828e6ce817"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"\ndef compute_metrics(pred):\n    predictions, labels = pred\n    predictions = predictions.argmax(axis=2)\n\n    true_labels = []\n    true_preds = []\n\n    for pred_seq, label_seq in zip(predictions, labels):\n        curr_preds = []\n        curr_labels = []\n        for p, l in zip(pred_seq, label_seq):\n            if l != -100:\n                curr_preds.append(id2tag[p])\n                curr_labels.append(id2tag[l])\n        true_preds.append(curr_preds)\n        true_labels.append(curr_labels)\n\n    return {\n        \"precision\": precision_score(true_labels, true_preds),\n        \"recall\": recall_score(true_labels, true_preds),\n        \"f1\": f1_score(true_labels, true_preds)\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T11:03:19.608975Z","iopub.execute_input":"2025-05-17T11:03:19.609201Z","iopub.status.idle":"2025-05-17T11:03:19.614724Z","shell.execute_reply.started":"2025-05-17T11:03:19.609184Z","shell.execute_reply":"2025-05-17T11:03:19.613850Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Estrai tutte le etichette\nall_labels = []\nfor example in tokenized_dataset[\"train\"]:\n    all_labels += example[\"labels\"]\n\n# Conta le etichette escludendo i -100 (token ignorati)\nlabel_counts = Counter([label for label in all_labels if label != -100])\ntotal = sum(label_counts.values())\n\n# Calcola peso inverso della frequenza (più rara = peso più alto)\nweights = [0.0] * len(tag2id)\nfor label_id, count in label_counts.items():\n    weights[label_id] = total / (len(label_counts) * count)\n\nweights = torch.tensor(weights).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T11:03:19.615572Z","iopub.execute_input":"2025-05-17T11:03:19.615830Z","iopub.status.idle":"2025-05-17T11:03:48.375776Z","shell.execute_reply.started":"2025-05-17T11:03:19.615813Z","shell.execute_reply":"2025-05-17T11:03:48.375214Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from transformers.modeling_outputs import TokenClassifierOutput\n\nclass WeightedTokenClassifier(nn.Module):\n    def __init__(self, base_model, weights):\n        super().__init__()\n        self.base_model = base_model\n        self.loss_fct = CrossEntropyLoss(weight=weights, ignore_index=-100)\n\n    def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n        # Rimuove 'num_items_in_batch' se presente\n        kwargs.pop(\"num_items_in_batch\", None)\n\n        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n        logits = outputs.logits\n\n        loss = None\n        if labels is not None:\n            loss = self.loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n\n        return TokenClassifierOutput(\n            loss=loss,\n            logits=logits,\n            hidden_states=outputs.hidden_states if hasattr(outputs, \"hidden_states\") else None,\n            attentions=outputs.attentions if hasattr(outputs, \"attentions\") else None,\n        )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T11:03:48.376516Z","iopub.execute_input":"2025-05-17T11:03:48.376731Z","iopub.status.idle":"2025-05-17T11:03:48.382629Z","shell.execute_reply.started":"2025-05-17T11:03:48.376715Z","shell.execute_reply":"2025-05-17T11:03:48.381999Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"base_model = AutoModelForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(tag2id))\nmodel = WeightedTokenClassifier(base_model, weights)\nmodel.to(device)\n\n\nargs = TrainingArguments(\n    output_dir=\"/kaggle/working/\",\n    run_name=\"bert-ner-food-v1\",  # nome run esplicito\n    do_train=True,\n    do_eval=True,\n    logging_steps=100,\n    save_steps=5000,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    report_to=\"none\",  # Disabilita logging verso wandb\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    data_collator=data_collator,\n)\n\n\"\"\"\nNel fine-tuning, serve a:uniformare la lunghezza delle sequenze (padding), \ngestire correttamente i batch, \nallineare i token con le label (soprattutto importante nel NER).\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T11:03:48.383324Z","iopub.execute_input":"2025-05-17T11:03:48.383566Z","iopub.status.idle":"2025-05-17T11:03:50.542693Z","shell.execute_reply.started":"2025-05-17T11:03:48.383542Z","shell.execute_reply":"2025-05-17T11:03:50.541882Z"}},"outputs":[{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8f6573c31d64a7d9c3cb74964aa77af"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_31/512715000.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'\\nNel fine-tuning, serve a:uniformare la lunghezza delle sequenze (padding), \\ngestire correttamente i batch, \\nallineare i token con le label (soprattutto importante nel NER).\\n'"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T11:03:50.543551Z","iopub.execute_input":"2025-05-17T11:03:50.544220Z","iopub.status.idle":"2025-05-17T13:57:47.311458Z","shell.execute_reply.started":"2025-05-17T11:03:50.544193Z","shell.execute_reply":"2025-05-17T13:57:47.310578Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [15000/15000 2:53:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.365700</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.253000</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.259200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.236500</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.234200</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.216100</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.210300</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.216100</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.204200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.208000</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.218600</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.213800</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.197100</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.204100</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.195600</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.198400</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.190200</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.196500</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.191800</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.192100</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.187900</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.203800</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.192100</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.193300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.194100</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.191400</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.183600</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.194100</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.199200</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.190400</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.178600</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.186800</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.177300</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.175400</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.177900</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.184700</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>0.174700</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>0.194900</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>0.186900</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.187500</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>0.185200</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>0.179500</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>0.172000</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>0.185300</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.175300</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>0.174700</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>0.176300</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>0.170800</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>0.164100</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.182700</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>0.152200</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>0.156300</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>0.156600</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>0.151300</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.168200</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>0.152100</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>0.159600</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>0.151300</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>0.149500</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.168900</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>0.150400</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>0.154100</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>0.159100</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>0.161400</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.157100</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>0.157900</td>\n    </tr>\n    <tr>\n      <td>6700</td>\n      <td>0.159500</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>0.172500</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>0.155100</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.159200</td>\n    </tr>\n    <tr>\n      <td>7100</td>\n      <td>0.157100</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>0.158400</td>\n    </tr>\n    <tr>\n      <td>7300</td>\n      <td>0.165000</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>0.156400</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.155300</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>0.152500</td>\n    </tr>\n    <tr>\n      <td>7700</td>\n      <td>0.153600</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>0.146200</td>\n    </tr>\n    <tr>\n      <td>7900</td>\n      <td>0.138100</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.143400</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>0.153500</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>0.151300</td>\n    </tr>\n    <tr>\n      <td>8300</td>\n      <td>0.167300</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>0.146700</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.162100</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>0.157300</td>\n    </tr>\n    <tr>\n      <td>8700</td>\n      <td>0.148300</td>\n    </tr>\n    <tr>\n      <td>8800</td>\n      <td>0.156100</td>\n    </tr>\n    <tr>\n      <td>8900</td>\n      <td>0.162100</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.155600</td>\n    </tr>\n    <tr>\n      <td>9100</td>\n      <td>0.157400</td>\n    </tr>\n    <tr>\n      <td>9200</td>\n      <td>0.162500</td>\n    </tr>\n    <tr>\n      <td>9300</td>\n      <td>0.151000</td>\n    </tr>\n    <tr>\n      <td>9400</td>\n      <td>0.142500</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.148900</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>0.146900</td>\n    </tr>\n    <tr>\n      <td>9700</td>\n      <td>0.154500</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>0.154800</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>0.158600</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.152200</td>\n    </tr>\n    <tr>\n      <td>10100</td>\n      <td>0.128000</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>0.131300</td>\n    </tr>\n    <tr>\n      <td>10300</td>\n      <td>0.126800</td>\n    </tr>\n    <tr>\n      <td>10400</td>\n      <td>0.139100</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.121600</td>\n    </tr>\n    <tr>\n      <td>10600</td>\n      <td>0.122400</td>\n    </tr>\n    <tr>\n      <td>10700</td>\n      <td>0.124000</td>\n    </tr>\n    <tr>\n      <td>10800</td>\n      <td>0.134200</td>\n    </tr>\n    <tr>\n      <td>10900</td>\n      <td>0.133900</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.135500</td>\n    </tr>\n    <tr>\n      <td>11100</td>\n      <td>0.125800</td>\n    </tr>\n    <tr>\n      <td>11200</td>\n      <td>0.133400</td>\n    </tr>\n    <tr>\n      <td>11300</td>\n      <td>0.129300</td>\n    </tr>\n    <tr>\n      <td>11400</td>\n      <td>0.137700</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.121400</td>\n    </tr>\n    <tr>\n      <td>11600</td>\n      <td>0.126200</td>\n    </tr>\n    <tr>\n      <td>11700</td>\n      <td>0.124000</td>\n    </tr>\n    <tr>\n      <td>11800</td>\n      <td>0.127900</td>\n    </tr>\n    <tr>\n      <td>11900</td>\n      <td>0.130300</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.127200</td>\n    </tr>\n    <tr>\n      <td>12100</td>\n      <td>0.115400</td>\n    </tr>\n    <tr>\n      <td>12200</td>\n      <td>0.124500</td>\n    </tr>\n    <tr>\n      <td>12300</td>\n      <td>0.137200</td>\n    </tr>\n    <tr>\n      <td>12400</td>\n      <td>0.124200</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.124100</td>\n    </tr>\n    <tr>\n      <td>12600</td>\n      <td>0.124200</td>\n    </tr>\n    <tr>\n      <td>12700</td>\n      <td>0.133300</td>\n    </tr>\n    <tr>\n      <td>12800</td>\n      <td>0.122900</td>\n    </tr>\n    <tr>\n      <td>12900</td>\n      <td>0.133700</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.130500</td>\n    </tr>\n    <tr>\n      <td>13100</td>\n      <td>0.140100</td>\n    </tr>\n    <tr>\n      <td>13200</td>\n      <td>0.123900</td>\n    </tr>\n    <tr>\n      <td>13300</td>\n      <td>0.122800</td>\n    </tr>\n    <tr>\n      <td>13400</td>\n      <td>0.131500</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.127200</td>\n    </tr>\n    <tr>\n      <td>13600</td>\n      <td>0.134100</td>\n    </tr>\n    <tr>\n      <td>13700</td>\n      <td>0.128800</td>\n    </tr>\n    <tr>\n      <td>13800</td>\n      <td>0.124900</td>\n    </tr>\n    <tr>\n      <td>13900</td>\n      <td>0.134100</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.122100</td>\n    </tr>\n    <tr>\n      <td>14100</td>\n      <td>0.126000</td>\n    </tr>\n    <tr>\n      <td>14200</td>\n      <td>0.129100</td>\n    </tr>\n    <tr>\n      <td>14300</td>\n      <td>0.130900</td>\n    </tr>\n    <tr>\n      <td>14400</td>\n      <td>0.124500</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>0.126800</td>\n    </tr>\n    <tr>\n      <td>14600</td>\n      <td>0.127300</td>\n    </tr>\n    <tr>\n      <td>14700</td>\n      <td>0.133200</td>\n    </tr>\n    <tr>\n      <td>14800</td>\n      <td>0.123700</td>\n    </tr>\n    <tr>\n      <td>14900</td>\n      <td>0.122600</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.132500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=15000, training_loss=0.1607112346013387, metrics={'train_runtime': 10435.7333, 'train_samples_per_second': 22.998, 'train_steps_per_second': 1.437, 'total_flos': 0.0, 'train_loss': 0.1607112346013387, 'epoch': 3.0})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T13:57:47.312336Z","iopub.execute_input":"2025-05-17T13:57:47.312590Z","iopub.status.idle":"2025-05-17T14:01:09.321573Z","shell.execute_reply.started":"2025-05-17T13:57:47.312564Z","shell.execute_reply":"2025-05-17T14:01:09.320895Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2500/2500 03:08]\n    </div>\n    "},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.19696687161922455,\n 'eval_precision': 0.38602867455384,\n 'eval_recall': 0.9300345418971473,\n 'eval_f1': 0.5455968938422406,\n 'eval_runtime': 201.9804,\n 'eval_samples_per_second': 99.02,\n 'eval_steps_per_second': 12.377,\n 'epoch': 3.0}"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"#### Test with Lora","metadata":{}},{"cell_type":"code","source":"!pip install peft accelerate -q\n\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom transformers import AutoModelForTokenClassification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:01:09.322288Z","iopub.execute_input":"2025-05-17T14:01:09.322546Z","iopub.status.idle":"2025-05-17T14:01:12.509994Z","shell.execute_reply.started":"2025-05-17T14:01:09.322518Z","shell.execute_reply":"2025-05-17T14:01:12.509130Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"base_model = AutoModelForTokenClassification.from_pretrained(\n    \"bert-base-cased\",\n    num_labels=len(tag2id)\n)\n\npeft_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=TaskType.TOKEN_CLS\n)\n\n# Applica LoRA\nmodel = get_peft_model(base_model, peft_config)\nmodel.print_trainable_parameters()  # Verifica i parametri LoRA addestrabili\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:01:12.511043Z","iopub.execute_input":"2025-05-17T14:01:12.511305Z","iopub.status.idle":"2025-05-17T14:01:12.770689Z","shell.execute_reply.started":"2025-05-17T14:01:12.511281Z","shell.execute_reply":"2025-05-17T14:01:12.770112Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 297,219 || all params: 108,019,206 || trainable%: 0.2752\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Parametri di training\nargs = TrainingArguments(\n    output_dir=\"/kaggle/working/ner-lora/\",\n    run_name=\"bert-ner-lora\",\n    do_train=True,\n    do_eval=True,\n    logging_dir=\"/kaggle/working/logs\",\n    logging_steps=100,\n    save_steps=5000,\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=8,\n    weight_decay=0.01,\n    report_to=\"none\"\n)\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    data_collator=data_collator\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:01:12.771356Z","iopub.execute_input":"2025-05-17T14:01:12.771566Z","iopub.status.idle":"2025-05-17T14:01:12.998195Z","shell.execute_reply.started":"2025-05-17T14:01:12.771550Z","shell.execute_reply":"2025-05-17T14:01:12.997462Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/444641884.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"trainer.train()\n\n# Valutazione finale\nmetrics = trainer.evaluate()\nprint(\"Evaluation Results:\", metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:01:12.999504Z","iopub.execute_input":"2025-05-17T14:01:12.999750Z","iopub.status.idle":"2025-05-17T16:21:33.339678Z","shell.execute_reply.started":"2025-05-17T14:01:12.999733Z","shell.execute_reply":"2025-05-17T16:21:33.339093Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [15000/15000 2:16:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.512300</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.159500</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.131700</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.126500</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.124700</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.116900</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.108500</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.103600</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.102500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.099900</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.098100</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.096700</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.099600</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.096100</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.100500</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.094300</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.095500</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.088400</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.093700</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.092900</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.092300</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.092100</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.086400</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.089300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.091500</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.089700</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.091200</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.091800</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.093100</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.091500</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.090700</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.091500</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.090400</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.087200</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.084300</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.089800</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>0.087100</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>0.086000</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>0.088700</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.087600</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>0.088600</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>0.085500</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>0.084700</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>0.086500</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.084400</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>0.085800</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>0.084000</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>0.083600</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>0.084700</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.085100</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>0.084100</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>0.086500</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>0.086900</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>0.082300</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.081300</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>0.087600</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>0.085000</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>0.082100</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>0.081200</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.085900</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>0.083300</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>0.083600</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>0.084300</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>0.081600</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.085200</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>0.084700</td>\n    </tr>\n    <tr>\n      <td>6700</td>\n      <td>0.084200</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>0.082800</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>0.083300</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.084400</td>\n    </tr>\n    <tr>\n      <td>7100</td>\n      <td>0.083000</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>0.087300</td>\n    </tr>\n    <tr>\n      <td>7300</td>\n      <td>0.084500</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>0.083500</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.083100</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>0.083800</td>\n    </tr>\n    <tr>\n      <td>7700</td>\n      <td>0.079900</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>0.079200</td>\n    </tr>\n    <tr>\n      <td>7900</td>\n      <td>0.080900</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.079400</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>0.083500</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>0.083000</td>\n    </tr>\n    <tr>\n      <td>8300</td>\n      <td>0.080800</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>0.079700</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.084900</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>0.082900</td>\n    </tr>\n    <tr>\n      <td>8700</td>\n      <td>0.080100</td>\n    </tr>\n    <tr>\n      <td>8800</td>\n      <td>0.080000</td>\n    </tr>\n    <tr>\n      <td>8900</td>\n      <td>0.083100</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.081700</td>\n    </tr>\n    <tr>\n      <td>9100</td>\n      <td>0.081600</td>\n    </tr>\n    <tr>\n      <td>9200</td>\n      <td>0.084100</td>\n    </tr>\n    <tr>\n      <td>9300</td>\n      <td>0.082000</td>\n    </tr>\n    <tr>\n      <td>9400</td>\n      <td>0.081200</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.082600</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>0.083300</td>\n    </tr>\n    <tr>\n      <td>9700</td>\n      <td>0.083600</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>0.084800</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>0.082400</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.081300</td>\n    </tr>\n    <tr>\n      <td>10100</td>\n      <td>0.079400</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>0.081600</td>\n    </tr>\n    <tr>\n      <td>10300</td>\n      <td>0.078000</td>\n    </tr>\n    <tr>\n      <td>10400</td>\n      <td>0.082300</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.081300</td>\n    </tr>\n    <tr>\n      <td>10600</td>\n      <td>0.080400</td>\n    </tr>\n    <tr>\n      <td>10700</td>\n      <td>0.082100</td>\n    </tr>\n    <tr>\n      <td>10800</td>\n      <td>0.084900</td>\n    </tr>\n    <tr>\n      <td>10900</td>\n      <td>0.081600</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.085200</td>\n    </tr>\n    <tr>\n      <td>11100</td>\n      <td>0.081000</td>\n    </tr>\n    <tr>\n      <td>11200</td>\n      <td>0.078700</td>\n    </tr>\n    <tr>\n      <td>11300</td>\n      <td>0.084700</td>\n    </tr>\n    <tr>\n      <td>11400</td>\n      <td>0.084900</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.080000</td>\n    </tr>\n    <tr>\n      <td>11600</td>\n      <td>0.081400</td>\n    </tr>\n    <tr>\n      <td>11700</td>\n      <td>0.080100</td>\n    </tr>\n    <tr>\n      <td>11800</td>\n      <td>0.082800</td>\n    </tr>\n    <tr>\n      <td>11900</td>\n      <td>0.077900</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.079600</td>\n    </tr>\n    <tr>\n      <td>12100</td>\n      <td>0.078700</td>\n    </tr>\n    <tr>\n      <td>12200</td>\n      <td>0.080200</td>\n    </tr>\n    <tr>\n      <td>12300</td>\n      <td>0.082900</td>\n    </tr>\n    <tr>\n      <td>12400</td>\n      <td>0.079900</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.080500</td>\n    </tr>\n    <tr>\n      <td>12600</td>\n      <td>0.078500</td>\n    </tr>\n    <tr>\n      <td>12700</td>\n      <td>0.081500</td>\n    </tr>\n    <tr>\n      <td>12800</td>\n      <td>0.081200</td>\n    </tr>\n    <tr>\n      <td>12900</td>\n      <td>0.083100</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.082500</td>\n    </tr>\n    <tr>\n      <td>13100</td>\n      <td>0.080800</td>\n    </tr>\n    <tr>\n      <td>13200</td>\n      <td>0.078100</td>\n    </tr>\n    <tr>\n      <td>13300</td>\n      <td>0.083400</td>\n    </tr>\n    <tr>\n      <td>13400</td>\n      <td>0.079400</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.082500</td>\n    </tr>\n    <tr>\n      <td>13600</td>\n      <td>0.080300</td>\n    </tr>\n    <tr>\n      <td>13700</td>\n      <td>0.079800</td>\n    </tr>\n    <tr>\n      <td>13800</td>\n      <td>0.081200</td>\n    </tr>\n    <tr>\n      <td>13900</td>\n      <td>0.080900</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.078100</td>\n    </tr>\n    <tr>\n      <td>14100</td>\n      <td>0.080900</td>\n    </tr>\n    <tr>\n      <td>14200</td>\n      <td>0.080000</td>\n    </tr>\n    <tr>\n      <td>14300</td>\n      <td>0.078600</td>\n    </tr>\n    <tr>\n      <td>14400</td>\n      <td>0.079900</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>0.081800</td>\n    </tr>\n    <tr>\n      <td>14600</td>\n      <td>0.078600</td>\n    </tr>\n    <tr>\n      <td>14700</td>\n      <td>0.078600</td>\n    </tr>\n    <tr>\n      <td>14800</td>\n      <td>0.083600</td>\n    </tr>\n    <tr>\n      <td>14900</td>\n      <td>0.079000</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.082600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2500/2500 03:17]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.07875818759202957, 'eval_precision': 0.5997103441504247, 'eval_recall': 0.5901350274161211, 'eval_f1': 0.5948841569572786, 'eval_runtime': 210.6964, 'eval_samples_per_second': 94.923, 'eval_steps_per_second': 11.865, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":25}]}